{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "vvrt4WJ7o8e6"
   },
   "outputs": [],
   "source": [
    "#Set up generating mathematical functions in tree structures from the following\n",
    "#primitives, these will be used for calculating displacements of neurons\n",
    "from deap import gp\n",
    "import operator\n",
    "import math\n",
    "def square(x):\n",
    "    return x*x\n",
    "def absSqrt(x):\n",
    "    return math.sqrt(abs(x))\n",
    "pset = gp.PrimitiveSet(\"nodePrims\", arity=1)\n",
    "pset.addPrimitive(max, 2)\n",
    "pset.addPrimitive(operator.mul, 2)\n",
    "pset.addPrimitive(operator.add, 2)\n",
    "pset.addPrimitive(operator.sub, 2)\n",
    "pset.addPrimitive(math.sin, 1)\n",
    "pset.addPrimitive(math.cos, 1)\n",
    "pset.addPrimitive(absSqrt, 1)\n",
    "pset.addPrimitive(square, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "QCKS3iQIo8fK",
    "outputId": "a471f2b5-673b-4a53-838c-c6cb7dc4647d",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/theano_p27/lib/python2.7/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ec2-user/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ec2-user/anaconda3/envs/theano_p27/lib/python2.7/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ec2-user/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n",
      "/home/ec2-user/anaconda3/envs/theano_p27/lib/python2.7/site-packages/matplotlib/font_manager.py:278: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  'Matplotlib is building the font cache using fc-list. '\n",
      "/home/ec2-user/anaconda3/envs/theano_p27/lib/python2.7/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  RuntimeWarning)\n",
      "/home/ec2-user/anaconda3/envs/theano_p27/lib/python2.7/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\tmean   \tmin    \tmax    \tstdDev \n",
      "0  \t30    \t29.8183\t2.76483\t626.801\t111.468\n",
      "1  \t25    \t49.4355\t3.4496 \t626.801\t106.333\n",
      "2  \t25    \t134.38 \t16     \t626.801\t178.283\n",
      "3  \t25    \t235.152\t24.1012\t626.801\t189.383\n",
      "4  \t22    \t352.303\t187.605\t626.801\t212.625\n",
      "5  \t22    \t549.942\t187.605\t626.801\t166.88 \n",
      "6  \t23    \t677.923\t626.801\t1649.24\t222.835\n",
      "7  \t25    \t780.167\t626.801\t1649.24\t365.083\n",
      "8  \t27    \t1163.58\t626.801\t1649.24\t510.579\n",
      "9  \t22    \t4405.71\t626.801\t38743  \t9778.76\n",
      "10 \t23    \t11972.8\t1649.24\t38743  \t16504.9\n",
      "11 \t24    \t25324  \t1649.24\t38743  \t17374.8\n",
      "12 \t22    \t38743  \t38743  \t38743  \t0      \n",
      "13 \t27    \t38743  \t38743  \t38743  \t0      \n",
      "14 \t24    \t38743  \t38743  \t38743  \t0      \n",
      "15 \t21    \t38960  \t38743  \t47422.1\t1355.01\n",
      "16 \t21    \t39827.9\t38743  \t47422.1\t2870.32\n",
      "17 \t25    \t43299.5\t38743  \t47422.1\t4334.09\n",
      "18 \t25    \t48129.7\t38743  \t65536  \t5455.03\n",
      "19 \t24    \t52856.2\t47422.1\t65536  \t8300.85\n",
      "20 \t25    \t59649  \t47422.1\t65536  \t8484.11\n",
      "21 \t24    \t65536  \t65536  \t65536  \t0      \n",
      "22 \t24    \t65536  \t65536  \t65536  \t0      \n",
      "23 \t23    \t65536  \t65536  \t65536  \t0      \n",
      "24 \t25    \t65536  \t65536  \t65536  \t0      \n",
      "25 \t24    \t65536  \t65536  \t65536  \t0      \n",
      "26 \t28    \t65536  \t65536  \t65536  \t0      \n",
      "27 \t22    \t106172 \t65536  \t390625 \t107513 \n",
      "28 \t29    \t190321 \t65536  \t390625 \t156175 \n",
      "29 \t20    \t304102 \t65536  \t390625 \t141553 \n",
      "30 \t23    \t382498 \t65536  \t390625 \t50754.5\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Code to implement the evolution of the models and hyperparameters for generating them\n",
    "%matplotlib notebook\n",
    "from deap import creator, base, tools, algorithms\n",
    "from random import randint\n",
    "import numpy as np\n",
    "import pickle\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "DataDims = 2\n",
    "MINDIMFUNCS = 1\n",
    "MAXDIMFUNCS = 10\n",
    "MINDIMS = DataDims\n",
    "MAXDIMS = 10\n",
    "POPSIZE = 30\n",
    "GENERATIONS = 30\n",
    "MU = 40\n",
    "LAMBDA = 30\n",
    "CXPB = 0.5\n",
    "MUTPB = 0.3\n",
    "WEIGHTSCALE = 0.05\n",
    "BIASSCALE = 0.05\n",
    "\n",
    "\n",
    "def genTreeList():\n",
    "    return [gp.PrimitiveTree(gp.genHalfAndHalf(pset=pset, min_=1,max_=6)) for i in range(randint(MINDIMFUNCS,MAXDIMFUNCS))]\n",
    "def genFuncList():\n",
    "    return [genTreeList() for j in range(randint(MINDIMS,MAXDIMS))]\n",
    "\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,) )\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "# def myMutate(individual):\n",
    "#     new = [[gp.mutNodeReplacement(x,pset=pset) for x in l] for l in toolbox.clone(individual)]\n",
    "#     return (tools.initIterate(creator.Individual, lambda: new),)\n",
    "\n",
    "\n",
    "def getFitMap(ls):\n",
    "    fitnesses = []\n",
    "    for l in ls:\n",
    "        fitnesses.append(l.fitness.values[0])\n",
    "    return fitnesses\n",
    "\n",
    "def evolve(evaluator):\n",
    "    \n",
    "    \n",
    "    \n",
    "    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,) )\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "    \n",
    "    toolbox = base.Toolbox()\n",
    "    toolbox.register(\"individual\", tools.initIterate, creator.Individual, genFuncList)\n",
    "    \n",
    "    def myMutate(individual):\n",
    "        new = [[gp.mutNodeReplacement(x,pset=pset) for x in l] for l in toolbox.clone(individual)]\n",
    "        new = [[x[0] for x in l] for l in new]\n",
    "        return (tools.initIterate(creator.Individual, lambda: new),)\n",
    "\n",
    "    toolbox.register(\"mate\", tools.cxUniform, indpb=0.5)\n",
    "    toolbox.register(\"mutate\", myMutate)\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize = 4)\n",
    "    toolbox.register(\"evaluate\", evaluator)\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "    pop = toolbox.population(POPSIZE)\n",
    "    \n",
    "    \n",
    "\n",
    "    myStats = tools.Statistics()\n",
    "    myStats.register(\"mean\", lambda ls: np.mean(getFitMap(ls)))\n",
    "    myStats.register(\"min\", lambda ls: min(getFitMap(ls)))\n",
    "    myStats.register(\"max\", lambda ls: max(getFitMap(ls)))\n",
    "    myStats.register(\"stdDev\", lambda ls: np.std(getFitMap(ls)))\n",
    "\n",
    "    hallOFame = tools.HallOfFame(5) # hall of fame of size 5\n",
    "\n",
    "\n",
    "    (finalPop, logbook) = algorithms.eaMuPlusLambda(pop, toolbox, MU, LAMBDA, CXPB, MUTPB, GENERATIONS, myStats, halloffame=hallOFame, verbose=True)\n",
    "\n",
    "    gen = logbook.select(\"gen\")\n",
    "    fit_maxs = logbook.select(\"max\")\n",
    "    fit_avgs = logbook.select(\"mean\")\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "    line1 = ax1.plot(gen, fit_maxs, \"b-\", label=\"Maximum Fitness\")\n",
    "    ax1.set_xlabel(\"Generation\")\n",
    "    ax1.set_ylabel(\"Fitness\", color=\"b\")\n",
    "    for tl in ax1.get_yticklabels():\n",
    "        tl.set_color(\"b\")\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    line2 = ax2.plot(gen, fit_avgs, \"r-\", label=\"Average Fitness\")\n",
    "    ax2.set_ylabel(\"Size\", color=\"r\")\n",
    "    for tl in ax2.get_yticklabels():\n",
    "        tl.set_color(\"r\")\n",
    "\n",
    "    lns = line1 + line2\n",
    "    labs = [l.get_label() for l in lns]\n",
    "    ax1.legend(lns, labs, loc=\"center right\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def flatten(mylist):\n",
    "    return list(itertools.chain.from_iterable(mylist))\n",
    "    \n",
    "def myEval(individual):\n",
    "    funcs = []\n",
    "    for dimlist in individual:\n",
    "        newDimlist = []\n",
    "        for tree in dimlist:\n",
    "#             print gp.stringify(tree)\n",
    "            f = gp.compile(tree, pset)\n",
    "            newDimlist.append(f)\n",
    "        funcs.append(newDimlist)\n",
    "    flattened = flatten(funcs)\n",
    "    mapped = map(lambda f: f(1), flattened)\n",
    "    return max(mapped),\n",
    "    \n",
    "    \n",
    "evolve(myEval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "MSJBPuYeo8fm",
    "outputId": "19052e0c-7a92-439e-eb8b-ccc170a9eeaa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuDNN version 7005 on context None\n",
      "Mapped name None to device cuda: GRID K520 (0000:00:03.0)\n"
     ]
    }
   ],
   "source": [
    "#Load MNIST data to train/test models on\n",
    "import theano\n",
    "import mnist\n",
    "import numpy as np\n",
    "\n",
    "train_images = mnist.train_images()\n",
    "train_labels = mnist.train_labels()\n",
    "\n",
    "test_images = mnist.test_images()\n",
    "test_labels = mnist.test_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "MSJBPuYeo8fm",
    "outputId": "19052e0c-7a92-439e-eb8b-ccc170a9eeaa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f83cc59bc90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parse mnist data into form that we will use\n",
    "def labelToArray(x):\n",
    "    blank = [0] * 10\n",
    "    blank[x] = 1\n",
    "    return np.array(blank)\n",
    "\n",
    "trainingimgs = [train_images[i].astype(theano.config.floatX).ravel() * (1.0/256) for i in range(train_images.shape[0])]\n",
    "traininglabels = [labelToArray(train_labels[i]).astype(theano.config.floatX) for i in range(train_labels.shape[0])]\n",
    "testingimgs = [test_images[i].astype(theano.config.floatX).ravel() * (1.0/256) for i in range(test_images.shape[0])]\n",
    "testinglabels = [labelToArray(test_labels[i]).astype(theano.config.floatX) * (1.0 / 256) for i in range(test_labels.shape[0])]\n",
    "plt.imshow(trainingimgs[0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "oTGC3727o8f0",
    "outputId": "b31754f4-b054-4e8c-d625-9dc6e12cf7dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running initial singleGenConsolidate\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "starting to loop\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "first version took: 0.000170946121216\n",
      "looped\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "first version took: 0.000148057937622\n",
      "looped\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "first version took: 0.000217199325562\n",
      "looped\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "first version took: 0.000140905380249\n",
      "looped\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "first version took: 0.000139951705933\n",
      "looped\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "first version took: 0.000143051147461\n",
      "looped\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "first version took: 0.000187873840332\n",
      "looped\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "first version took: 0.00015115737915\n",
      "looped\n",
      "[0.2443998]\n",
      "biased and relued: [0.00036287 0.0865052  0.05890616 0.13602126 0.09092445]\n",
      "biased and relued: [0.00674443 0.05439217 0.02567784 0.00419954 0.0227646 ]\n",
      "biased and relued: [0.03805926 0.03900546 0.02774199 0.00591309 0.02349696]\n",
      "biased and relued: [0.05130827 0.03693888 0.04956002 0.03951226 0.03997591]\n",
      "biased and relued: [0.01275025 0.04605314 0.03573955 0.02772033 0.03974575]\n",
      "biased and relued: [0.01199579 0.0170929  0.01890449 0.04267422 0.03830744]\n",
      "biased and relued: [0.02506332 0.03694327 0.00493359 0.04750744 0.00939433]\n",
      "biased and relued: [0.0065265  0.02123431 0.01260454 0.00114341 0.02702037]\n",
      "biased and relued: [0.04751083 0.03250268 0.01431014 0.02632469 0.03625329]\n",
      "[0.2443998]\n"
     ]
    }
   ],
   "source": [
    "#Miscellaneous functions that get used for calculating growth of networks\n",
    "\n",
    "import theano.tensor as T\n",
    "from theano import shared\n",
    "import theano\n",
    "from autograd import grad as Grad\n",
    "import autograd.numpy as np\n",
    "import autograd.numpy.linalg as LA\n",
    "import itertools\n",
    "import typing\n",
    "import time\n",
    "import math\n",
    "from itertools import izip\n",
    "#We're modeling neurons as points in a high dimensional space, but to keep them\n",
    "#from just going all over the place and not interacting to create interesting \n",
    "#structures, we're going to limit the size of that space to a box of this width\n",
    "SPACESPAN = 2.0\n",
    "\n",
    "#Take one dimension of a neuron's position -- if it's outside the box,\n",
    "#wrap it around so it goes in the box. Otherwise, do nothing.\n",
    "def box(x):\n",
    "    if x > 0 + SPACESPAN / 2.0:\n",
    "        return -1.0 + x\n",
    "    elif x < 0 - SPACESPAN / 2.0:\n",
    "        return 1.0 + x\n",
    "    else:\n",
    "        return x\n",
    "      \n",
    "      \n",
    "#Want neurons that are close together to overlap, so we have a \"resolution\" of \n",
    "#the space such that if neurons are closer than the \"resolution\", they overlap. \n",
    "#resDenominator can be thought of as how many pixels are in a row of the box the\n",
    "#neurons live in.\n",
    "def discretize(x, resDenominator):\n",
    "    if x > 0.0:\n",
    "        return np.floor(1.0 * x * resDenominator) / resDenominator\n",
    "    elif x < 0.0:\n",
    "        return np.floor(1.0 * x * resDenominator) / resDenominator\n",
    "    else:\n",
    "        return 0.0\n",
    "    \n",
    "def mnistlabelToArray(x):\n",
    "    blank = [0] * 10\n",
    "    blank[x] = 1\n",
    "    return np.array(blank)\n",
    "\n",
    "\n",
    "def flatten(mylist):\n",
    "    return list(itertools.chain.from_iterable(mylist))\n",
    "\n",
    "#Consolidation is strange but crucial. Basically you have a big array of where the\n",
    "#neurons are in space, then you apply the displacement/\"growth\" rules to each\n",
    "#dimension of those positions. Now you have a huge list of neuron positions, and\n",
    "#consolidating is calculating what neurons overlap, and creating a list of indices\n",
    "#that tells which neurons are going as input to a neuron in the next layer. You\n",
    "#could do this with a bitmask, but the networks are usually sparse enough that \n",
    "#it would be extremely inefficient, but maybe with a low resDenominator the space\n",
    "#will overlap enough that it will be efficient. Improving this would be nice, but\n",
    "#I don't know if its necessary, given this is slow but not terribly slow.\n",
    "\n",
    "#to be honest I have to look over this a lot too to figure out whats going on.\n",
    "\n",
    "\n",
    "def dictSingleGenConsolidate(arrays):\n",
    "    #takes as input [[position, position,...],[position, position,...], ...]\n",
    "    #want to find, in the flattened list above, which the indices of all neurons that overlap with the first position,\n",
    "    #then the indices of all the neurons that overlap with the second position, and so on until done\n",
    "    \n",
    "    arraylen = len(arrays)\n",
    "    irange = range(arraylen)\n",
    "    \n",
    "    positionDict = {}\n",
    "    neuronPositionTuples = map(lambda l: tuple(l), arrays)\n",
    "    positionTuplesOrdered = []\n",
    "\n",
    "    print \"starting a dictSingleGenConsolidate\" \n",
    "\n",
    "    for posTuple,i in zip(neuronPositionTuples, irange):\n",
    "        if posTuple not in positionDict:\n",
    "            positionDict[posTuple] = [i]\n",
    "            positionTuplesOrdered.append(posTuple)\n",
    "        else:\n",
    "            positionDict[posTuple].append(i)\n",
    "\n",
    "    indices = [positionDict[posTuple] for posTuple in positionTuplesOrdered]\n",
    "    \n",
    "    print \"finished a dictSingleGenConsolidate\"\n",
    "        \n",
    "    #returns a list [[index, index, index,...], [index, index, index,...]] where the ith sublist corresponds to the ith neuron\n",
    "    #in the next layer up, and each sublist contains the indices of the neurons that connect to them.\n",
    "    return indices\n",
    "\n",
    "  \n",
    "def newSingleGenConsolidate(arrays):\n",
    "    bigMatrix = np.array(arrays)\n",
    "    arraylen = len(arrays)\n",
    "    initArraylen = len(arrays)\n",
    "    indices = []\n",
    "    flattenedIndices = []\n",
    "    \n",
    "    irange = range(arraylen)\n",
    "    \n",
    "    counter = True\n",
    "    print \"starting a newSingleGenConsolidate\"\n",
    "    flattenedIndices = np.ones()\n",
    "    for i in irange:\n",
    "        if i not in flattenedIndices:\n",
    "            subgroupArr = np.argwhere(np.all((bigMatrix-bigMatrix[i])==0, axis=0))\n",
    "            subgroup = subgroupArr.tolist()\n",
    "            indices.append(subgroup)\n",
    "            flattenedIndices += subgroup\n",
    "            arraylen -= subgroupArr.size\n",
    "            if counter and arraylen/initArraylen < 0.5:\n",
    "                print \"half way done a newSingleGenConsolidate\"\n",
    "                counter = False\n",
    "    \n",
    "    print \"finished a newSingleGenConsolidate\"\n",
    "    return indices\n",
    "            \n",
    "            \n",
    "            \n",
    "def singleGenConsolidate(arrays):\n",
    "    #takes as input [[position, position,...],[position, position,...], ...]\n",
    "    #want to find, in the flattened list above, which the indices of all neurons that overlap with the first position,\n",
    "    #then the indices of all the neurons that overlap with the second position, and so on until done\n",
    "    \n",
    "    indices = []\n",
    "    flattenedIndices = []\n",
    "    arraylen = len(arrays)\n",
    "    initArraylen = len(arrays) * 1.0\n",
    "    irange = range(arraylen)\n",
    "    \n",
    "    counter = True\n",
    "    print \"starting a singleGenConsolidate\"\n",
    "    for i in irange:\n",
    "        if i not in flattenedIndices:\n",
    "            subgroup = [i] + [j for j in irange[i + 1:] if np.array_equal(arrays[i], arrays[j])]\n",
    "            arraylen -= len(subgroup)\n",
    "            indices.append(subgroup)\n",
    "            flattenedIndices += subgroup\n",
    "            if counter and arraylen/initArraylen < 0.5:\n",
    "                print \"half way done a singleGenConsolidate\"\n",
    "                counter = False\n",
    "    \n",
    "    print \"finished a singleGenConsolidate\"\n",
    "    \n",
    "    #returns a list [[index, index, index,...], [index, index, index,...]] where the ith sublist corresponds to the ith neuron\n",
    "    #in the next layer up, and each sublist contains the indices of the neurons that connect to them.\n",
    "    return indices\n",
    "\n",
    "\n",
    "\n",
    "def nprelu(x):\n",
    "    np.maximum(0,x)\n",
    "\n",
    "\n",
    "def getSubV2np(index, inds, complete):\n",
    "    return complete[inds[index]:inds[index + 1]]\n",
    "\n",
    "def getSubV3np(index, indinds, inds, complete):\n",
    "    subInds = inds[indinds[index] : indinds[index + 1] + 1]\n",
    "    return subInds, complete\n",
    "  \n",
    "#this is a consolidation list actually being used\n",
    "def singleConsol(tensor, indices):\n",
    "    return (np.choose(indices, tensor)).sum()\n",
    "\n",
    "def positionConsolidate(arrays, consolidations):\n",
    "    return [arrays[sublist[0]] for sublist in consolidations]\n",
    "\n",
    "def numpyConsolidate(array, consols):\n",
    "    new = []\n",
    "    for sublist in consols:\n",
    "        x = 0.0\n",
    "        for i in sublist:\n",
    "            x += array[i]\n",
    "        new.append(x)\n",
    "\n",
    "    return new\n",
    "\n",
    "def npConsolidate(array, consolinds, consols):\n",
    "    ordered = array.take(consols)\n",
    "    f = lambda i : ordered[consolinds[i]: consolinds[i + 1]].sum()\n",
    "    veced = np.vectorize(f)\n",
    "    return veced(np.arange(consolinds.size))\n",
    "\n",
    "\n",
    "def generalfeedforward((weights, biases, finalweights, finalbiases), consolMasks, hiddenlayers, branchMultiplier, inp):\n",
    "    #implements a fractalnet in numpy, using consolidation masks instead of lists.\n",
    "    for i in range(hiddenlayers):\n",
    "        inp = np.repeat(inp, branchMultiplier)\n",
    "        inp = np.multiply(weights[i], inp)\n",
    "        inp = np.concatenate((inp, np.array([0.0]).astype('float32')))\n",
    "        inp = inp.take(consolMasks[i]).sum(axis = 1)\n",
    "        inp = nprelu(np.add(inp, biases[i]))\n",
    "    \n",
    "    print inp\n",
    "    finalout = nprelu(np.dot(inp, finalweights) + finalbiases)\n",
    "    return finalout\n",
    "\n",
    "\n",
    "class nnet:\n",
    "    weights = []\n",
    "    biases = []\n",
    "    consolidations = []\n",
    "    finalweights = []\n",
    "    finalbiases = []\n",
    "    weightnum = 0\n",
    "    hiddenlayers = 0\n",
    "    \n",
    "    def __init__(self, resolution, functions, inputdimension, datainp, dataoutp, synapseThreshold):\n",
    "        self.resDenominator = resolution\n",
    "        self.funcs = functions\n",
    "        self.dimensions = len(self.funcs)\n",
    "        \n",
    "        #branch multiplier says how many neurons grow out of each neuron every\n",
    "        #time a new layer is grown. This is the same fo\n",
    "        \n",
    "        self.branchMultiplier = len(flatten(self.funcs))\n",
    "        self.TBranchMult = shared(np.array([self.branchMultiplier]))\n",
    "#         self.dataset = [shared(dat.astype(theano.config.floatX)) for dat in datainp]\n",
    "#         self.datalabels = [shared(outp.astype(theano.config.floatX)) for outp in dataoutp]\n",
    "        self.dataSample = datainp[0] #numpy\n",
    "        self.dataOutSample = dataoutp[0]\n",
    "        self.inputdimension = inputdimension\n",
    "        \n",
    "        if self.dataSample.size ** (1.0/ inputdimension) > self.resDenominator * 2.0:\n",
    "            print \"resDenominator may be too small for effective learning\"\n",
    "            \n",
    "        self.threshold = synapseThreshold\n",
    "\n",
    "    def applyFuncs(self, narray): #checked\n",
    "        #grows a single neuron's new positions, given vector position (represented as a list)\n",
    "        boxvec = np.vectorize(lambda x: discretize(box(x), self.resDenominator))\n",
    "        displaced = []\n",
    "        \n",
    "        for dim in range(self.dimensions):\n",
    "            for f in self.funcs[dim]:\n",
    "                \n",
    "                zeroes = np.zeros_like(narray)\n",
    "                displacement = f(narray[dim]) % SPACESPAN\n",
    "                zeroes[dim] = displacement\n",
    "                \n",
    "                newArray = np.add(narray, zeroes)\n",
    "                newArrayBoxed = boxvec(newArray)\n",
    "                displaced.append(newArrayBoxed)\n",
    "                \n",
    "        \n",
    "        return displaced\n",
    "        \n",
    "\n",
    "    def applyFuncsMult(self, narrays): \n",
    "        #given list of neuron positions (lists), grow them and return a list of list of positions, where the first list is the \n",
    "        #first neuron's \"outgrowths\", the second list is the second neuron's \"outgrowths\" and so on.\n",
    "        \n",
    "        return flatten([self.applyFuncs(x) for x in narrays])\n",
    "    \n",
    "    def locate(self, sample):  #only 1 or 2 implemented\n",
    "        #given input data as an array, represent that data spacially as a neurons that can then be grown\n",
    "        \n",
    "        insize = sample.size\n",
    "        sample = np.ravel(sample) \n",
    "        tensorFrame = [0] * self.dimensions\n",
    "        located = [0] * insize\n",
    "        \n",
    "        boxvec = np.vectorize(lambda x: discretize(box(x), self.resDenominator))\n",
    "        \n",
    "        #self.inputdimension is the dimension the input should be represented in\n",
    "        \n",
    "        if self.inputdimension == 1:\n",
    "            #arrange neurons in a line along the first dimension\n",
    "            for i in range(insize):\n",
    "                myTens = tensorFrame[:]\n",
    "                myTens[0] = (2.0 * i) / insize - 1.0\n",
    "                located[i] = boxvec(np.array(myTens))\n",
    "        \n",
    "        if self.inputdimension == 2:\n",
    "            #arrange neurons in a grid in the first two dimensions that has integer dimensions, calculated to be as \n",
    "            #close to square as possible for convenience\n",
    "            located = []\n",
    "            factorPairs = [(i,(insize / i)) for i in range(1, int(math.floor(insize**0.5))) if insize % i == 0]\n",
    "            pair = factorPairs[-1]\n",
    "            for i in range(pair[0]):\n",
    "                for j in range(pair[1]):\n",
    "                    myTens = tensorFrame[:]\n",
    "                    myTens[0] = 2.0 * i/pair[0] - 1.0\n",
    "                    myTens[1] = 2.0 * j/pair[1] - 1.0\n",
    "                    located.append(boxvec(np.array(myTens)))\n",
    "                            \n",
    "        return located\n",
    "        \n",
    "    def genConsolidate(self): #finds consolidation list from located self.dataSample\n",
    "        consols = []\n",
    "#         print len(self.dataSample.ravel())\n",
    "\n",
    "        located = self.locate(self.dataSample)\n",
    "        #type is [position, position, ...], don't care about dataSample's actual values right now, just its dimensions\n",
    "        \n",
    "#         print len(located)\n",
    "#         print type(located[0])\n",
    "        print \"running initial dictSingleGenConsolidate\"\n",
    "    \n",
    "        #Grow the neurons, generate consolidations list, consolidate, then start a loop\n",
    "        located = self.applyFuncsMult(located)\n",
    "        consols.append(dictSingleGenConsolidate(located))\n",
    "        located = positionConsolidate(located, consols[-1]) \n",
    "\n",
    "        \n",
    "        print \"starting to loop\"\n",
    "        #stop the growth when it hits a certain number of weights\n",
    "        while len(flatten(flatten(consols))) + len(flatten(consols[-1])) * self.branchMultiplier < self.threshold:\n",
    "            located = self.applyFuncsMult(located)\n",
    "            testStart = time.time()\n",
    "            consols.append(dictSingleGenConsolidate(located))\n",
    "            print \"first version took: \" + str(time.time() - testStart)\n",
    "#             testStart = time.time()\n",
    "#             x = newSingleGenConsolidate(located)\n",
    "#             print \"new version took: \" + str(time.time() - testStart)\n",
    "            \n",
    "            located = positionConsolidate(located, consols[-1]) \n",
    "            print \"looped\"\n",
    "            \n",
    "        self.consolidations = consols\n",
    "        \n",
    "        #In contrast to using the consolidation list, which is a list of lists of variable length, you can also pad them to create\n",
    "        #a list of fixed lengths lists (maximum of the previous variable lengths) that makes things neater but sacrifices some\n",
    "        #memory (and possibly some speed, but depending on implementation it might be faster). Pad with out of bounds indices\n",
    "        #that theano and numpy will default to zero.\n",
    "        self.consolMasks = []\n",
    "        for layerConsols in self.consolidations:\n",
    "#             print \"initial \" + str(layerConsols)\n",
    "            maxInLength = max(map(len, layerConsols))\n",
    "            inLength = len(flatten(layerConsols))\n",
    "            extended = map(lambda l: l + [inLength] * (maxInLength - len(l)), layerConsols)\n",
    "#             print \"extended: \" + str(extended)\n",
    "            self.consolMasks.append(np.array(extended).astype('int32'))\n",
    "        return consols\n",
    "    \n",
    "    def genWeights(self):\n",
    "        myWeightNum = 0\n",
    "        self.hiddenlayers = 0\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        self.finalweights = []\n",
    "        self.finalbiases = []\n",
    "        for consol in self.consolidations:\n",
    "            weightVec = (np.random.rand(len(flatten(consol))) * WEIGHTSCALE).astype(theano.config.floatX).tolist()\n",
    "            biasVec   = (np.random.rand(len(consol)) * BIASSCALE).astype(theano.config.floatX).tolist()\n",
    "            self.weights.append(weightVec)\n",
    "            self.biases.append(biasVec)\n",
    "            myWeightNum += len(weightVec)\n",
    "\n",
    "            #convert to shared data type for later speed\n",
    "            self.hiddenlayers += 1\n",
    "        \n",
    "        outsize = len(self.dataOutSample)\n",
    "        \n",
    "        self.finalweights = np.random.rand(len(self.consolidations[-1]),outsize).astype('float32')        #final interconnected layer for output\n",
    "        self.finalbiases = np.random.rand(outsize).astype('float32')\n",
    "\n",
    "        myWeightNum += len(self.consolidations[-1]) * outsize\n",
    "#         self.weightNum = myWeightNum\n",
    "        \n",
    "    def feedforward(self, inp):\n",
    "        \n",
    "        for i in range(self.hiddenlayers):\n",
    "            inp = np.repeat(inp, self.branchMultiplier)\n",
    "#             print \"repeated: \" + str(inp)\n",
    "            inp = np.multiply(self.weights[i], inp)\n",
    "#             print \"weighted: \" + str(inp)\n",
    "            inp = numpyConsolidate(inp, self.consolidations[i])\n",
    "#             print \"consolidated: \" + str(inp)\n",
    "            inp = np.maximum(0, np.add(inp, self.biases[i]))\n",
    "            print \"biased and relued: \" + str(inp)\n",
    "        \n",
    "#         print \"before finals: \" + str(inp)\n",
    "#         print \"finalweights: \" + str(self.finalweights)\n",
    "#         print \"finalbiases: \" + str(self.finalbiases)\n",
    "        finalout = (np.dot(inp, self.finalweights) + self.finalbiases)\n",
    "#         print \"final: \" + str(finalout)\n",
    "        return finalout\n",
    "\n",
    "    def nfeedforward(self, inp):\n",
    "        for i in range(self.hiddenlayers):\n",
    "            inp = np.repeat(inp, self.branchMultiplier)\n",
    "            inp = np.multiply(self.weights[i], inp)\n",
    "            inp = np.concatenate((inp, np.array([0.0]).astype('float32')))\n",
    "            inp = inp.take(self.consolMasks[i]).sum(axis = 1)\n",
    "            inp = np.maximum(0,np.add(inp, self.biases[i]))\n",
    "        return np.dot(inp, self.finalweights) + self.finalbiases\n",
    "    \n",
    "    def test(inputs, outputs):\n",
    "        \n",
    "        def foo(x):\n",
    "            if x > 0.5:\n",
    "                return 1.0\n",
    "            return 0.0\n",
    "\n",
    "        binarize = np.vectorize(foo)\n",
    "        \n",
    "        errors = [LA.norm(outp - binarize(self.feedforward(inp))) for inp,outp in izip(inputs,outputs)]\n",
    "        return sum(errors)/len(inputs) * 100.0\n",
    "        \n",
    "    \n",
    "    def numpytrain(self, alpha, epochs, batchsize, inputlist, outputlist, verbose, testdatainputs, testdatalabels):\n",
    "        print \"starting training\"\n",
    "        \n",
    "        def error((weights, biases, finalweights, finalbiases), inp, outp):\n",
    "            return LA.norm(outp - generalfeedforward((weights,biases,finalweights,finalbiases), \n",
    "                                                     self.consolMasks, self.hiddenlayers, self.branchMultiplier, inp))\n",
    "        #use autograd to automatically differentiate error function\n",
    "        error_grad = Grad(error)\n",
    "        \n",
    "        inlen = len(inputlist)\n",
    "        outlen = len(outputlist)\n",
    "\n",
    "        if inlen != outlen:\n",
    "            Exception(\"number of input vectors (\"+str(inlen)+\") not equal not number of ouptut vectors (\"+str(outlen)+\")\")\n",
    "            \n",
    "        if alpha == 0.0:\n",
    "            raise(\"why is alpha zero?\")\n",
    "            \n",
    "        if type(batchsize) != int:\n",
    "            raise(\"Why is batchsize not an int?\")\n",
    "        \n",
    "        if batchsize == 0 or batchsize > inlen:\n",
    "            raise(\"batchsize of \"+str(batchsize)+\"is not allowed. Note than inputveclist has length \"+str(inlen))\n",
    "            \n",
    "        #just some error checks\n",
    "        \n",
    "        randindexlist = range(inlen)\n",
    "        start = time.time()\n",
    "        avgpercenttesterror = \"No test set\"\n",
    "        avgpercenttesterrorlist = []\n",
    "        \n",
    "        #using stochastic gradient descent training method\n",
    "        for epoch in xrange(epochs):\n",
    "            #random.shuffle(randindexlist)\n",
    "            #for batch in range(inlen/batchsize):\n",
    "            \n",
    "#                 low = batch * batchsize\n",
    "#                 upper = (batch + 1) * batchsize\n",
    "#                 if upper > inlen: upper = inlen \n",
    "                \n",
    "#                 total_Egradweights = None\n",
    "#                 total_Egradbiases = None\n",
    "                \n",
    "#                 for i in randindexlist[low:upper]:\n",
    "            for inp,outp in izip(inputlist,outputlist):\n",
    "                Egradws, Egradbs, Egadfws, Egradfbs = error_grad((self.weights, self.biases, \n",
    "                                                       self.finalweights, self.finalbiases), inp, outp) #formerly used indexes from randindexlist\n",
    "#                     if total_Egradweights:\n",
    "#                         total_Egradweights = [x + y for x,y in izip(Egradweights,total_Egradweights)]\n",
    "#                         total_Egradbiases = [x + y for x,y in izip(Egradbiases,total_Egradbiases)]\n",
    "#                     else:\n",
    "#                         total_Egradweights = Egradweights\n",
    "#                         total_Egradbiases = Egradbiases\n",
    "                \n",
    "#                 total_Egradweights = [x / (batchsize * 1.0) for x in total_Egradweights]\n",
    "#                 total_Egradbiases = [x / (batchsize * 1.0) for x in total_Egradbiases]\n",
    "                \n",
    "#                 self.weights = [curr-grad*alpha for curr, grad in izip(self.weights, total_Egradweights)]\n",
    "#                 self.biases = [curr-grad*alpha for curr, grad in izip(self.biases, total_Egradbiases)]\n",
    "                self.weights = [curr-grad*alpha for curr, grad in izip(self.weights, Egradws)]\n",
    "                self.biases = [curr-grad*alpha for curr, grad in izip(self.biases, Egradbs)]\n",
    "                self.finalweights = self.finalweights - alpha * Egradfws\n",
    "                self.finalbiases = self.finalbiases - alpha * Egradfbs\n",
    "            \n",
    "            if len(testinputlist) == len(testoutputlist) and len(testinputlist) != 0:\n",
    "                avgpercenttesterror = self.test(testinputlist, testoutputlist)\n",
    "                avgpercenttesterrorlist.append(avgpercenttesterror)\n",
    "            else:\n",
    "                print \"bad test set\"\n",
    "            \n",
    "            elapsed = time.time() - start\n",
    "            start = time.time()\n",
    "            if verbose:\n",
    "                print \"epoch: \" + str(epoch) + \"\\t percenterror: \" + str(avgpercenttesterror) + \"% \\t time elapsed this epoch: \" + str(elapsed) + \"s\"\n",
    "            \n",
    "        return (avgpercenttesterror, avgpercenttesterrorlist)\n",
    "\n",
    "# singleGenConsolidate([np.array([0,0,0]), np.array([0,1,2,3]), np.array([0,0,0])])\n",
    "testnet = nnet(10, [[lambda x: x + 1], [lambda x: x * 2]], 1, [np.array([0,1,2,3])], [np.array([1])], 100)\n",
    "testnet.genConsolidate()\n",
    "testnet.genWeights()\n",
    "numpyConsolidate(np.array([1,2,3]), [[0,2], [1]])\n",
    "print testnet.nfeedforward(np.array([0,1,2,3]))\n",
    "print testnet.feedforward(np.array([0,1,2,3]))\n",
    "# print mynet.consolidations\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "from theano import shared,config,function\n",
    "import itertools\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "# theano.config.exception_verbosity = \"high\"\n",
    "\n",
    "def flatten(mylist):\n",
    "    return list(itertools.chain.from_iterable(mylist))\n",
    "  \n",
    "\n",
    "\n",
    "class V2IndexedShared:\n",
    "    def __init__(self, atype):\n",
    "        self.myType = atype\n",
    "    \n",
    "    def fromList(self,D2List):\n",
    "        self.complete = shared(np.array(flatten(D2List)).astype(self.myType))\n",
    "        self.length = shared(len(D2List))\n",
    "        inds = [0]\n",
    "        for sublist in D2List:\n",
    "            inds.append(len(sublist) + inds[-1])\n",
    "        self.inds = shared(np.array(inds).astype('int32'))\n",
    "        return self\n",
    "\n",
    "    \n",
    "class V3IndexedShared:\n",
    "    def __init__(self,D3List, atype):\n",
    "        self.complete = shared(np.array(flatten(flatten(D3List))).astype(atype))\n",
    "#         self.complete = np.array(flatten(flatten(D3List))).astype(atype)\n",
    "\n",
    "        self.myType = atype\n",
    "        self.length = shared(len(D3List))\n",
    "        D2Inds = [0]\n",
    "        D3Inds = [0]\n",
    "        \n",
    "        for sublistOLists in D3List:\n",
    "            \n",
    "            for sublist in sublistOLists:\n",
    "                D2Inds.append(len(sublist) + D2Inds[-1])\n",
    "                \n",
    "            D3Inds.append(len(sublistOLists) + D3Inds[-1])\n",
    "            \n",
    "                \n",
    "        self.D2Inds = shared(np.array(D2Inds).astype('int32'))\n",
    "        self.D3Inds = shared(np.array(D3Inds).astype('int32'))\n",
    "        \n",
    "#         self.D2Inds = np.array(D2Inds).astype('int32')\n",
    "#         self.D3Inds = np.array(D3Inds).astype('int32')\n",
    "#         print D3Inds\n",
    "#         print D2Inds\n",
    "#         print np.array(flatten(flatten(D3List)))\n",
    "    \n",
    "\n",
    "def relu(x):\n",
    "    return T.maximum(x, 0)\n",
    "\n",
    "#instead of having nested lists of variable sizes, the following two classes implement either a list of lists and a lists of \n",
    "#lists of lists. It implements it by having a \"complete\" array, then a array of indexes for the beginning and end of the slices\n",
    "#of that array, then an array for the beginning and end of slices (of the slices array)\n",
    "\n",
    "\n",
    "def getSubV2(index, inds, complete):\n",
    "    return complete[inds[index]:inds[index + 1]]\n",
    "\n",
    "def getSubV2Check():\n",
    "    tind = T.iscalar('ind')\n",
    "    tinds = T.ivector('inds')\n",
    "    tcomp = T.vector('complete')\n",
    "    \n",
    "    nind = np.asscalar(np.array([0]).astype('int32'))\n",
    "    ninds = np.array([0,2,4]).astype('int32')\n",
    "    comp = np.array([0,1,2,3,4]).astype(theano.config.floatX)\n",
    "    \n",
    "    f = theano.function([tind, tinds, tcomp], getSubV2(tind, tinds, tcomp))\n",
    "    print f(nind,ninds,comp)\n",
    "getSubV2Check()\n",
    "def getV2Length(inds):\n",
    "    return inds.size -1\n",
    "\n",
    "def getSubV3(index, indinds, inds, complete):\n",
    "    subInds = inds[indinds[index] : indinds[index + 1] + 1]\n",
    "    return subInds, complete\n",
    "\n",
    "def getSubV3Check():\n",
    "    D3List = [[[0,1,2,], [3,4,5]], [[6,7,8], [9,10,11]]]\n",
    "    consolcomplete = [0,1,2,3,4,5,6,7,8,9,10,11]\n",
    "    consolinds = [0,3,6,9,12]\n",
    "    consolindinds = [0,2,4]\n",
    "    print getSubV3(1, consolindinds, consolinds, consolcomplete)\n",
    "    print consolinds[2:5]\n",
    "    t = V3IndexedShared(D3List, 'int32')\n",
    "    \n",
    "# getSubV3Check()\n",
    "\n",
    "#the following pair of functions implements consolidation of a tensor using theano scan -- not the fastest, but its inherently\n",
    "#difficult to vectorize.\n",
    "def singleConsol(tensor, indices):\n",
    "    return (T.choose(indices, tensor)).sum()\n",
    "\n",
    "def consolidateTensor(tensor, consolinds, consolcomplete):\n",
    "    irange = T.arange(getV2Length(consolinds))\n",
    "    consolidated, updates = theano.scan(fn = lambda ind, tens, coninds, concomp: singleConsol(tens, getSubV2(ind, coninds, concomp)),\n",
    "                                        sequences = irange,\n",
    "                                        non_sequences=[tensor, consolinds, consolcomplete])\n",
    "    return consolidated\n",
    "\n",
    "def consolidateTensorCheck():\n",
    "    x = T.vector('x')\n",
    "    inds = T.ivector('inds')\n",
    "    complete = T.ivector('complete')\n",
    "    y = consolidateTensor(x,inds,complete)\n",
    "    f = theano.function([x,inds,complete], y)\n",
    "    print f(np.array([1.0,2.0,4.0,8.0]).astype(theano.config.floatX), np.array([0,3,4]).astype('int32'), np.array([1,2,3,0]).astype('int32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "QSaXtAM_o8gB",
    "outputId": "e4de1289-9fd1-49fe-8413-9bf3e368acce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running initial singleGenConsolidate\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "starting to loop\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "first version took: 0.000830173492432\n",
      "looped\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "first version took: 0.000391006469727\n",
      "looped\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "first version took: 0.00020694732666\n",
      "looped\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "first version took: 0.00140285491943\n",
      "looped\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "first version took: 0.000326871871948\n",
      "looped\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "first version took: 0.000204086303711\n",
      "looped\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "first version took: 0.000639915466309\n",
      "looped\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "first version took: 0.000198125839233\n",
      "looped\n",
      "biased and relued: [0.00899616 0.16347228 0.03879589 0.11553556 0.11686028]\n",
      "biased and relued: [0.01339271 0.05498184 0.04917422 0.0313776  0.00737138]\n",
      "biased and relued: [0.01930777 0.00946476 0.02232764 0.05081137 0.03451739]\n",
      "biased and relued: [0.02504846 0.04387642 0.04046647 0.01305619 0.02613946]\n",
      "biased and relued: [0.02361935 0.03023243 0.0309939  0.02056288 0.02990696]\n",
      "biased and relued: [0.04519889 0.03830873 0.00702915 0.0395049  0.03040435]\n",
      "biased and relued: [0.03740117 0.01826369 0.0150778  0.02931827 0.0238862 ]\n",
      "biased and relued: [0.02669788 0.01304886 0.03881287 0.02929873 0.05036731]\n",
      "biased and relued: [0.00408057 0.04043392 0.0457932  0.01877569 0.04024897]\n",
      "[0.10703611 0.69719829 0.82710102 0.86150068]\n",
      "[array([0.00899616, 0.16347228, 0.03879589, 0.11553556, 0.11686028],\n",
      "      dtype=float32), array([0.01339271, 0.05498184, 0.04917423, 0.0313776 , 0.00737138],\n",
      "      dtype=float32), array([0.01930777, 0.00946476, 0.02232764, 0.05081137, 0.03451739],\n",
      "      dtype=float32), array([0.02504846, 0.04387642, 0.04046647, 0.01305619, 0.02613946],\n",
      "      dtype=float32), array([0.02361935, 0.03023244, 0.0309939 , 0.02056288, 0.02990696],\n",
      "      dtype=float32), array([0.04519889, 0.03830874, 0.00702915, 0.0395049 , 0.03040435],\n",
      "      dtype=float32), array([0.03740117, 0.01826369, 0.0150778 , 0.02931827, 0.0238862 ],\n",
      "      dtype=float32), array([0.02669788, 0.01304886, 0.03881286, 0.02929873, 0.05036731],\n",
      "      dtype=float32), array([0.00408057, 0.04043392, 0.0457932 , 0.01877569, 0.04024897],\n",
      "      dtype=float32)]\n",
      "[0.0000000e+00 0.0000000e+00 6.5989298e-13 5.3943856e-13 1.9063600e-13\n",
      " 1.3197860e-12 2.8595399e-13 1.2018880e-13]\n",
      "[8.3947348e-14 8.3947348e-14 4.4497652e-13 2.6602403e-12 6.3133879e-13\n",
      " 4.6229860e-13 3.1449130e-13 3.1449130e-13 3.1809725e-13 8.3819350e-13]\n",
      "[2.2845545e-12 2.2845545e-12 3.4533071e-12 3.4533071e-12 3.0885418e-12\n",
      " 2.2520895e-11 1.4370367e-11 1.5185738e-12 4.6298257e-13 1.1413743e-12]\n",
      "[4.2727114e-11 4.2727114e-11 3.0232743e-11 3.0232743e-11 7.1319894e-11\n",
      " 2.4051039e-10 5.4733346e-10 2.1387980e-10 1.1025694e-10 1.6870452e-10]\n",
      "[1.7984850e-09 1.7984850e-09 6.1801484e-09 6.1801484e-09 5.6998450e-09\n",
      " 6.5787917e-09 2.1225954e-09 2.1340696e-09 3.6818348e-09 2.5602274e-09]\n",
      "[6.9427628e-08 6.9427628e-08 1.1858969e-07 1.1858969e-07 1.2157659e-07\n",
      " 8.9284651e-09 5.9235825e-09 6.9416231e-08 1.1731298e-07 2.0492845e-07]\n",
      "[2.6160244e-06 2.6160244e-06 3.4473574e-06 3.4473574e-06 6.3254504e-07\n",
      " 3.5955222e-07 2.0207376e-06 5.6865201e-06 2.7360513e-06 1.1404685e-05]\n",
      "[1.5947141e-04 1.5947141e-04 4.0739862e-05 4.0739862e-05 3.3633263e-05\n",
      " 1.7589095e-05 3.4201392e-05 1.4392500e-04 5.3281685e-05 4.2318748e-04]\n",
      "[0.00325892 0.00325892 0.0008     0.0008     0.00237953 0.00087917\n",
      " 0.00066366 0.00874278 0.00308791 0.01789793]\n",
      "[0.0000000e+00 0.0000000e+00 6.5989298e-13 5.3943856e-13 1.9063600e-13\n",
      " 1.3197860e-12 2.8595399e-13 1.2018880e-13]\n",
      "[8.3947348e-14 8.3947348e-14 4.4497652e-13 2.6602403e-12 6.3133879e-13\n",
      " 4.6229860e-13 3.1449130e-13 3.1449130e-13 3.1809725e-13 8.3819350e-13]\n",
      "[2.2845545e-12 2.2845545e-12 3.4533071e-12 3.4533071e-12 3.0885418e-12\n",
      " 2.2520895e-11 1.4370367e-11 1.5185738e-12 4.6298257e-13 1.1413743e-12]\n",
      "[4.2727114e-11 4.2727114e-11 3.0232743e-11 3.0232743e-11 7.1319894e-11\n",
      " 2.4051039e-10 5.4733346e-10 2.1387980e-10 1.1025694e-10 1.6870452e-10]\n",
      "[1.7984850e-09 1.7984850e-09 6.1801484e-09 6.1801484e-09 5.6998450e-09\n",
      " 6.5787917e-09 2.1225954e-09 2.1340696e-09 3.6818348e-09 2.5602274e-09]\n",
      "[6.9427628e-08 6.9427628e-08 1.1858969e-07 1.1858969e-07 1.2157659e-07\n",
      " 8.9284651e-09 5.9235825e-09 6.9416231e-08 1.1731298e-07 2.0492845e-07]\n",
      "[2.6160244e-06 2.6160244e-06 3.4473574e-06 3.4473574e-06 6.3254504e-07\n",
      " 3.5955222e-07 2.0207376e-06 5.6865201e-06 2.7360513e-06 1.1404685e-05]\n",
      "[1.5947141e-04 1.5947141e-04 4.0739862e-05 4.0739862e-05 3.3633263e-05\n",
      " 1.7589095e-05 3.4201392e-05 1.4392500e-04 5.3281685e-05 4.2318748e-04]\n",
      "[0.00325892 0.00325892 0.0008     0.0008     0.00237953 0.00087917\n",
      " 0.00066366 0.00874278 0.00308791 0.01789793]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[numpy.ndarray,\n",
       " numpy.ndarray,\n",
       " numpy.ndarray,\n",
       " numpy.ndarray,\n",
       " numpy.ndarray,\n",
       " numpy.ndarray,\n",
       " numpy.ndarray,\n",
       " numpy.ndarray,\n",
       " numpy.ndarray]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this class is essentially the same as nnet above, except that I implemented it in Theano for speed. All of the derivatives are \n",
    "#explicitly calculated, as I wasn't able to get theano to differentiate it. A lot of the set up is actually accomplished by the \n",
    "#previous class that used numpy.\n",
    "    \n",
    "from random import shuffle\n",
    "\n",
    "class tnnet:\n",
    "    def __init__(self, resolution, functions, inputdimension, traindatainps, traindataoutps, testdatainps, testdataoutps, synapseThreshold, net = None):\n",
    "        \n",
    "        mynet = None\n",
    "        if net == None:\n",
    "            mynet = nnet(resolution, functions, inputdimension, traindatainps, traindataoutps, synapseThreshold)\n",
    "            mynet.genConsolidate()\n",
    "            mynet.genWeights()\n",
    "        else:\n",
    "            mynet = net\n",
    "        self.nnet = mynet\n",
    "        \n",
    "\n",
    "        self.sharedTrainingInps = shared(np.array(traindatainps).astype(theano.config.floatX))\n",
    "        self.sharedTrainingOutps = shared(np.array(traindataoutps).astype(theano.config.floatX))\n",
    "        self.sharedTestingInps = shared(np.array(testdatainps).astype(theano.config.floatX))\n",
    "        self.sharedTestingOutps = shared(np.array(testdataoutps).astype(theano.config.floatX))\n",
    "\n",
    "\n",
    "#         print \"weights: \" + str(mynet.weights)\n",
    "#         print \"biases: \" + str(mynet.biases)\n",
    "#         print mynet.feedforward(np.array([0,1,2,3]).astype(theano.config.floatX))\n",
    "#         inp_lengths = [len(consol) for consol in mynet.consolidations]\n",
    "#         inp_lengths = [datainps[0].size] + inp_lengths\n",
    "#         self.inp_lengths = np.array(inp_lengths).astype('int32')\n",
    "#         print \"inp_lengths: \" + str(inp_lengths)\n",
    "#         print \"dinp length: \" + str(datainps[0].size)\n",
    "#         print \"consolidations: \" + str(mynet.consolidations)\n",
    "        \n",
    "#         self.maxInp = np.amax(inp_lengths)\n",
    "#         self.maxPad = shared(np.array([0] * (np.amax(inp_lengths) - min(inp_lengths))).astype(theano.config.floatX))\n",
    "#         self.maxZeroes = shared(np.array([0.0] * self.maxInp).astype(theano.config.floatX))\n",
    "        \n",
    "#         initialPaddingLength = np.amax(inp_lengths) - datainps[0].size\n",
    "#         self.initialPadding = shared(np.array([0.0] * initialPaddingLength).astype(theano.config.floatX))\n",
    "#         self.inp_lengths = shared(self.inp_lengths)\n",
    "        \n",
    "        tweights = V2IndexedShared(theano.config.floatX)\n",
    "        tweights.fromList(mynet.weights)\n",
    "        self.weights = map(lambda x: shared(np.array(x).astype(theano.config.floatX)), mynet.weights)\n",
    "        \n",
    "        tbiases = V2IndexedShared(theano.config.floatX)\n",
    "        tbiases.fromList(mynet.biases)\n",
    "#         print tbiases.complete.get_value()\n",
    "        self.biases = map(lambda x: shared(np.array(x).astype(theano.config.floatX)), mynet.biases)\n",
    "    \n",
    "        tcons = V3IndexedShared(mynet.consolidations, 'int32')\n",
    "#         print \"final weights: \" + str(mynet.finalweights)\n",
    "        tfws = shared((mynet.finalweights).astype(theano.config.floatX))\n",
    "        tfbs = shared((mynet.finalbiases).astype(theano.config.floatX))\n",
    "        self.weightnum = mynet.weightnum\n",
    "        self.hiddenlayers = mynet.hiddenlayers\n",
    "        \n",
    "        self.consolMasks = []\n",
    "        self.dEdWsinverseConsols = []\n",
    "        self.oneMultipliers = []\n",
    "        \n",
    "        #this loop fulfills two important functions. First, it makes consolmasks from consolidation lists\n",
    "        #Second, it creates inverse consolidation lists, going from the next layer back to the original layer,\n",
    "        #which is crucial for backpropagation.\n",
    "        for layerConsols in mynet.consolidations:\n",
    "#             print \"initial \" + str(layerConsols)\n",
    "            maxInLength = max(map(len, layerConsols))\n",
    "            inLength = len(flatten(layerConsols))\n",
    "            extended = map(lambda l: l + [inLength] * (maxInLength - len(l)), layerConsols)\n",
    "#             print \"extended: \" + str(extended)\n",
    "            self.consolMasks.append(shared(np.array(extended).astype('int32')))\n",
    "            self.oneMultipliers.append(shared(np.array([1.0] * maxInLength).astype(theano.config.floatX)))\n",
    "            \n",
    "            flattened = flatten(layerConsols)\n",
    "            frame = [0] * len(flattened)\n",
    "            for i in range(len(layerConsols)):\n",
    "                for sub in layerConsols[i]:\n",
    "                    frame[sub] = i\n",
    "            \n",
    "            self.dEdWsinverseConsols.append(shared(np.array(frame).astype('int32')))\n",
    "        \n",
    "#         print self.nnet.consolidations[0]\n",
    "#         print self.dEdWsinverseConsols[0].get_value()\n",
    "            \n",
    "        \n",
    "        \n",
    "        inp = T.fvector('inp')\n",
    "#         paddedInp = T.concatenate([inp, self.initialPadding])\n",
    "        actualOutp = T.fvector('actualOutp')\n",
    "        alpha = T.fscalar('alpha')\n",
    "        \n",
    "        self.consolidations = map(lambda x: V2IndexedShared('int32').fromList(x), self.nnet.consolidations)\n",
    "        \n",
    "        self.winds = tweights.inds\n",
    "        self.ws = tweights.complete\n",
    "        self.binds = tbiases.inds\n",
    "        self.bs = tbiases.complete\n",
    "        self.consindinds = tcons.D3Inds\n",
    "        self.consinds = tcons.D2Inds\n",
    "        self.cons = tcons.complete\n",
    "        self.bMult = shared(np.asscalar(np.array([mynet.branchMultiplier]).astype('int32')))\n",
    "        self.fws = tfws\n",
    "        self.fbs = tfbs\n",
    "#         print \"weights: \" + '\\n'.join(map(str, self.nnet.weights))\n",
    "# #         print self.nnet.biases\n",
    "#         print \"inverse Consols: \" + '\\n'.join(map(lambda x: str(x.get_value().tolist()), self.dEdWsinverseConsols))\n",
    "#         print \"consols: \" + '\\n'.join(map(str, self.nnet.consolidations))\n",
    "        self.zeropad = shared(np.array([0.0]).astype(theano.config.floatX))\n",
    "        \n",
    "        self.bMultOnes = shared(np.array([1.0] * self.nnet.branchMultiplier).astype(theano.config.floatX))\n",
    "        \n",
    "        self.params = self.weights + self.biases + [self.fws, self.fbs]\n",
    "#         self.constparams = [self.consindinds, self.consinds, self.cons, self.winds, self.binds, self.bMult]\n",
    "        \n",
    "#         def singleCons(consInds, tens):\n",
    "#             asum, _ = theano.scan(fn = lambda i, tensor: tensor[i],\n",
    "#                                  sequences = consInds,\n",
    "#                                  non_sequences = tens)\n",
    "#             return asum.sum()\n",
    "        \n",
    "        \n",
    "#         def layer(ind, inpLength, inp):\n",
    "#             weights = getSubV2(ind, self.winds, self.ws)\n",
    "#             biases = getSubV2(ind, self.binds, self.bs)\n",
    "#             consolinds, consols = getSubV3(ind, self.consindinds, self.consinds, self.cons)\n",
    "#             inp = T.repeat(inp[0:inpLength], self.bMult)\n",
    "#             inp = weights * inp\n",
    "            \n",
    "#             #consolidation code\n",
    "#             numConsolidatedRange = T.arange(consolinds.size - 1)\n",
    "#             inp, _ = theano.scan(fn = lambda ind, x, coninds, concomp: singleCons(getSubV2(ind, coninds, concomp), x),\n",
    "#                                                 sequences = numConsolidatedRange,\n",
    "#                                                 non_sequences=[inp, consolinds, consols])\n",
    "#             inp = inp + biases\n",
    "#             inp = relu(inp)\n",
    "#             padding = self.maxPad[0 : self.maxInp - inp.size]\n",
    "#             inp = T.concatenate([inp, padding])\n",
    "#             return inp\n",
    "       \n",
    "        def layer(ind, x):\n",
    "            #get output of layer ind with input x\n",
    "            \n",
    "#             print \"in layer\"\n",
    "#             consolinds = self.consolidations[ind].inds\n",
    "#             consols = self.consolidations[ind].complete\n",
    "            \n",
    "            x = T.repeat(x, self.bMult) * self.weights[ind]\n",
    "            x = T.concatenate([x, T.zeros_like(x)])\n",
    "            x = (x.take(self.consolMasks[ind]).astype(theano.config.floatX)) #.sum(axis = 1)\n",
    "            x = T.dot(x, self.oneMultipliers[ind])\n",
    "# #             inp, _ = theano.map(fn = lambda i: inp[i],\n",
    "# #                                sequences = consols)\n",
    "# #             #consolidation code\n",
    "#             r = T.arange(consolinds.size - 1).astype(theano.config.floatX)\n",
    "#             for i in xrange(len(self.nnet.consolidations[ind])):\n",
    "#                 r = T.set_subtensor(r[i], x[consolinds[i]:consolinds[i + 1]].sum())\n",
    "#             numConsolidatedRange = T.arange(consolinds.size - 1).astype('int32')\n",
    "# #             inp2, _ = theano.map(fn = lambda i: inp1[consolinds[i]: consolinds[i + 1]].sum(),\n",
    "# #                                                 sequences = numConsolidatedRange)\n",
    "#             r, _ = theano.map(fn = lambda i, x: x[consolinds[i]: consolinds[i+1]].sum(),\n",
    "#                                                 sequences = numConsolidatedRange,\n",
    "#                                                 non_sequences=[x])\n",
    "            return theano.tensor.nnet.relu(x + self.biases[ind])\n",
    "#             return r\n",
    "\n",
    "        def gradLayer(ind, nextdEdInputs, layerOutput): #returns (dEdWs, dEdBs, newdEdInputs)\n",
    "            expandedLayerOutput = T.repeat(layerOutput, self.bMult)\n",
    "            inverse = self.dEdWsinverseConsols[ind]\n",
    "            inverseddEdInputs = nextdEdInputs.take(inverse)\n",
    "            dEdWs = expandedLayerOutput * inverseddEdInputs\n",
    "            dEdBs = nextdEdInputs\n",
    "            #upt to here correct\n",
    "            \n",
    "            dOutsdIns = T.gt(layerOutput, T.zeros_like(layerOutput))\n",
    "            dOutsdIns = T.cast(dOutsdIns, 'float32')\n",
    "            \n",
    "            dEdConnections = self.weights[ind] * inverseddEdInputs\n",
    "            dEdConnectionGroups = dEdConnections.reshape((dEdConnections.size // self.bMult, self.bMult))\n",
    "            dEdOuts = T.dot(dEdConnectionGroups, self.bMultOnes) #could need to be axis 1\n",
    "            \n",
    "            newdEdInputs = dEdOuts * dOutsdIns\n",
    "            \n",
    "            return (dEdWs, dEdBs, newdEdInputs)\n",
    "        \n",
    "        def intermediateLoop(z):\n",
    "            ret = []\n",
    "            for i in range(self.hiddenlayers):\n",
    "                z = layer(i, z)\n",
    "                ret.append(z.copy())\n",
    "            \n",
    "            return ret\n",
    "        \n",
    "        def gradLoop(dEdIn, layerOutputs):\n",
    "            dEdWs = []\n",
    "            dEdBs = []\n",
    "            for k in reversed(range(self.hiddenlayers)):\n",
    "                newdEdWs, newdEdBs, dEdIn = gradLayer(k, dEdIn, layerOutputs[k])\n",
    "                dEdWs.append(newdEdWs)\n",
    "                dEdBs.append(newdEdBs)\n",
    "            \n",
    "            return dEdWs, dEdBs\n",
    "        \n",
    "        def myGrad(theta, actualOutp):\n",
    "            #get gradient given input (theta) and the target output (actualOutp)\n",
    "            \n",
    "            #get all layer outputs\n",
    "            outputs = intermediateLoop(theta)\n",
    "            \n",
    "            #list of all outputs, including input layer \"outputs\"\n",
    "            outputs = [theta] + outputs\n",
    "            \n",
    "            #calculate final output\n",
    "            last = T.dot(outputs[-1], self.fws)\n",
    "            last = last + self.fbs\n",
    "            last = theano.tensor.nnet.relu(last)\n",
    "            \n",
    "            #get error\n",
    "            difference = last - actualOutp\n",
    "            err = T.dot(difference, difference)\n",
    "            \n",
    "            #get final layer derivative\n",
    "            finaldOutdIn = T.gt(last, T.zeros_like(last))\n",
    "            finaldOutdIn = T.cast(finaldOutdIn, 'float32')\n",
    "            \n",
    "            #get derivative of error with respect to last layer inputs\n",
    "            initdEdIn = finaldOutdIn * (last - actualOutp)\n",
    "            dEdFbs = initdEdIn   \n",
    "            \n",
    "            \n",
    "            initdEdInshuffled = initdEdIn.dimshuffle(('x',0))\n",
    "            finalStructuredLayerOut = outputs[-1]\n",
    "            finalStructuredLayerOutShuffled = finalStructuredLayerOut.dimshuffle((0,'x'))\n",
    "            \n",
    "            dEdFws = finalStructuredLayerOutShuffled * initdEdInshuffled\n",
    "            \n",
    "            \n",
    "            finalStructuredLayerdOutdIn = T.gt(finalStructuredLayerOut, T.zeros_like(finalStructuredLayerOut))\n",
    "            finalStructuredLayerdOutdIn = T.cast(finalStructuredLayerdOutdIn, 'float32')\n",
    "            \n",
    "            finalStructuredLayerdEdOut = T.dot(initdEdIn, self.fws.T)\n",
    "            \n",
    "            finalStructuredLayerdEdIn = finalStructuredLayerdOutdIn * finalStructuredLayerdEdOut\n",
    "            #up to here is correct\n",
    "\n",
    "            dEdWs, dEdBs = gradLoop(finalStructuredLayerdEdIn, outputs)\n",
    "            \n",
    "            return err, list(reversed(dEdWs)), list(reversed(dEdBs)), dEdFws, dEdFbs #, list(reversed(dEdIns)),\n",
    "            \n",
    "            \n",
    "        final = T.fvector()\n",
    "        def loop(z):\n",
    "            ret = T.fvector()\n",
    "            for i in range(self.hiddenlayers):\n",
    "                z = layer(i, z)\n",
    "                ret = z\n",
    "            return ret\n",
    "        finalHiddenOutput = loop(inp)\n",
    "        final = T.dot(finalHiddenOutput, self.fws)\n",
    "        final = final + self.fbs\n",
    "        final = theano.tensor.nnet.relu(final)\n",
    "        \n",
    "        #Declare theano functions for full classifaction (including end relu linerar classifier)\n",
    "        self.classify = theano.function([inp], final)\n",
    "        self.partialClassify = theano.function([inp], finalHiddenOutput)\n",
    "        \n",
    "        index = T.iscalar()\n",
    "        \n",
    "        self.partialClassifyTraining = theano.function(inputs= [index], outputs = finalHiddenOutput,\n",
    "                                                       givens = {\n",
    "                                                                        inp : self.sharedTrainingInps[index],\n",
    "                                                                    } )\n",
    "        self.partialClassifyTesting = theano.function(inputs=[index], outputs = finalHiddenOutput,\n",
    "                                                     givens = {\n",
    "                                                         inp : self.sharedTestingInps[index]\n",
    "                                                     })\n",
    "        \n",
    "        diff = final - actualOutp\n",
    "        squared = 0.5 * T.dot(diff, diff)\n",
    "\n",
    "#         print self.classify(np.array([0,1,2,3]).astype(theano.config.floatX))\n",
    "\n",
    "        index = T.iscalar()\n",
    "\n",
    "        squaredError, wgrads, bgrads, fwsgrads, fbsgrads = myGrad(inp, actualOutp)\n",
    "#         mygradients = myGrad(inp, actualOutp)\n",
    "        self.realGrad = theano.function(inputs = [inp, actualOutp], outputs = T.grad(squared, self.weights))\n",
    "        self.mygrads = theano.function(inputs = [inp, actualOutp], outputs = wgrads)\n",
    "        \n",
    "        #concatenate lists of the gradients so as to iteratively modify them -- don't worry, I'm not just adding them together\n",
    "        gradients = wgrads + bgrads + [fwsgrads, fbsgrads]\n",
    "        \n",
    "#         realgrads = T.grad(squared, self.params)\n",
    "#         realUpdates = OrderedDict((p, p - alpha * g) for p, g in zip(self.params, realgrads))\n",
    "        param_Updates = OrderedDict((p, p - alpha * g) for p, g in zip(self.params, gradients))\n",
    "        \n",
    "        self.intermediates = theano.function([inp], intermediateLoop(inp))\n",
    "        \n",
    "        self.train = theano.function(inputs = [index, alpha],\n",
    "                                                                    outputs = squaredError,\n",
    "                                                                    updates = param_Updates,\n",
    "                                                                    givens = {\n",
    "                                                                        inp : self.sharedTrainingInps[index],\n",
    "                                                                        actualOutp: self.sharedTrainingOutps[index]\n",
    "                                                                    })\n",
    "#         self.realtrain = theano.function(inputs = [index, alpha],\n",
    "#                                                                     outputs = squared,\n",
    "#                                                                     updates = realUpdates,\n",
    "#                                                                     givens = {\n",
    "#                                                                         inp : self.sharedTrainingInps[index],\n",
    "#                                                                         actualOutp: self.sharedTrainingOutps[index]\n",
    "#                                                                     })\n",
    "        self.test = theano.function(inputs = [index],\n",
    "            outputs = final,\n",
    "            givens = {\n",
    "                inp : self.sharedTestingInps[index]\n",
    "            })\n",
    "    \n",
    "    def descend(self, alpha, epochs, trainingInps, trainingOutps, testingInps, testingOutps, verbose):\n",
    "        training = zip(trainingInps, trainingOutps)\n",
    "        testing = zip(testingInps, testingOutps)\n",
    "        testLen = len(testing)\n",
    "        trainLen = len(trainingInps)\n",
    "        indorder = range(trainLen)\n",
    "        testingAccuracies = []\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            print \"starting epoch...\"\n",
    "            start = time.time()\n",
    "            shuffle(indorder)\n",
    "            for j in indorder:\n",
    "                self.train(j, alpha)\n",
    "            \n",
    "            testingAccuracy = 0.0\n",
    "            for j in range(len(testingOutps)):\n",
    "                if np.argmax(self.test(j)) == np.argmax(testingOutps[j]):\n",
    "                    testingAccuracy += 1.0\n",
    "            # for (testInp, testOutp) in testing:\n",
    "            #     if np.argmax(self.classify(testInp)) == np.argmax(testOutp):\n",
    "            #         testingAccuracy += 1.0\n",
    "                    \n",
    "            percentTestingAccuracy = testingAccuracy / testLen * 100.0\n",
    "            testingAccuracies.append(percentTestingAccuracy)\n",
    "            end = time.time()\n",
    "            if verbose:\n",
    "                print \"epoch \" + str(i + 1) + \" -- testing accuracy : \" + str(percentTestingAccuracy) + \" duration: \" + str(end - start) + \"s\"\n",
    "        \n",
    "        return max(testingAccuracies), testingAccuracies\n",
    "            \n",
    "        \n",
    "tn = tnnet(10, [[lambda x: x + 1], [lambda x: x * 2]], 1, [np.array([0,1,2,3])], [np.array([1,2,3,4])],  [np.array([1,2,3,4])],  [np.array([1,2,3,4])], 100)\n",
    "print tn.nnet.feedforward(np.array([0,1,2,3]))\n",
    "print tn.intermediates(np.array([0,1,2,3]).astype(theano.config.floatX))\n",
    "# print tn.nnet.weights\n",
    "# print tn.nnet.biases\n",
    "x = np.array([0,1,2,3]).astype(theano.config.floatX)\n",
    "classed = tn.classify(np.array([0,1,2,3]).astype(theano.config.floatX))\n",
    "# print '\\n'.join(map(str,classed))\n",
    "# diff = x * 0.5 - classed\n",
    "# print np.dot(diff, diff)\n",
    "# print tn.classify(np.array([0,1,2,3]).astype(theano.config.floatX))\n",
    "print '\\n'.join(map(str, tn.realGrad(x, x * 0.33)))\n",
    "print '\\n'.join(map(str, tn.mygrads(x, x*0.33)))\n",
    "map(type, tn.mygrads(x, x * 0.33))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "nj8CfYB8o8gQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "lDEgKax3o8gb",
    "outputId": "1c206e12-9712-4c4d-ab70-1687de132e4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating\n",
      "running initial singleGenConsolidate\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "starting to loop\n",
      "branchmultiplier: 25\n",
      "weights length: 19600\n",
      "average number of connections per neuron by layer: [1.0]\n",
      "spacial dimension: 3\n",
      "branching by layer: [10, 7, 8]\n",
      "beginning training\n"
     ]
    }
   ],
   "source": [
    "import deap.gp as gp\n",
    "import time\n",
    "import sys\n",
    "import sklearn.svm as svm\n",
    "sys.setrecursionlimit(1500)\n",
    "\n",
    "def mnistevaluate(individual):\n",
    "    weights = []\n",
    "    biases = []\n",
    "    branching = 0\n",
    "    consolidations = []\n",
    "    fws = []\n",
    "    fbs = []\n",
    "    hiddenlayers = 0\n",
    "    weightnum = 0\n",
    "    branching = 0\n",
    "    \n",
    "    print \"evaluating\"\n",
    "    funcs = []\n",
    "    for dimlist in individual:\n",
    "        newDimlist = []\n",
    "        for tree in dimlist:\n",
    "#             print gp.stringify(tree)\n",
    "            f = gp.compile(tree, pset)\n",
    "            newDimlist.append(f)\n",
    "        funcs.append(newDimlist)\n",
    "    \n",
    "    res = 20\n",
    "    tnet = tnnet(res, funcs, 2, trainingimgs, traininglabels, testingimgs, testinglabels, 200000)\n",
    "    mynet = tnet.nnet\n",
    "    weights = mynet.weights\n",
    "    biases = mynet.biases\n",
    "    branching = mynet.branchMultiplier\n",
    "    consolidations = mynet.consolidations\n",
    "    fws = mynet.finalweights\n",
    "    fbs = mynet.finalbiases\n",
    "    hiddenlayers = mynet.hiddenlayers\n",
    "    weightnum = mynet.weightnum\n",
    "    print \"branchmultiplier: \" + str(mynet.branchMultiplier)\n",
    "    print \"weights length: \" + str(len(flatten(mynet.weights)))\n",
    "#     print \"consolidations lengths\" + str(map(len, mynet.consolidations))\n",
    "    layerDensities = []\n",
    "    prevlayerLength = trainingimgs[0].size\n",
    "    for layer in mynet.weights:\n",
    "        layerLength = len(layer)\n",
    "        branched = prevlayerLength * mynet.branchMultiplier\n",
    "        layerDensities.append((1.0 * branched) / layerLength)\n",
    "        prevlayerLength = layerLength\n",
    "    print \"average number of connections per neuron by layer: \" + str(layerDensities)\n",
    "    print \"spacial dimension: \" + str(len(funcs))\n",
    "    print \"branching by layer: \" + str(map(len, funcs))\n",
    "    print \"beginning training\"\n",
    "    testStart = time.time()\n",
    "    x = tnet.train(0, 0.05)\n",
    "    print \"trained in: \" + str(time.time() - testStart)\n",
    "    print x\n",
    "    print tnet.classify(trainingimgs[0])\n",
    "#     testStart = time.time()\n",
    "#     x = tnet.realtrain(0, 0.05)\n",
    "    print \"autograd trained in: \" + str(time.time() - testStart)\n",
    "    \n",
    "    avgpercenttestAccuracy, avgpercenttestAccuracylist = tnet.descend(0.02, 5, trainingimgs,traininglabels, testingimgs, testinglabels, True)\n",
    "    return avgpercenttestAccuracy\n",
    "\n",
    "def mnistEvaluateRandomWeights(individual):\n",
    "    weights = []\n",
    "    biases = []\n",
    "    branching = 0\n",
    "    consolidations = []\n",
    "    fws = []\n",
    "    fbs = []\n",
    "    hiddenlayers = 0\n",
    "    weightnum = 0\n",
    "    branching = 0\n",
    "    \n",
    "    print \"evaluating\"\n",
    "    funcs = []\n",
    "    for dimlist in individual:\n",
    "        newDimlist = []\n",
    "        for tree in dimlist:\n",
    "#             print gp.stringify(tree)\n",
    "            f = gp.compile(tree, pset)\n",
    "            newDimlist.append(f)\n",
    "        funcs.append(newDimlist)\n",
    "    \n",
    "    res = 20\n",
    "    tnet = tnnet(res, funcs, 2, trainingimgs, traininglabels, testingimgs, testinglabels, 50000)\n",
    "    mynet = tnet.nnet\n",
    "    weights = mynet.weights\n",
    "    biases = mynet.biases\n",
    "    branching = mynet.branchMultiplier\n",
    "    consolidations = mynet.consolidations\n",
    "    fws = mynet.finalweights\n",
    "    fbs = mynet.finalbiases\n",
    "    hiddenlayers = mynet.hiddenlayers\n",
    "    weightnum = mynet.weightnum\n",
    "    print \"branchmultiplier: \" + str(mynet.branchMultiplier)\n",
    "    print \"weights length: \" + str(len(flatten(mynet.weights)))\n",
    "#     print \"consolidations lengths\" + str(map(len, mynet.consolidations))\n",
    "    layerDensities = []\n",
    "    prevlayerLength = trainingimgs[0].size\n",
    "    for layer in mynet.weights:\n",
    "        layerLength = len(layer)\n",
    "        branched = prevlayerLength * mynet.branchMultiplier\n",
    "        layerDensities.append((1.0 * branched) / layerLength)\n",
    "        prevlayerLength = layerLength\n",
    "    print \"average number of connections per neuron by layer: \" + str(layerDensities)\n",
    "    print \"spacial dimension: \" + str(len(funcs))\n",
    "    print \"branching by layer: \" + str(map(len, funcs))\n",
    "    print \"beginning training\"\n",
    "    testStart = time.time()\n",
    "    \n",
    "    #generate dataset with random weights\n",
    "    randomWeightsTrainingOutputs = []\n",
    "    for i in range(len(trainingimgs)):\n",
    "        randomWeightsTrainingOutputs.append(tnet.partialClassifyTraining(i))\n",
    "        \n",
    "    randomWeightsTestingOutputs = []\n",
    "    for i in range(len(testingimgs)):\n",
    "        randomWeightsTestingOutputs.append(tnet.partialClassifyTesting(i))\n",
    "        \n",
    "    mySVMclassifier = svm.LinearSVC()\n",
    "    \n",
    "    #svm doesn't want vectors as the class, just scalars\n",
    "    mySVMclassifier.fit(randomWeightsTrainingOutputs, train_labels)\n",
    "    \n",
    "    accuracy = mySVMclassifier.score(randomWeightsTestingOutputs, test_labels)\n",
    "    print \"SVM Accuracy \" + str(accuracy)\n",
    "    \n",
    "    return score\n",
    "    \n",
    "\n",
    "evolve(mnistEvaluateRandomWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "sVPrn32Io8go",
    "outputId": "78405ad5-4013-41d4-8530-4fe2b807e272"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4)\n",
      "(100,)\n",
      "[1 1 0 0 0 0 0 1 0 1 0 1 1 1 1 0 0 0 1 1 1 0 0 1 0 1 1 1 0 1 1 1 0 1 1 1 0\n",
      " 1 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 1 0 0 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0\n",
      " 1 0 1 0 0 1 1 0 1 1 0 1 1 0 1 0 0 1 1 0 1 1 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_features=4, random_state=0)\n",
    "print str(X.shape)\n",
    "print str(y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "NeYABakdo8g8",
    "outputId": "6ee523b4-f91c-499c-80c0-ef7a74d67c9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting theano net instance...\n"
     ]
    },
    {
     "ename": "UnusedInputError",
     "evalue": "theano.function was asked to create a function computing outputs given certain inputs, but the provided input variable at index 0 is not part of the computational graph needed to compute the outputs: inp.\nTo make this error into a warning, you can pass the parameter on_unused_input='warn' to theano.function. To disable it completely, use on_unused_input='ignore'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnusedInputError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-868a88d1e99c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m\"numpy classified in \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtestStart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mtnetFromParams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbiases\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfws\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfbs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsolidations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhiddenlayers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweightnum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbranching\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-868a88d1e99c>\u001b[0m in \u001b[0;36mtnetFromParams\u001b[1;34m(weights, biases, fws, fbs, consolidations, hiddenlayers, weightnum, branching)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbranchingmultiplier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbranching\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m\"starting theano net instance...\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mmytnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtnnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainingimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraininglabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestingimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestinglabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mtestStart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmytnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainingimgs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-a7fa26851401>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, resolution, functions, inputdimension, traindatainps, traindataoutps, testdatainps, testdataoutps, synapseThreshold, net)\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[0mfinal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassify\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m \u001b[1;31m#         print self.classify(np.array([0,1,2,3]).astype(theano.config.floatX))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/theano/compile/function.pyc\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[0;32m    318\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m                    output_keys=output_keys)\n\u001b[0m\u001b[0;32m    321\u001b[0m     \u001b[1;31m# We need to add the flag check_aliased inputs if we have any mutable or\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[1;31m# borrowed used defined inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/theano/compile/pfunc.pyc\u001b[0m in \u001b[0;36mpfunc\u001b[1;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[0;32m    477\u001b[0m                          \u001b[0maccept_inplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_inplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    478\u001b[0m                          \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 479\u001b[1;33m                          output_keys=output_keys)\n\u001b[0m\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36morig_function\u001b[1;34m(inputs, outputs, mode, accept_inplace, name, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[0;32m   1774\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1775\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1776\u001b[1;33m                    \u001b[0moutput_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1777\u001b[0m             defaults)\n\u001b[0;32m   1778\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, mode, accept_inplace, function_builder, profile, on_unused_input, fgraph, output_keys)\u001b[0m\n\u001b[0;32m   1413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1414\u001b[0m         \u001b[1;31m# Check if some input variables are unused\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1415\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_unused_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon_unused_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m         \u001b[1;31m# Make a list of (SymbolicInput|SymblicInputKits, indices,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m_check_unused_inputs\u001b[1;34m(self, inputs, outputs, on_unused_input)\u001b[0m\n\u001b[0;32m   1551\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mon_unused_input\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'raise'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1552\u001b[0m                     raise UnusedInputError(msg % (inputs.index(i),\n\u001b[1;32m-> 1553\u001b[1;33m                                                   i.variable, err_msg))\n\u001b[0m\u001b[0;32m   1554\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1555\u001b[0m                     raise ValueError(\"Invalid value for keyword \"\n",
      "\u001b[1;31mUnusedInputError\u001b[0m: theano.function was asked to create a function computing outputs given certain inputs, but the provided input variable at index 0 is not part of the computational graph needed to compute the outputs: inp.\nTo make this error into a warning, you can pass the parameter on_unused_input='warn' to theano.function. To disable it completely, use on_unused_input='ignore'."
     ]
    }
   ],
   "source": [
    "def tnetFromParams(weights, biases, fws, fbs, consolidations, hiddenlayers, weightnum, branching):\n",
    "    frame = nnet(10, [[lambda x: x + 1], [lambda x: x * 2]], 1, [np.array([0,1,2,3])], [np.array([1])], 100)\n",
    "    frame.weights = weights\n",
    "    frame.biases = biases\n",
    "    frame.finalweights = np.array(fws).astype(theano.config.floatX)\n",
    "    frame.finalbiases = np.array(fbs).astype(theano.config.floatX)\n",
    "    frame.consolidations = consolidations\n",
    "    frame.hiddenlayers = hiddenlayers\n",
    "    frame.weightnum = weightnum\n",
    "    frame.branchingmultiplier = branching\n",
    "    print \"starting theano net instance...\"\n",
    "    mytnet = tnnet(10, [[lambda x: x + 1], [lambda x: x * 2]], 1, trainingimgs, traininglabels, testingimgs, testinglabels, 5000, net = frame)\n",
    "    testStart = time.time()\n",
    "    x = mytnet.classify(trainingimgs[0])\n",
    "    print \"classified in \" + str(time.time() - testStart)\n",
    "    testStart = time.time()\n",
    "    x = frame.feedforward(trainingimgs[0])\n",
    "    print \"numpy classified in \" + str(time.time() - testStart)\n",
    "\n",
    "tnetFromParams(weights, biases, fws, fbs, consolidations, hiddenlayers, weightnum, branching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "yEp_G79Jo8hM",
    "outputId": "c5d71b76-ff5e-435a-c958-ef090f8006f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 0.752302922028\n",
      "Cost: 0.234828531853\n",
      "Cost: 0.217997165391\n",
      "Cost: 0.176582778796\n",
      "Cost: 0.0941889559431\n",
      "Cost: 0.0547008715418\n",
      "Cost: 0.0227962112237\n",
      "Cost: 0.0103721161976\n",
      "Cost: 0.00631427914256\n",
      "Cost: 0.00444667437915\n",
      "Cost: 0.00339910571615\n",
      "Cost: 0.00273639533448\n",
      "Cost: 0.00228238999109\n",
      "Cost: 0.00195317405859\n",
      "Cost: 0.00170428799655\n",
      "Cost: 0.00150985199376\n",
      "Cost: 0.00135402741352\n",
      "Cost: 0.00122653983734\n",
      "Cost: 0.00112027524709\n",
      "Cost: 0.00103046853549\n",
      "0.971243725343\n",
      "0.0324757818475\n",
      "0.97118115104\n",
      "0.0308740290756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 970 (CNMeM is disabled, cuDNN not available)\n"
     ]
    }
   ],
   "source": [
    "import theano.tensor.nnet as nnet\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "import numpy as np\n",
    "x = T.dvector()\n",
    "y = T.dscalar()\n",
    "def layer(x, w):\n",
    "    b = np.array([1], dtype=theano.config.floatX)\n",
    "    new_x = T.concatenate([x, b])\n",
    "    m = T.dot(w.T, new_x) #theta1: 3x3 * x: 3x1 = 3x1 ;;; theta2: 1x4 * 4x1\n",
    "    h = nnet.sigmoid(m)\n",
    "    return h\n",
    "def grad_desc(cost, theta):\n",
    "    alpha = 0.1 #learning rate\n",
    "    return theta - (alpha * T.grad(cost, wrt=theta))\n",
    "theta1 = theano.shared(np.array(np.random.rand(3,3), dtype=theano.config.floatX)) # randomly initialize\n",
    "theta2 = theano.shared(np.array(np.random.rand(4,1), dtype=theano.config.floatX))\n",
    "hid1 = layer(x, theta1) #hidden layer\n",
    "out1 = T.sum(layer(hid1, theta2)) #output layer\n",
    "fc = (out1 - y)**2 #cost expression\n",
    "\n",
    "\n",
    "cost = theano.function(inputs=[x, y], outputs=fc, updates=[\n",
    "        (theta1, grad_desc(fc, theta1)),\n",
    "        (theta2, grad_desc(fc, theta2))])\n",
    "run_forward = theano.function(inputs=[x], outputs=out1)\n",
    "inputs = np.array([[0,1],[1,0],[1,1],[0,0]]).reshape(4,2) #training data X\n",
    "exp_y = np.array([1, 1, 0, 0]) #training data Y\n",
    "cur_cost = 0\n",
    "for i in range(10000):\n",
    "    for k in range(len(inputs)):\n",
    "        cur_cost = cost(inputs[k], exp_y[k]) #call our Theano-compiled cost function, it will auto update weights\n",
    "    if i % 500 == 0: #only print the cost every 500 epochs/iterations (to save space)\n",
    "        print('Cost: %s' % (cur_cost,))\n",
    "        \n",
    "\n",
    "\n",
    "#Training done! Let's test it out\n",
    "print(run_forward([0,1]))\n",
    "print(run_forward([1,1]))\n",
    "print(run_forward([1,0]))\n",
    "print(run_forward([0,0]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3b6BDwT7o8hg",
    "outputId": "76a1e4e7-f4cf-411b-e5f3-1882464400a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GpuElemwise{exp,no_inplace}(<CudaNdarrayType(float32, vector)>), HostFromGpu(GpuElemwise{exp,no_inplace}.0)]\n",
      "Looping 1000 times took 0.332850 seconds\n",
      "Result is [ 1.23178029  1.61879349  1.52278066 ...,  2.20771813  2.29967761\n",
      "  1.62323296]\n",
      "Used the gpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 970 (CNMeM is disabled, cuDNN not available)\n"
     ]
    }
   ],
   "source": [
    "from theano import function, config, shared, sandbox\n",
    "import theano.tensor as T\n",
    "import numpy\n",
    "import time\n",
    "\n",
    "vlen = 10 * 30 * 768  # 10 x #cores x # threads per core\n",
    "iters = 1000\n",
    "\n",
    "rng = numpy.random.RandomState(22)\n",
    "x = shared(numpy.asarray(rng.rand(vlen), config.floatX))\n",
    "f = function([], T.exp(x))\n",
    "print(f.maker.fgraph.toposort())\n",
    "t0 = time.time()\n",
    "for i in range(iters):\n",
    "    r = f()\n",
    "t1 = time.time()\n",
    "print(\"Looping %d times took %f seconds\" % (iters, t1 - t0))\n",
    "print(\"Result is %s\" % (r,))\n",
    "if numpy.any([isinstance(x.op, T.Elemwise) for x in f.maker.fgraph.toposort()]):\n",
    "    print('Used the cpu')\n",
    "else:\n",
    "    print('Used the gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "ekPuNdbUo8h7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3G-IDP2bo8iK",
    "outputId": "e1f99a3d-02a6-4232-8845-70c8c603618c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  2.,  1.,  4.], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = T.fvector()\n",
    "y = x\n",
    "y = T.set_subtensor(y[3], 1)\n",
    "out = y\n",
    "f = theano.function([x], out)\n",
    "f(np.array(range(5)).astype(theano.config.floatX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "a1MNNkCvo8iW",
    "outputId": "86b58a00-20e5-49b1-a6dc-545994854e51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2,  4,  4,  6,  6, 10, 10,  8,  8, 12]),\n",
       " array([1, 2, 3, 4, 5, 6]),\n",
       " array([  3.,   5.,   8.,   9.,  10.]))"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = np.array([0.0,0.0,0.0])\n",
    "ws = np.array([1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\n",
    "dEdIns = np.array([1,2,3,4,5,6])\n",
    "prevOut = np.array([2,2,2,2,2])\n",
    "bMult = 2\n",
    "bMultOnes = np.array([1.0,1.0])\n",
    "\n",
    "layerConsols = [[0], [1,2], [3,4], [7,8], [5,6], [9]]\n",
    "flattened = flatten(layerConsols)\n",
    "inverseConsols = [0] * len(flattened)\n",
    "for i in range(len(layerConsols)):\n",
    "    for sub in layerConsols[i]:\n",
    "        inverseConsols[sub] = i\n",
    "\n",
    "inverseConsols = np.array([0,1,1,2,2,4,4,3,3,5])\n",
    "\n",
    "    \n",
    "def gradLayer(nextdEdInputs, layerOutput): #returns (dEdWs, dEdBs, newdEdInputs)\n",
    "        expandedLayerOutput = np.repeat(layerOutput, bMult)\n",
    "        inverseddEdInputs = nextdEdInputs.take(inverseConsols)\n",
    "        dEdWs = expandedLayerOutput * inverseddEdInputs\n",
    "        dEdBs = nextdEdInputs\n",
    "        #upt to here correct\n",
    "        def foo(x):\n",
    "            if x >0.0:\n",
    "                return 1.0\n",
    "            else:\n",
    "                return 0.0\n",
    "        gtCast = np.vectorize(foo)\n",
    "#         dOutsdIns = np.gt(layerOutput, np.zeros_like(layerOutput))\n",
    "#         dOutsdIns = np.cast(dOutsdIns, 'float32')\n",
    "\n",
    "        dOutsdIns = gtCast(layerOutput)\n",
    "        dEdConnections = ws * inverseddEdInputs\n",
    "        dEdConnectionGroups = dEdConnections.reshape((dEdConnections.size // bMult, bMult))\n",
    "        dEdOuts = np.dot(dEdConnectionGroups, bMultOnes) #could need to be axis 1\n",
    "\n",
    "        newdEdInputs = dEdOuts * dOutsdIns\n",
    "\n",
    "        return (dEdWs, dEdBs, newdEdInputs)\n",
    "gradLayer(dEdIns, prevOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "M-PVWbN1o8ir"
   },
   "outputs": [],
   "source": [
    "x = np.array(range(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hcPuP7cAo8iz",
    "outputId": "f6336096-b5f9-4c2d-e44d-e662951cee47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [3, 4, 5]])"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape((2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Fr91u3DHo8i_"
   },
   "outputs": [],
   "source": [
    "import numerai\n",
    "trainingfeats, traininglabels, testingfeats, testinglabels = numerai.readTraining()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "5pIuvsvao8jE",
    "outputId": "334b69d7-dfb4-4693-a26d-2bc06017f70d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testingfeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "zSHm_uoUo8jP",
    "outputId": "23988138-fe8b-4a6c-e3b8-e7b4d0f19050"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "tXkvywWyo8jZ"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm evolve.pyc\n",
    "rm fulcrum.pyc\n",
    "rm fractalNetwork2.pyc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ImKcWwlHo8jn",
    "outputId": "d34e1c0b-9a3c-4f1a-87c9-d1761ad389af"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'run'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-a940d54d3ba1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfulcrum\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfulcrum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'module' object has no attribute 'run'"
     ]
    }
   ],
   "source": [
    "import fulcrum\n",
    "fulcrum.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Uzw4trTho8j0",
    "outputId": "bdd00cdb-ec65-4beb-fadf-484cecc5dc8c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 == 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "e5asE65Xo8kA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "Neuro120fractal.ipynb",
   "provenance": [
    {
     "file_id": "0B-aDu7AYJQFwS0Y4WFdUNGtmRlk",
     "timestamp": 1523566751533
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python [conda env:theano_p27]",
   "language": "python",
   "name": "conda-env-theano_p27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
