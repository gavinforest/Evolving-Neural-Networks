{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "vvrt4WJ7o8e6"
   },
   "outputs": [],
   "source": [
    "#Set up generating mathematical functions in tree structures from the following\n",
    "#primitives, these will be used for calculating displacements of neurons\n",
    "from deap import gp\n",
    "import operator\n",
    "import math\n",
    "def square(x):\n",
    "    return x*x\n",
    "def absSqrt(x):\n",
    "    return math.sqrt(abs(x))\n",
    "pset = gp.PrimitiveSet(\"nodePrims\", arity=1)\n",
    "pset.addPrimitive(max, 2)\n",
    "pset.addPrimitive(operator.mul, 2)\n",
    "pset.addPrimitive(operator.add, 2)\n",
    "pset.addPrimitive(operator.sub, 2)\n",
    "pset.addPrimitive(math.sin, 1)\n",
    "pset.addPrimitive(math.cos, 1)\n",
    "pset.addPrimitive(absSqrt, 1)\n",
    "pset.addPrimitive(square, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "QCKS3iQIo8fK",
    "outputId": "a471f2b5-673b-4a53-838c-c6cb7dc4647d",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\tmean   \tmin\tmax    \tstdDev \n",
      "0  \t150   \t21.7032\t1  \t1734.14\t142.609\n",
      "1  \t21    \t153.822\t4  \t1734.14\t451.224\n",
      "2  \t24    \t640.798\t6.14948\t1734.14\t803.162\n",
      "3  \t22    \t1206.66\t36.6039\t1734.14\t760.815\n",
      "4  \t23    \t1697.18\t256    \t1734.14\t230.774\n",
      "5  \t25    \t1854.81\t1734.14\t6561   \t753.594\n",
      "6  \t22    \t1975.48\t1734.14\t6561   \t1051.99\n",
      "7  \t16    \t3182.2 \t1734.14\t6561   \t2211.95\n",
      "8  \t27    \t5243.81\t1734.14\t6561   \t2010.34\n",
      "9  \t20    \t6561   \t6561   \t6561   \t0      \n",
      "10 \t23    \t6561   \t6561   \t6561   \t0      \n",
      "11 \t22    \t6561   \t6561   \t6561   \t0      \n",
      "12 \t23    \t6561   \t6561   \t6561   \t0      \n",
      "13 \t24    \t6561   \t6561   \t6561   \t0      \n",
      "14 \t23    \t6561   \t6561   \t6561   \t0      \n",
      "15 \t24    \t6561   \t6561   \t6561   \t0      \n",
      "16 \t25    \t6561   \t6561   \t6561   \t0      \n",
      "17 \t23    \t6561   \t6561   \t6561   \t0      \n",
      "18 \t24    \t6561   \t6561   \t6561   \t0      \n",
      "19 \t22    \t6561   \t6561   \t6561   \t0      \n",
      "20 \t21    \t6561   \t6561   \t6561   \t0      \n",
      "21 \t26    \t6561   \t6561   \t6561   \t0      \n",
      "22 \t26    \t6561   \t6561   \t6561   \t0      \n",
      "23 \t24    \t6561   \t6561   \t6561   \t0      \n",
      "24 \t22    \t6561   \t6561   \t6561   \t0      \n",
      "25 \t23    \t6561   \t6561   \t6561   \t0      \n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Code to implement the evolution of the models and hyperparameters for generating them\n",
    "%matplotlib notebook\n",
    "from deap import creator, base, tools, algorithms\n",
    "from random import randint\n",
    "import numpy as np\n",
    "import pickle\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "DataDims = 2\n",
    "MINDIMFUNCS = 1\n",
    "MAXDIMFUNCS = 10\n",
    "MINDIMS = DataDims\n",
    "MAXDIMS = 10\n",
    "POPSIZE = 150\n",
    "GENERATIONS = 25\n",
    "MU = 40\n",
    "LAMBDA = 30\n",
    "CXPB = 0.5\n",
    "MUTPB = 0.3\n",
    "WEIGHTSCALE = 0.05\n",
    "BIASSCALE = 0.05\n",
    "\n",
    "\n",
    "def genTreeList():\n",
    "    return [gp.PrimitiveTree(gp.genHalfAndHalf(pset=pset, min_=1,max_=6)) for i in range(randint(MINDIMFUNCS,MAXDIMFUNCS))]\n",
    "def genFuncList():\n",
    "    return [genTreeList() for j in range(randint(MINDIMS,MAXDIMS))]\n",
    "\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,) )\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "# def myMutate(individual):\n",
    "#     new = [[gp.mutNodeReplacement(x,pset=pset) for x in l] for l in toolbox.clone(individual)]\n",
    "#     return (tools.initIterate(creator.Individual, lambda: new),)\n",
    "\n",
    "\n",
    "def getFitMap(ls):\n",
    "    fitnesses = []\n",
    "    for l in ls:\n",
    "        fitnesses.append(l.fitness.values[0])\n",
    "    return fitnesses\n",
    "\n",
    "def evolve(evaluator):\n",
    "    \n",
    "    \n",
    "    \n",
    "    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,) )\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "    \n",
    "    toolbox = base.Toolbox()\n",
    "    toolbox.register(\"individual\", tools.initIterate, creator.Individual, genFuncList)\n",
    "    \n",
    "    def myMutate(individual):\n",
    "        new = [[gp.mutNodeReplacement(x,pset=pset) for x in l] for l in toolbox.clone(individual)]\n",
    "        new = [[x[0] for x in l] for l in new]\n",
    "        return (tools.initIterate(creator.Individual, lambda: new),)\n",
    "\n",
    "    toolbox.register(\"mate\", tools.cxUniform, indpb=0.5)\n",
    "    toolbox.register(\"mutate\", myMutate)\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize = 4)\n",
    "    toolbox.register(\"evaluate\", evaluator)\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "    pop = toolbox.population(POPSIZE)\n",
    "    \n",
    "    \n",
    "\n",
    "    myStats = tools.Statistics()\n",
    "    myStats.register(\"mean\", lambda ls: np.mean(getFitMap(ls)))\n",
    "    myStats.register(\"min\", lambda ls: min(getFitMap(ls)))\n",
    "    myStats.register(\"max\", lambda ls: max(getFitMap(ls)))\n",
    "    myStats.register(\"stdDev\", lambda ls: np.std(getFitMap(ls)))\n",
    "\n",
    "    hallOFame = tools.HallOfFame(5) # hall of fame of size 5\n",
    "\n",
    "\n",
    "    (finalPop, logbook) = algorithms.eaMuPlusLambda(pop, toolbox, MU, LAMBDA, CXPB, MUTPB, GENERATIONS, myStats, halloffame=hallOFame, verbose=True)\n",
    "\n",
    "    gen = logbook.select(\"gen\")\n",
    "    fit_maxs = logbook.select(\"max\")\n",
    "    fit_avgs = logbook.select(\"mean\")\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "    line1 = ax1.plot(gen, fit_maxs, \"b-\", label=\"Maximum Fitness\")\n",
    "    ax1.set_xlabel(\"Generation\")\n",
    "    ax1.set_ylabel(\"Fitness\", color=\"b\")\n",
    "    for tl in ax1.get_yticklabels():\n",
    "        tl.set_color(\"b\")\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    line2 = ax2.plot(gen, fit_avgs, \"r-\", label=\"Average Fitness\")\n",
    "    ax2.set_ylabel(\"Size\", color=\"r\")\n",
    "    for tl in ax2.get_yticklabels():\n",
    "        tl.set_color(\"r\")\n",
    "\n",
    "    lns = line1 + line2\n",
    "    labs = [l.get_label() for l in lns]\n",
    "    ax1.legend(lns, labs, loc=\"center right\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def flatten(mylist):\n",
    "    return list(itertools.chain.from_iterable(mylist))\n",
    "    \n",
    "def myEval(individual):\n",
    "    funcs = []\n",
    "    for dimlist in individual:\n",
    "        newDimlist = []\n",
    "        for tree in dimlist:\n",
    "#             print gp.stringify(tree)\n",
    "            f = gp.compile(tree, pset)\n",
    "            newDimlist.append(f)\n",
    "        funcs.append(newDimlist)\n",
    "    flattened = flatten(funcs)\n",
    "    mapped = map(lambda f: f(1), flattened)\n",
    "    return max(mapped),\n",
    "    \n",
    "    \n",
    "evolve(myEval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "MSJBPuYeo8fm",
    "outputId": "19052e0c-7a92-439e-eb8b-ccc170a9eeaa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuDNN version 7005 on context None\n",
      "Mapped name None to device cuda: GRID K520 (0000:00:03.0)\n"
     ]
    }
   ],
   "source": [
    "#Load MNIST data to train/test models on\n",
    "import theano\n",
    "import mnist\n",
    "import numpy as np\n",
    "\n",
    "train_images = mnist.train_images()\n",
    "train_labels = mnist.train_labels()\n",
    "\n",
    "test_images = mnist.test_images()\n",
    "test_labels = mnist.test_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "MSJBPuYeo8fm",
    "outputId": "19052e0c-7a92-439e-eb8b-ccc170a9eeaa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6270b959d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parse mnist data into form that we will use\n",
    "def labelToArray(x):\n",
    "    blank = [0] * 10\n",
    "    blank[x] = 1\n",
    "    return np.array(blank)\n",
    "\n",
    "trainingimgs = [train_images[i].astype(theano.config.floatX).ravel() * (1.0/256) for i in range(train_images.shape[0])]\n",
    "traininglabels = [labelToArray(train_labels[i]).astype(theano.config.floatX) for i in range(train_labels.shape[0])]\n",
    "testingimgs = [test_images[i].astype(theano.config.floatX).ravel() * (1.0/256) for i in range(test_images.shape[0])]\n",
    "testinglabels = [labelToArray(test_labels[i]).astype(theano.config.floatX) * (1.0 / 256) for i in range(test_labels.shape[0])]\n",
    "plt.imshow(trainingimgs[0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "oTGC3727o8f0",
    "outputId": "b31754f4-b054-4e8c-d625-9dc6e12cf7dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running initial singleGenConsolidate\n",
      "starting a singleGenConsolidate\n",
      "half way done a singleGenConsolidate\n",
      "finished a singleGenConsolidate\n",
      "starting to loop\n",
      "starting a singleGenConsolidate\n",
      "half way done a singleGenConsolidate\n",
      "finished a singleGenConsolidate\n",
      "first version took: 0.000173807144165\n",
      "looped\n",
      "starting a singleGenConsolidate\n",
      "half way done a singleGenConsolidate\n",
      "finished a singleGenConsolidate\n",
      "first version took: 0.0001540184021\n",
      "looped\n",
      "starting a singleGenConsolidate\n",
      "half way done a singleGenConsolidate\n",
      "finished a singleGenConsolidate\n",
      "first version took: 0.000154972076416\n",
      "looped\n",
      "starting a singleGenConsolidate\n",
      "half way done a singleGenConsolidate\n",
      "finished a singleGenConsolidate\n",
      "first version took: 0.000158071517944\n",
      "looped\n",
      "starting a singleGenConsolidate\n",
      "half way done a singleGenConsolidate\n",
      "finished a singleGenConsolidate\n",
      "first version took: 0.000166177749634\n",
      "looped\n",
      "starting a singleGenConsolidate\n",
      "half way done a singleGenConsolidate\n",
      "finished a singleGenConsolidate\n",
      "first version took: 0.000154972076416\n",
      "looped\n",
      "starting a singleGenConsolidate\n",
      "half way done a singleGenConsolidate\n",
      "finished a singleGenConsolidate\n",
      "first version took: 0.000152111053467\n",
      "looped\n",
      "starting a singleGenConsolidate\n",
      "half way done a singleGenConsolidate\n",
      "finished a singleGenConsolidate\n",
      "first version took: 0.000153064727783\n",
      "looped\n",
      "[ 0.93820096]\n",
      "biased and tanned: [ 0.04408862  0.07158857  0.06487364  0.18927555  0.07557143]\n",
      "biased and tanned: [ 0.01636772  0.05831546  0.04112239  0.04844521  0.02884416]\n",
      "biased and tanned: [ 0.03316154  0.02267201  0.04299259  0.0303378   0.0176501 ]\n",
      "biased and tanned: [ 0.00249707  0.0390876   0.03305502  0.04861817  0.00910204]\n",
      "biased and tanned: [ 0.00950003  0.02723151  0.02849113  0.00567916  0.01975187]\n",
      "biased and tanned: [ 0.00022523  0.04764779  0.02825208  0.00774352  0.00794655]\n",
      "biased and tanned: [ 0.04521414  0.0299231   0.01892255  0.01104637  0.03145993]\n",
      "biased and tanned: [ 0.02693113  0.02440411  0.03740145  0.04333505  0.01544306]\n",
      "biased and tanned: [ 0.03497066  0.00492714  0.01980029  0.04440942  0.0269134 ]\n",
      "[ 0.93820096]\n"
     ]
    }
   ],
   "source": [
    "#Miscellaneous functions that get used for calculating growth of networks\n",
    "\n",
    "import theano.tensor as T\n",
    "from theano import shared\n",
    "import theano\n",
    "from autograd import grad as Grad\n",
    "import autograd.numpy as np\n",
    "import autograd.numpy.linalg as LA\n",
    "import itertools\n",
    "import typing\n",
    "import time\n",
    "import math\n",
    "from itertools import izip\n",
    "#We're modeling neurons as points in a high dimensional space, but to keep them\n",
    "#from just going all over the place and not interacting to create interesting \n",
    "#structures, we're going to limit the size of that space to a box of this width\n",
    "SPACESPAN = 2.0\n",
    "\n",
    "#Take one dimension of a neuron's position -- if it's outside the box,\n",
    "#wrap it around so it goes in the box. Otherwise, do nothing.\n",
    "def box(x):\n",
    "    if x > 0 + SPACESPAN / 2.0:\n",
    "        return -1.0 + x\n",
    "    elif x < 0 - SPACESPAN / 2.0:\n",
    "        return 1.0 + x\n",
    "    else:\n",
    "        return x\n",
    "      \n",
    "      \n",
    "#Want neurons that are close together to overlap, so we have a \"resolution\" of \n",
    "#the space such that if neurons are closer than the \"resolution\", they overlap. \n",
    "#resDenominator can be thought of as how many pixels are in a row of the box the\n",
    "#neurons live in.\n",
    "def discretize(x, resDenominator):\n",
    "    if x > 0.0:\n",
    "        return np.floor(1.0 * x * resDenominator) / resDenominator\n",
    "    elif x < 0.0:\n",
    "        return np.floor(1.0 * x * resDenominator) / resDenominator\n",
    "    else:\n",
    "        return 0.0\n",
    "    \n",
    "def mnistlabelToArray(x):\n",
    "    blank = [0] * 10\n",
    "    blank[x] = 1\n",
    "    return np.array(blank)\n",
    "\n",
    "\n",
    "def flatten(mylist):\n",
    "    return list(itertools.chain.from_iterable(mylist))\n",
    "\n",
    "#Consolidation is strange but crucial. Basically you have a big array of where the\n",
    "#neurons are in space, then you apply the displacement/\"growth\" rules to each\n",
    "#dimension of those positions. Now you have a huge list of neuron positions, and\n",
    "#consolidating is calculating what neurons overlap, and creating a list of indices\n",
    "#that tells which neurons are going as input to a neuron in the next layer. You\n",
    "#could do this with a bitmask, but the networks are usually sparse enough that \n",
    "#it would be extremely inefficient, but maybe with a low resDenominator the space\n",
    "#will overlap enough that it will be efficient. Improving this would be nice, but\n",
    "#I don't know if its necessary, given this is slow but not terribly slow.\n",
    "\n",
    "#to be honest I have to look over this a lot too to figure out whats going on.\n",
    "  \n",
    "def newSingleGenConsolidate(arrays):\n",
    "    bigMatrix = np.array(arrays)\n",
    "    arraylen = len(arrays)\n",
    "    initArraylen = len(arrays)\n",
    "    indices = []\n",
    "    flattenedIndices = []\n",
    "    \n",
    "    irange = range(arraylen)\n",
    "    \n",
    "    counter = True\n",
    "    print \"starting a singleGenConsolidate\"\n",
    "    for i in irange:\n",
    "        if i not in flattenedIndices:\n",
    "            subgroupArr = np.argwhere(np.all((bigMatrix-bigMatrix[i])==0, axis=0))\n",
    "            subgroup = subgroupArr.tolist()\n",
    "            indices.append(subgroup)\n",
    "            flattenedIndices += subgroup\n",
    "            arraylen -= subgroupArr.size\n",
    "            if counter and arraylen/initArraylen < 0.5:\n",
    "                print \"half way done a singleGenConsolidate\"\n",
    "                counter = False\n",
    "    \n",
    "    print \"finished a singleGenConsolidate\"\n",
    "    return indices\n",
    "            \n",
    "            \n",
    "            \n",
    "def singleGenConsolidate(arrays):\n",
    "    #takes as input [[position, position,...],[position, position,...], ...]\n",
    "    #want to find, in the flattened list above, which the indices of all neurons that overlap with the first position,\n",
    "    #then the indices of all the neurons that overlap with the second position, and so on until done\n",
    "    \n",
    "    indices = []\n",
    "    flattenedIndices = []\n",
    "    arraylen = len(arrays)\n",
    "    initArraylen = len(arrays) * 1.0\n",
    "    irange = range(arraylen)\n",
    "    \n",
    "    counter = True\n",
    "    print \"starting a singleGenConsolidate\"\n",
    "    for i in irange:\n",
    "        if i not in flattenedIndices:\n",
    "            subgroup = [i] + [j for j in irange[i + 1:] if np.array_equal(arrays[i], arrays[j])]\n",
    "            arraylen -= len(subgroup)\n",
    "            indices.append(subgroup)\n",
    "            flattenedIndices += subgroup\n",
    "            if counter and arraylen/initArraylen < 0.5:\n",
    "                print \"half way done a singleGenConsolidate\"\n",
    "                counter = False\n",
    "    \n",
    "    print \"finished a singleGenConsolidate\"\n",
    "    \n",
    "    #returns a list [[index, index, index,...], [index, index, index,...]] where the ith sublist corresponds to the ith neuron\n",
    "    #in the next layer up, and each sublist contains the indices of the neurons that connect to them.\n",
    "    return indices\n",
    "\n",
    "\n",
    "\n",
    "def nprelu(x):\n",
    "    np.maximum(0,x)\n",
    "\n",
    "\n",
    "def getSubV2np(index, inds, complete):\n",
    "    return complete[inds[index]:inds[index + 1]]\n",
    "\n",
    "def getSubV3np(index, indinds, inds, complete):\n",
    "    subInds = inds[indinds[index] : indinds[index + 1] + 1]\n",
    "    return subInds, complete\n",
    "  \n",
    "#this is a consolidation list actually being used\n",
    "def singleConsol(tensor, indices):\n",
    "    return (np.choose(indices, tensor)).sum()\n",
    "\n",
    "def positionConsolidate(arrays, consolidations):\n",
    "    return [arrays[sublist[0]] for sublist in consolidations]\n",
    "\n",
    "def numpyConsolidate(array, consols):\n",
    "    new = []\n",
    "    for sublist in consols:\n",
    "        x = 0.0\n",
    "        for i in sublist:\n",
    "            x += array[i]\n",
    "        new.append(x)\n",
    "\n",
    "    return new\n",
    "\n",
    "def npConsolidate(array, consolinds, consols):\n",
    "    ordered = array.take(consols)\n",
    "    f = lambda i : ordered[consolinds[i]: consolinds[i + 1]].sum()\n",
    "    veced = np.vectorize(f)\n",
    "    return veced(np.arange(consolinds.size))\n",
    "\n",
    "\n",
    "def generalfeedforward((weights, biases, finalweights, finalbiases), consolMasks, hiddenlayers, branchMultiplier, inp):\n",
    "    #implements a fractalnet in numpy, using consolidation masks instead of lists.\n",
    "    for i in range(hiddenlayers):\n",
    "        inp = np.repeat(inp, branchMultiplier)\n",
    "        inp = np.multiply(weights[i], inp)\n",
    "        inp = np.concatenate((inp, np.array([0.0]).astype('float32')))\n",
    "        inp = inp.take(consolMasks[i]).sum(axis = 1)\n",
    "        inp = nprelu(np.add(inp, biases[i]))\n",
    "    \n",
    "    print inp\n",
    "    finalout = nprelu(np.dot(inp, finalweights) + finalbiases)\n",
    "    return finalout\n",
    "\n",
    "\n",
    "class nnet:\n",
    "    weights = []\n",
    "    biases = []\n",
    "    consolidations = []\n",
    "    finalweights = []\n",
    "    finalbiases = []\n",
    "    weightnum = 0\n",
    "    hiddenlayers = 0\n",
    "    \n",
    "    def __init__(self, resolution, functions, inputdimension, datainp, dataoutp, synapseThreshold):\n",
    "        self.resDenominator = resolution\n",
    "        self.funcs = functions\n",
    "        self.dimensions = len(self.funcs)\n",
    "        \n",
    "        #branch multiplier says how many neurons grow out of each neuron every\n",
    "        #time a new layer is grown. This is the same fo\n",
    "        \n",
    "        self.branchMultiplier = len(flatten(self.funcs))\n",
    "        self.TBranchMult = shared(np.array([self.branchMultiplier]))\n",
    "#         self.dataset = [shared(dat.astype(theano.config.floatX)) for dat in datainp]\n",
    "#         self.datalabels = [shared(outp.astype(theano.config.floatX)) for outp in dataoutp]\n",
    "        self.dataSample = datainp[0] #numpy\n",
    "        self.dataOutSample = dataoutp[0]\n",
    "        self.inputdimension = inputdimension\n",
    "        \n",
    "        if self.dataSample.size ** (1.0/ inputdimension) > self.resDenominator * 2.0:\n",
    "            print \"resDenominator may be too small for effective learning\"\n",
    "            \n",
    "        self.threshold = synapseThreshold\n",
    "\n",
    "    def applyFuncs(self, narray): #checked\n",
    "        #grows a single neuron's new positions, given vector position (represented as a list)\n",
    "        boxvec = np.vectorize(lambda x: discretize(box(x), self.resDenominator))\n",
    "        displaced = []\n",
    "        \n",
    "        for dim in range(self.dimensions):\n",
    "            for f in self.funcs[dim]:\n",
    "                \n",
    "                zeroes = np.zeros_like(narray)\n",
    "                displacement = f(narray[dim]) % SPACESPAN\n",
    "                zeroes[dim] = displacement\n",
    "                \n",
    "                newArray = np.add(narray, zeroes)\n",
    "                newArrayBoxed = boxvec(newArray)\n",
    "                displaced.append(newArrayBoxed)\n",
    "                \n",
    "        \n",
    "        return displaced\n",
    "        \n",
    "\n",
    "    def applyFuncsMult(self, narrays): \n",
    "        #given list of neuron positions (lists), grow them and return a list of list of positions, where the first list is the \n",
    "        #first neuron's \"outgrowths\", the second list is the second neuron's \"outgrowths\" and so on.\n",
    "        \n",
    "        return flatten([self.applyFuncs(x) for x in narrays])\n",
    "    \n",
    "    def locate(self, sample):  #only 1 or 2 implemented\n",
    "        #given input data as an array, represent that data spacially as a neurons that can then be grown\n",
    "        \n",
    "        insize = sample.size\n",
    "        sample = np.ravel(sample) \n",
    "        tensorFrame = [0] * self.dimensions\n",
    "        located = [0] * insize\n",
    "        \n",
    "        boxvec = np.vectorize(lambda x: discretize(box(x), self.resDenominator))\n",
    "        \n",
    "        #self.inputdimension is the dimension the input should be represented in\n",
    "        \n",
    "        if self.inputdimension == 1:\n",
    "            #arrange neurons in a line along the first dimension\n",
    "            for i in range(insize):\n",
    "                myTens = tensorFrame[:]\n",
    "                myTens[0] = (2.0 * i) / insize - 1.0\n",
    "                located[i] = boxvec(np.array(myTens))\n",
    "        \n",
    "        if self.inputdimension == 2:\n",
    "            #arrange neurons in a grid in the first two dimensions that has integer dimensions, calculated to be as \n",
    "            #close to square as possible for convenience\n",
    "            located = []\n",
    "            factorPairs = [(i,(insize / i)) for i in range(1, int(math.floor(insize**0.5))) if insize % i == 0]\n",
    "            pair = factorPairs[-1]\n",
    "            for i in range(pair[0]):\n",
    "                for j in range(pair[1]):\n",
    "                    myTens = tensorFrame[:]\n",
    "                    myTens[0] = 2.0 * i/pair[0] - 1.0\n",
    "                    myTens[1] = 2.0 * j/pair[1] - 1.0\n",
    "                    located.append(boxvec(np.array(myTens)))\n",
    "                            \n",
    "        return located\n",
    "        \n",
    "    def genConsolidate(self): #finds consolidation list from located self.dataSample\n",
    "        consols = []\n",
    "#         print len(self.dataSample.ravel())\n",
    "\n",
    "        located = self.locate(self.dataSample)\n",
    "        #type is [position, position, ...], don't care about dataSample's actual values right now, just its dimensions\n",
    "        \n",
    "#         print len(located)\n",
    "#         print type(located[0])\n",
    "        print \"running initial singleGenConsolidate\"\n",
    "    \n",
    "        #Grow the neurons, generate consolidations list, consolidate, then start a loop\n",
    "        located = self.applyFuncsMult(located)\n",
    "        consols.append(singleGenConsolidate(located))\n",
    "        located = positionConsolidate(located, consols[-1]) \n",
    "\n",
    "        \n",
    "        print \"starting to loop\"\n",
    "        #stop the growth when it hits a certain number of weights\n",
    "        while len(flatten(flatten(consols))) + len(flatten(consols[-1])) * self.branchMultiplier < self.threshold:\n",
    "            located = self.applyFuncsMult(located)\n",
    "            testStart = time.time()\n",
    "            consols.append(singleGenConsolidate(located))\n",
    "            print \"first version took: \" + str(time.time() - testStart)\n",
    "#             testStart = time.time()\n",
    "#             x = newSingleGenConsolidate(located)\n",
    "#             print \"new version took: \" + str(time.time() - testStart)\n",
    "            \n",
    "            located = positionConsolidate(located, consols[-1]) \n",
    "            print \"looped\"\n",
    "            \n",
    "        self.consolidations = consols\n",
    "        \n",
    "        #In contrast to using the consolidation list, which is a list of lists of variable length, you can also pad them to create\n",
    "        #a list of fixed lengths lists (maximum of the previous variable lengths) that makes things neater but sacrifices some\n",
    "        #memory (and possibly some speed, but depending on implementation it might be faster). Pad with out of bounds indices\n",
    "        #that theano and numpy will default to zero.\n",
    "        self.consolMasks = []\n",
    "        for layerConsols in self.consolidations:\n",
    "#             print \"initial \" + str(layerConsols)\n",
    "            maxInLength = max(map(len, layerConsols))\n",
    "            inLength = len(flatten(layerConsols))\n",
    "            extended = map(lambda l: l + [inLength] * (maxInLength - len(l)), layerConsols)\n",
    "#             print \"extended: \" + str(extended)\n",
    "            self.consolMasks.append(np.array(extended).astype('int32'))\n",
    "        return consols\n",
    "    \n",
    "    def genWeights(self):\n",
    "        myWeightNum = 0\n",
    "        self.hiddenlayers = 0\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        self.finalweights = []\n",
    "        self.finalbiases = []\n",
    "        for consol in self.consolidations:\n",
    "            weightVec = (np.random.rand(len(flatten(consol))) * WEIGHTSCALE).astype(theano.config.floatX).tolist()\n",
    "            biasVec   = (np.random.rand(len(consol)) * BIASSCALE).astype(theano.config.floatX).tolist()\n",
    "            self.weights.append(weightVec)\n",
    "            self.biases.append(biasVec)\n",
    "            myWeightNum += len(weightVec)\n",
    "\n",
    "            #convert to shared data type for later speed\n",
    "            self.hiddenlayers += 1\n",
    "        \n",
    "        outsize = len(self.dataOutSample)\n",
    "        \n",
    "        self.finalweights = np.random.rand(len(self.consolidations[-1]),outsize).astype('float32')        #final interconnected layer for output\n",
    "        self.finalbiases = np.random.rand(outsize).astype('float32')\n",
    "\n",
    "        myWeightNum += len(self.consolidations[-1]) * outsize\n",
    "#         self.weightNum = myWeightNum\n",
    "        \n",
    "    def feedforward(self, inp):\n",
    "        \n",
    "        for i in range(self.hiddenlayers):\n",
    "            inp = np.repeat(inp, self.branchMultiplier)\n",
    "#             print \"repeated: \" + str(inp)\n",
    "            inp = np.multiply(self.weights[i], inp)\n",
    "#             print \"weighted: \" + str(inp)\n",
    "            inp = numpyConsolidate(inp, self.consolidations[i])\n",
    "#             print \"consolidated: \" + str(inp)\n",
    "            inp = np.maximum(0, np.add(inp, self.biases[i]))\n",
    "            print \"biased and relued: \" + str(inp)\n",
    "        \n",
    "#         print \"before finals: \" + str(inp)\n",
    "#         print \"finalweights: \" + str(self.finalweights)\n",
    "#         print \"finalbiases: \" + str(self.finalbiases)\n",
    "        finalout = (np.dot(inp, self.finalweights) + self.finalbiases)\n",
    "#         print \"final: \" + str(finalout)\n",
    "        return finalout\n",
    "\n",
    "    def nfeedforward(self, inp):\n",
    "        for i in range(self.hiddenlayers):\n",
    "            inp = np.repeat(inp, self.branchMultiplier)\n",
    "            inp = np.multiply(self.weights[i], inp)\n",
    "            inp = np.concatenate((inp, np.array([0.0]).astype('float32')))\n",
    "            inp = inp.take(self.consolMasks[i]).sum(axis = 1)\n",
    "            inp = np.maximum(0,np.add(inp, self.biases[i])))\n",
    "        return np.dot(inp, self.finalweights) + self.finalbiases\n",
    "    \n",
    "    def test(inputs, outputs):\n",
    "        \n",
    "        def foo(x):\n",
    "            if x > 0.5:\n",
    "                return 1.0\n",
    "            return 0.0\n",
    "\n",
    "        binarize = np.vectorize(foo)\n",
    "        \n",
    "        errors = [LA.norm(outp - binarize(self.feedforward(inp))) for inp,outp in izip(inputs,outputs)]\n",
    "        return sum(errors)/len(inputs) * 100.0\n",
    "        \n",
    "    \n",
    "    def numpytrain(self, alpha, epochs, batchsize, inputlist, outputlist, verbose, testdatainputs, testdatalabels):\n",
    "        print \"starting training\"\n",
    "        \n",
    "        def error((weights, biases, finalweights, finalbiases), inp, outp):\n",
    "            return LA.norm(outp - generalfeedforward((weights,biases,finalweights,finalbiases), \n",
    "                                                     self.consolMasks, self.hiddenlayers, self.branchMultiplier, inp))\n",
    "        #use autograd to automatically differentiate error function\n",
    "        error_grad = Grad(error)\n",
    "        \n",
    "        inlen = len(inputlist)\n",
    "        outlen = len(outputlist)\n",
    "\n",
    "        if inlen != outlen:\n",
    "            Exception(\"number of input vectors (\"+str(inlen)+\") not equal not number of ouptut vectors (\"+str(outlen)+\")\")\n",
    "            \n",
    "        if alpha == 0.0:\n",
    "            raise(\"why is alpha zero?\")\n",
    "            \n",
    "        if type(batchsize) != int:\n",
    "            raise(\"Why is batchsize not an int?\")\n",
    "        \n",
    "        if batchsize == 0 or batchsize > inlen:\n",
    "            raise(\"batchsize of \"+str(batchsize)+\"is not allowed. Note than inputveclist has length \"+str(inlen))\n",
    "            \n",
    "        #just some error checks\n",
    "        \n",
    "        randindexlist = range(inlen)\n",
    "        start = time.time()\n",
    "        avgpercenttesterror = \"No test set\"\n",
    "        avgpercenttesterrorlist = []\n",
    "        \n",
    "        #using stochastic gradient descent training method\n",
    "        for epoch in xrange(epochs):\n",
    "            #random.shuffle(randindexlist)\n",
    "            #for batch in range(inlen/batchsize):\n",
    "            \n",
    "#                 low = batch * batchsize\n",
    "#                 upper = (batch + 1) * batchsize\n",
    "#                 if upper > inlen: upper = inlen \n",
    "                \n",
    "#                 total_Egradweights = None\n",
    "#                 total_Egradbiases = None\n",
    "                \n",
    "#                 for i in randindexlist[low:upper]:\n",
    "            for inp,outp in izip(inputlist,outputlist):\n",
    "                Egradws, Egradbs, Egadfws, Egradfbs = error_grad((self.weights, self.biases, \n",
    "                                                       self.finalweights, self.finalbiases), inp, outp) #formerly used indexes from randindexlist\n",
    "#                     if total_Egradweights:\n",
    "#                         total_Egradweights = [x + y for x,y in izip(Egradweights,total_Egradweights)]\n",
    "#                         total_Egradbiases = [x + y for x,y in izip(Egradbiases,total_Egradbiases)]\n",
    "#                     else:\n",
    "#                         total_Egradweights = Egradweights\n",
    "#                         total_Egradbiases = Egradbiases\n",
    "                \n",
    "#                 total_Egradweights = [x / (batchsize * 1.0) for x in total_Egradweights]\n",
    "#                 total_Egradbiases = [x / (batchsize * 1.0) for x in total_Egradbiases]\n",
    "                \n",
    "#                 self.weights = [curr-grad*alpha for curr, grad in izip(self.weights, total_Egradweights)]\n",
    "#                 self.biases = [curr-grad*alpha for curr, grad in izip(self.biases, total_Egradbiases)]\n",
    "                self.weights = [curr-grad*alpha for curr, grad in izip(self.weights, Egradws)]\n",
    "                self.biases = [curr-grad*alpha for curr, grad in izip(self.biases, Egradbs)]\n",
    "                self.finalweights = self.finalweights - alpha * Egradfws\n",
    "                self.finalbiases = self.finalbiases - alpha * Egradfbs\n",
    "            \n",
    "            if len(testinputlist) == len(testoutputlist) and len(testinputlist) != 0:\n",
    "                avgpercenttesterror = self.test(testinputlist, testoutputlist)\n",
    "                avgpercenttesterrorlist.append(avgpercenttesterror)\n",
    "            else:\n",
    "                print \"bad test set\"\n",
    "            \n",
    "            elapsed = time.time() - start\n",
    "            start = time.time()\n",
    "            if verbose:\n",
    "                print \"epoch: \" + str(epoch) + \"\\t percenterror: \" + str(avgpercenttesterror) + \"% \\t time elapsed this epoch: \" + str(elapsed) + \"s\"\n",
    "            \n",
    "        return (avgpercenttesterror, avgpercenttesterrorlist)\n",
    "\n",
    "# singleGenConsolidate([np.array([0,0,0]), np.array([0,1,2,3]), np.array([0,0,0])])\n",
    "testnet = nnet(10, [[lambda x: x + 1], [lambda x: x * 2]], 1, [np.array([0,1,2,3])], [np.array([1])], 100)\n",
    "testnet.genConsolidate()\n",
    "testnet.genWeights()\n",
    "numpyConsolidate(np.array([1,2,3]), [[0,2], [1]])\n",
    "print testnet.nfeedforward(np.array([0,1,2,3]))\n",
    "print testnet.feedforward(np.array([0,1,2,3]))\n",
    "# print mynet.consolidations\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "from theano import shared,config,function\n",
    "import itertools\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "# theano.config.exception_verbosity = \"high\"\n",
    "\n",
    "def flatten(mylist):\n",
    "    return list(itertools.chain.from_iterable(mylist))\n",
    "  \n",
    "\n",
    "\n",
    "class V2IndexedShared:\n",
    "    def __init__(self, atype):\n",
    "        self.myType = atype\n",
    "    \n",
    "    def fromList(self,D2List):\n",
    "        self.complete = shared(np.array(flatten(D2List)).astype(self.myType))\n",
    "        self.length = shared(len(D2List))\n",
    "        inds = [0]\n",
    "        for sublist in D2List:\n",
    "            inds.append(len(sublist) + inds[-1])\n",
    "        self.inds = shared(np.array(inds).astype('int32'))\n",
    "        return self\n",
    "\n",
    "    \n",
    "class V3IndexedShared:\n",
    "    def __init__(self,D3List, atype):\n",
    "        self.complete = shared(np.array(flatten(flatten(D3List))).astype(atype))\n",
    "#         self.complete = np.array(flatten(flatten(D3List))).astype(atype)\n",
    "\n",
    "        self.myType = atype\n",
    "        self.length = shared(len(D3List))\n",
    "        D2Inds = [0]\n",
    "        D3Inds = [0]\n",
    "        \n",
    "        for sublistOLists in D3List:\n",
    "            \n",
    "            for sublist in sublistOLists:\n",
    "                D2Inds.append(len(sublist) + D2Inds[-1])\n",
    "                \n",
    "            D3Inds.append(len(sublistOLists) + D3Inds[-1])\n",
    "            \n",
    "                \n",
    "        self.D2Inds = shared(np.array(D2Inds).astype('int32'))\n",
    "        self.D3Inds = shared(np.array(D3Inds).astype('int32'))\n",
    "        \n",
    "#         self.D2Inds = np.array(D2Inds).astype('int32')\n",
    "#         self.D3Inds = np.array(D3Inds).astype('int32')\n",
    "#         print D3Inds\n",
    "#         print D2Inds\n",
    "#         print np.array(flatten(flatten(D3List)))\n",
    "    \n",
    "\n",
    "def relu(x):\n",
    "    return T.maximum(x, 0)\n",
    "\n",
    "#instead of having nested lists of variable sizes, the following two classes implement either a list of lists and a lists of \n",
    "#lists of lists. It implements it by having a \"complete\" array, then a array of indexes for the beginning and end of the slices\n",
    "#of that array, then an array for the beginning and end of slices (of the slices array)\n",
    "\n",
    "\n",
    "def getSubV2(index, inds, complete):\n",
    "    return complete[inds[index]:inds[index + 1]]\n",
    "\n",
    "def getSubV2Check():\n",
    "    tind = T.iscalar('ind')\n",
    "    tinds = T.ivector('inds')\n",
    "    tcomp = T.vector('complete')\n",
    "    \n",
    "    nind = np.asscalar(np.array([0]).astype('int32'))\n",
    "    ninds = np.array([0,2,4]).astype('int32')\n",
    "    comp = np.array([0,1,2,3,4]).astype(theano.config.floatX)\n",
    "    \n",
    "    f = theano.function([tind, tinds, tcomp], getSubV2(tind, tinds, tcomp))\n",
    "    print f(nind,ninds,comp)\n",
    "getSubV2Check()\n",
    "def getV2Length(inds):\n",
    "    return inds.size -1\n",
    "\n",
    "def getSubV3(index, indinds, inds, complete):\n",
    "    subInds = inds[indinds[index] : indinds[index + 1] + 1]\n",
    "    return subInds, complete\n",
    "\n",
    "def getSubV3Check():\n",
    "    D3List = [[[0,1,2,], [3,4,5]], [[6,7,8], [9,10,11]]]\n",
    "    consolcomplete = [0,1,2,3,4,5,6,7,8,9,10,11]\n",
    "    consolinds = [0,3,6,9,12]\n",
    "    consolindinds = [0,2,4]\n",
    "    print getSubV3(1, consolindinds, consolinds, consolcomplete)\n",
    "    print consolinds[2:5]\n",
    "    t = V3IndexedShared(D3List, 'int32')\n",
    "    \n",
    "# getSubV3Check()\n",
    "\n",
    "#the following pair of functions implements consolidation of a tensor using theano scan -- not the fastest, but its inherently\n",
    "#difficult to vectorize.\n",
    "def singleConsol(tensor, indices):\n",
    "    return (T.choose(indices, tensor)).sum()\n",
    "\n",
    "def consolidateTensor(tensor, consolinds, consolcomplete):\n",
    "    irange = T.arange(getV2Length(consolinds))\n",
    "    consolidated, updates = theano.scan(fn = lambda ind, tens, coninds, concomp: singleConsol(tens, getSubV2(ind, coninds, concomp)),\n",
    "                                        sequences = irange,\n",
    "                                        non_sequences=[tensor, consolinds, consolcomplete])\n",
    "    return consolidated\n",
    "\n",
    "def consolidateTensorCheck():\n",
    "    x = T.vector('x')\n",
    "    inds = T.ivector('inds')\n",
    "    complete = T.ivector('complete')\n",
    "    y = consolidateTensor(x,inds,complete)\n",
    "    f = theano.function([x,inds,complete], y)\n",
    "    print f(np.array([1.0,2.0,4.0,8.0]).astype(theano.config.floatX), np.array([0,3,4]).astype('int32'), np.array([1,2,3,0]).astype('int32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "QSaXtAM_o8gB",
    "outputId": "e4de1289-9fd1-49fe-8413-9bf3e368acce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.]\n",
      "running initial singleGenConsolidate\n",
      "starting a singleGenConsolidate\n",
      "half way done a singleGenConsolidate\n",
      "finished a singleGenConsolidate\n",
      "starting to loop\n",
      "starting a singleGenConsolidate\n",
      "half way done a singleGenConsolidate\n",
      "finished a singleGenConsolidate\n",
      "first version took: 0.000130176544189\n",
      "looped\n",
      "starting a singleGenConsolidate\n",
      "half way done a singleGenConsolidate\n",
      "finished a singleGenConsolidate\n",
      "first version took: 0.00011682510376\n",
      "looped\n",
      "starting a singleGenConsolidate\n",
      "half way done a singleGenConsolidate\n",
      "finished a singleGenConsolidate\n",
      "first version took: 0.000127077102661\n",
      "looped\n",
      "starting a singleGenConsolidate\n",
      "half way done a singleGenConsolidate\n",
      "finished a singleGenConsolidate\n",
      "first version took: 0.000118970870972\n",
      "looped\n",
      "starting a singleGenConsolidate\n",
      "half way done a singleGenConsolidate\n",
      "finished a singleGenConsolidate\n",
      "first version took: 0.000164031982422\n",
      "looped\n",
      "starting a singleGenConsolidate\n",
      "half way done a singleGenConsolidate\n",
      "finished a singleGenConsolidate\n",
      "first version took: 0.000115871429443\n",
      "looped\n",
      "starting a singleGenConsolidate\n",
      "half way done a singleGenConsolidate\n",
      "finished a singleGenConsolidate\n",
      "first version took: 0.000116109848022\n",
      "looped\n",
      "starting a singleGenConsolidate\n",
      "half way done a singleGenConsolidate\n",
      "finished a singleGenConsolidate\n",
      "first version took: 0.000116109848022\n",
      "looped\n",
      "biased and tanned: [ 0.0347343   0.06947865  0.08532283  0.14944834  0.13112794]\n",
      "biased and tanned: [ 0.00502553  0.04479414  0.01742804  0.03567469  0.04866783]\n",
      "biased and tanned: [ 0.02624959  0.045532    0.04871766  0.0297341   0.03935651]\n",
      "biased and tanned: [ 0.02320174  0.01215105  0.04823627  0.01270124  0.01075621]\n",
      "biased and tanned: [ 0.03496046  0.00249008  0.04515846  0.00926307  0.01823232]\n",
      "biased and tanned: [ 0.04780548  0.03011359  0.02207352  0.01809545  0.03796417]\n",
      "biased and tanned: [ 0.042976    0.02375921  0.04603051  0.01913313  0.04622111]\n",
      "biased and tanned: [ 0.03190861  0.02779615  0.00999493  0.04863133  0.02476974]\n",
      "biased and tanned: [ 0.0248273   0.01015288  0.0350741   0.01084486  0.03110566]\n",
      "[ 0.49129802  0.18162602  0.07252176  0.69363208]\n",
      "[array([ 0.0347343 ,  0.06947865,  0.08532283,  0.14944834,  0.13112794], dtype=float32), array([ 0.00502553,  0.04479414,  0.01742804,  0.03567469,  0.04866783], dtype=float32), array([ 0.02624959,  0.045532  ,  0.04871766,  0.0297341 ,  0.03935651], dtype=float32), array([ 0.02320174,  0.01215105,  0.04823627,  0.01270124,  0.0107562 ], dtype=float32), array([ 0.03496046,  0.00249008,  0.04515846,  0.00926307,  0.01823232], dtype=float32), array([ 0.04780548,  0.03011359,  0.02207352,  0.01809545,  0.03796417], dtype=float32), array([ 0.042976  ,  0.02375921,  0.04603051,  0.01913313,  0.04622111], dtype=float32), array([ 0.03190861,  0.02779615,  0.00999494,  0.04863133,  0.02476974], dtype=float32), array([ 0.0248273 ,  0.01015288,  0.0350741 ,  0.01084486,  0.03110566], dtype=float32)]\n",
      "CudaNdarray([ -0.00000000e+00  -0.00000000e+00  -7.09794862e-11  -3.09437059e-11\n",
      "  -6.40680911e-11  -1.41958972e-10  -9.61021401e-11  -1.08071579e-10])\n",
      "CudaNdarray([ -2.95477423e-12  -2.95477423e-12  -6.07544431e-11  -6.88297475e-11\n",
      "  -8.45259487e-11  -1.87352998e-11  -1.30682604e-10  -1.30682604e-10\n",
      "  -1.14662634e-10  -9.51916185e-11])\n",
      "CudaNdarray([ -7.73152983e-12  -7.73152983e-12  -6.45888787e-10  -6.45888787e-10\n",
      "  -2.51295790e-10  -1.34689898e-10  -2.75706236e-10  -5.48157020e-10\n",
      "  -7.01743719e-10  -7.19095450e-10])\n",
      "CudaNdarray([ -1.05721532e-09  -1.05721532e-09  -1.30148967e-08  -1.30148967e-08\n",
      "  -1.39254848e-08  -6.58210109e-09  -4.01728784e-09  -7.16572046e-09\n",
      "  -1.12496901e-08  -8.83219364e-09])\n",
      "CudaNdarray([ -1.33953897e-08  -1.33953897e-08  -6.74390037e-08  -6.74390037e-08\n",
      "  -2.67713887e-07  -2.70548526e-07  -7.12389863e-08  -1.29305331e-08\n",
      "  -5.96975198e-08  -1.77088371e-08])\n",
      "CudaNdarray([ -2.90448043e-07  -2.90448043e-07  -1.86532347e-07  -1.86532347e-07\n",
      "  -3.38282462e-06  -3.40887232e-06  -6.99240331e-07  -1.31861659e-08\n",
      "  -1.36578433e-06  -7.22607467e-07])\n",
      "CudaNdarray([ -1.00522138e-05  -1.00522138e-05  -5.97802828e-05  -5.97802828e-05\n",
      "  -4.38194693e-05  -2.90530697e-05  -2.38171451e-05  -6.42616897e-07\n",
      "  -7.53649438e-05  -3.53178402e-05])\n",
      "CudaNdarray([ -9.20780119e-04  -9.20780119e-04  -6.73925213e-04  -6.73925213e-04\n",
      "  -1.30564650e-03  -3.11780081e-04  -1.29595079e-04   2.27289402e-05\n",
      "  -1.31105282e-03  -7.13181274e-04])\n",
      "CudaNdarray([-0.01025385 -0.01025385 -0.00977619 -0.00977619 -0.00351532  0.00172284\n",
      "  0.00838264 -0.02166439 -0.00871177 -0.00523897])\n",
      "[ -0.00000000e+00  -0.00000000e+00  -7.09794862e-11  -3.09437059e-11\n",
      "  -6.40680911e-11  -1.41958972e-10  -9.61021401e-11  -1.08071579e-10]\n",
      "[ -2.95477423e-12  -2.95477423e-12  -6.07544431e-11  -6.88297475e-11\n",
      "  -8.45259487e-11  -1.87352998e-11  -1.30682604e-10  -1.30682604e-10\n",
      "  -1.14662634e-10  -9.51916185e-11]\n",
      "[ -7.73152983e-12  -7.73152983e-12  -6.45888787e-10  -6.45888787e-10\n",
      "  -2.51295790e-10  -1.34689898e-10  -2.75706236e-10  -5.48157020e-10\n",
      "  -7.01743719e-10  -7.19095450e-10]\n",
      "[ -1.05721532e-09  -1.05721532e-09  -1.30148967e-08  -1.30148967e-08\n",
      "  -1.39254848e-08  -6.58210109e-09  -4.01728784e-09  -7.16572046e-09\n",
      "  -1.12496901e-08  -8.83219364e-09]\n",
      "[ -1.33953897e-08  -1.33953897e-08  -6.74390037e-08  -6.74390037e-08\n",
      "  -2.67713887e-07  -2.70548526e-07  -7.12389863e-08  -1.29305331e-08\n",
      "  -5.96975198e-08  -1.77088371e-08]\n",
      "[ -2.90448043e-07  -2.90448043e-07  -1.86532347e-07  -1.86532347e-07\n",
      "  -3.38282462e-06  -3.40887232e-06  -6.99240331e-07  -1.31861659e-08\n",
      "  -1.36578433e-06  -7.22607467e-07]\n",
      "[ -1.00522147e-05  -1.00522147e-05  -5.97802828e-05  -5.97802828e-05\n",
      "  -4.38194693e-05  -2.90530697e-05  -2.38171451e-05  -6.42616897e-07\n",
      "  -7.53649438e-05  -3.53178402e-05]\n",
      "[ -9.20780236e-04  -9.20780236e-04  -6.73925213e-04  -6.73925213e-04\n",
      "  -1.30564650e-03  -3.11780081e-04  -1.29595079e-04   2.27289402e-05\n",
      "  -1.31105282e-03  -7.13181274e-04]\n",
      "[-0.01025385 -0.01025385 -0.00977619 -0.00977619 -0.00351532  0.00172284\n",
      "  0.00838264 -0.02166439 -0.00871177 -0.00523897]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[numpy.ndarray,\n",
       " numpy.ndarray,\n",
       " numpy.ndarray,\n",
       " numpy.ndarray,\n",
       " numpy.ndarray,\n",
       " numpy.ndarray,\n",
       " numpy.ndarray,\n",
       " numpy.ndarray,\n",
       " numpy.ndarray]"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this class is essentially the same as nnet above, except that I implemented it in Theano for speed. All of the derivatives are \n",
    "#explicitly calculated, as I wasn't able to get theano to differentiate it. A lot of the set up is actually accomplished by the \n",
    "#previous class that used numpy.\n",
    "    \n",
    "from random import shuffle\n",
    "\n",
    "class tnnet:\n",
    "    def __init__(self, resolution, functions, inputdimension, traindatainps, traindataoutps, testdatainps, testdataoutps, synapseThreshold, net = None):\n",
    "        \n",
    "        mynet = None\n",
    "        if net == None:\n",
    "            mynet = nnet(resolution, functions, inputdimension, traindatainps, traindataoutps, synapseThreshold)\n",
    "            mynet.genConsolidate()\n",
    "            mynet.genWeights()\n",
    "        else:\n",
    "            mynet = net\n",
    "        self.nnet = mynet\n",
    "        \n",
    "\n",
    "        self.sharedTrainingInps = shared(np.array(traindatainps).astype(theano.config.floatX))\n",
    "        self.sharedTrainingOutps = shared(np.array(traindataoutps).astype(theano.config.floatX))\n",
    "        self.sharedTestingInps = shared(np.array(testdatainps).astype(theano.config.floatX))\n",
    "        self.sharedTestingOutps = shared(np.array(testdataoutps).astype(theano.config.floatX))\n",
    "\n",
    "\n",
    "#         print \"weights: \" + str(mynet.weights)\n",
    "#         print \"biases: \" + str(mynet.biases)\n",
    "#         print mynet.feedforward(np.array([0,1,2,3]).astype(theano.config.floatX))\n",
    "#         inp_lengths = [len(consol) for consol in mynet.consolidations]\n",
    "#         inp_lengths = [datainps[0].size] + inp_lengths\n",
    "#         self.inp_lengths = np.array(inp_lengths).astype('int32')\n",
    "#         print \"inp_lengths: \" + str(inp_lengths)\n",
    "#         print \"dinp length: \" + str(datainps[0].size)\n",
    "#         print \"consolidations: \" + str(mynet.consolidations)\n",
    "        \n",
    "#         self.maxInp = np.amax(inp_lengths)\n",
    "#         self.maxPad = shared(np.array([0] * (np.amax(inp_lengths) - min(inp_lengths))).astype(theano.config.floatX))\n",
    "#         self.maxZeroes = shared(np.array([0.0] * self.maxInp).astype(theano.config.floatX))\n",
    "        \n",
    "#         initialPaddingLength = np.amax(inp_lengths) - datainps[0].size\n",
    "#         self.initialPadding = shared(np.array([0.0] * initialPaddingLength).astype(theano.config.floatX))\n",
    "#         self.inp_lengths = shared(self.inp_lengths)\n",
    "        \n",
    "        tweights = V2IndexedShared(theano.config.floatX)\n",
    "        tweights.fromList(mynet.weights)\n",
    "        self.weights = map(lambda x: shared(np.array(x).astype(theano.config.floatX)), mynet.weights)\n",
    "        \n",
    "        tbiases = V2IndexedShared(theano.config.floatX)\n",
    "        tbiases.fromList(mynet.biases)\n",
    "#         print tbiases.complete.get_value()\n",
    "        self.biases = map(lambda x: shared(np.array(x).astype(theano.config.floatX)), mynet.biases)\n",
    "    \n",
    "        tcons = V3IndexedShared(mynet.consolidations, 'int32')\n",
    "#         print \"final weights: \" + str(mynet.finalweights)\n",
    "        tfws = shared((mynet.finalweights).astype(theano.config.floatX))\n",
    "        tfbs = shared((mynet.finalbiases).astype(theano.config.floatX))\n",
    "        self.weightnum = mynet.weightnum\n",
    "        self.hiddenlayers = mynet.hiddenlayers\n",
    "        \n",
    "        self.consolMasks = []\n",
    "        self.dEdWsinverseConsols = []\n",
    "        self.oneMultipliers = []\n",
    "        \n",
    "        #this loop fulfills two important functions. First, it makes consolmasks from consolidation lists\n",
    "        #Second, it creates inverse consolidation lists, going from the next layer back to the original layer,\n",
    "        #which is crucial for backpropagation.\n",
    "        for layerConsols in mynet.consolidations:\n",
    "#             print \"initial \" + str(layerConsols)\n",
    "            maxInLength = max(map(len, layerConsols))\n",
    "            inLength = len(flatten(layerConsols))\n",
    "            extended = map(lambda l: l + [inLength] * (maxInLength - len(l)), layerConsols)\n",
    "#             print \"extended: \" + str(extended)\n",
    "            self.consolMasks.append(shared(np.array(extended).astype('int32')))\n",
    "            self.oneMultipliers.append(shared(np.array([1.0] * maxInLength).astype(theano.config.floatX)))\n",
    "            \n",
    "            flattened = flatten(layerConsols)\n",
    "            frame = [0] * len(flattened)\n",
    "            for i in range(len(layerConsols)):\n",
    "                for sub in layerConsols[i]:\n",
    "                    frame[sub] = i\n",
    "            \n",
    "            self.dEdWsinverseConsols.append(shared(np.array(frame).astype('int32')))\n",
    "        \n",
    "#         print self.nnet.consolidations[0]\n",
    "#         print self.dEdWsinverseConsols[0].get_value()\n",
    "            \n",
    "        \n",
    "        \n",
    "        inp = T.fvector('inp')\n",
    "#         paddedInp = T.concatenate([inp, self.initialPadding])\n",
    "        actualOutp = T.fvector('actualOutp')\n",
    "        alpha = T.fscalar('alpha')\n",
    "        \n",
    "        self.consolidations = map(lambda x: V2IndexedShared('int32').fromList(x), self.nnet.consolidations)\n",
    "        \n",
    "        self.winds = tweights.inds\n",
    "        self.ws = tweights.complete\n",
    "        self.binds = tbiases.inds\n",
    "        self.bs = tbiases.complete\n",
    "        self.consindinds = tcons.D3Inds\n",
    "        self.consinds = tcons.D2Inds\n",
    "        self.cons = tcons.complete\n",
    "        self.bMult = shared(np.asscalar(np.array([mynet.branchMultiplier]).astype('int32')))\n",
    "        self.fws = tfws\n",
    "        self.fbs = tfbs\n",
    "#         print \"weights: \" + '\\n'.join(map(str, self.nnet.weights))\n",
    "# #         print self.nnet.biases\n",
    "#         print \"inverse Consols: \" + '\\n'.join(map(lambda x: str(x.get_value().tolist()), self.dEdWsinverseConsols))\n",
    "#         print \"consols: \" + '\\n'.join(map(str, self.nnet.consolidations))\n",
    "        self.zeropad = shared(np.array([0.0]).astype(theano.config.floatX))\n",
    "        \n",
    "        self.bMultOnes = shared(np.array([1.0] * self.nnet.branchMultiplier).astype(theano.config.floatX))\n",
    "        \n",
    "        self.params = self.weights + self.biases + [self.fws, self.fbs]\n",
    "#         self.constparams = [self.consindinds, self.consinds, self.cons, self.winds, self.binds, self.bMult]\n",
    "        \n",
    "#         def singleCons(consInds, tens):\n",
    "#             asum, _ = theano.scan(fn = lambda i, tensor: tensor[i],\n",
    "#                                  sequences = consInds,\n",
    "#                                  non_sequences = tens)\n",
    "#             return asum.sum()\n",
    "        \n",
    "        \n",
    "#         def layer(ind, inpLength, inp):\n",
    "#             weights = getSubV2(ind, self.winds, self.ws)\n",
    "#             biases = getSubV2(ind, self.binds, self.bs)\n",
    "#             consolinds, consols = getSubV3(ind, self.consindinds, self.consinds, self.cons)\n",
    "#             inp = T.repeat(inp[0:inpLength], self.bMult)\n",
    "#             inp = weights * inp\n",
    "            \n",
    "#             #consolidation code\n",
    "#             numConsolidatedRange = T.arange(consolinds.size - 1)\n",
    "#             inp, _ = theano.scan(fn = lambda ind, x, coninds, concomp: singleCons(getSubV2(ind, coninds, concomp), x),\n",
    "#                                                 sequences = numConsolidatedRange,\n",
    "#                                                 non_sequences=[inp, consolinds, consols])\n",
    "#             inp = inp + biases\n",
    "#             inp = relu(inp)\n",
    "#             padding = self.maxPad[0 : self.maxInp - inp.size]\n",
    "#             inp = T.concatenate([inp, padding])\n",
    "#             return inp\n",
    "       \n",
    "        def layer(ind, x):\n",
    "            #get output of layer ind with input x\n",
    "            \n",
    "#             print \"in layer\"\n",
    "#             consolinds = self.consolidations[ind].inds\n",
    "#             consols = self.consolidations[ind].complete\n",
    "            \n",
    "            x = T.repeat(x, self.bMult) * self.weights[ind]\n",
    "            x = T.concatenate([x, T.zeros_like(x)])\n",
    "            x = (x.take(self.consolMasks[ind]).astype(theano.config.floatX)) #.sum(axis = 1)\n",
    "            x = T.dot(x, self.oneMultipliers[ind])\n",
    "# #             inp, _ = theano.map(fn = lambda i: inp[i],\n",
    "# #                                sequences = consols)\n",
    "# #             #consolidation code\n",
    "#             r = T.arange(consolinds.size - 1).astype(theano.config.floatX)\n",
    "#             for i in xrange(len(self.nnet.consolidations[ind])):\n",
    "#                 r = T.set_subtensor(r[i], x[consolinds[i]:consolinds[i + 1]].sum())\n",
    "#             numConsolidatedRange = T.arange(consolinds.size - 1).astype('int32')\n",
    "# #             inp2, _ = theano.map(fn = lambda i: inp1[consolinds[i]: consolinds[i + 1]].sum(),\n",
    "# #                                                 sequences = numConsolidatedRange)\n",
    "#             r, _ = theano.map(fn = lambda i, x: x[consolinds[i]: consolinds[i+1]].sum(),\n",
    "#                                                 sequences = numConsolidatedRange,\n",
    "#                                                 non_sequences=[x])\n",
    "            return theano.tensor.nnet.relu(x + self.biases[ind])\n",
    "#             return r\n",
    "\n",
    "        def gradLayer(ind, nextdEdInputs, layerOutput): #returns (dEdWs, dEdBs, newdEdInputs)\n",
    "            expandedLayerOutput = T.repeat(layerOutput, self.bMult)\n",
    "            inverse = self.dEdWsinverseConsols[ind]\n",
    "            inverseddEdInputs = nextdEdInputs.take(inverse)\n",
    "            dEdWs = expandedLayerOutput * inverseddEdInputs\n",
    "            dEdBs = nextdEdInputs\n",
    "            #upt to here correct\n",
    "            \n",
    "            dOutsdIns = T.gt(layerOutput, T.zeros_like(layerOutput))\n",
    "            dOutsdIns = T.cast(dOutsdIns, 'float32')\n",
    "            \n",
    "            dEdConnections = self.weights[ind] * inverseddEdInputs\n",
    "            dEdConnectionGroups = dEdConnections.reshape((dEdConnections.size // self.bMult, self.bMult))\n",
    "            dEdOuts = T.dot(dEdConnectionGroups, self.bMultOnes) #could need to be axis 1\n",
    "            \n",
    "            newdEdInputs = dEdOuts * dOutsdIns\n",
    "            \n",
    "            return (dEdWs, dEdBs, newdEdInputs)\n",
    "        \n",
    "        def intermediateLoop(z):\n",
    "            ret = []\n",
    "            for i in range(self.hiddenlayers):\n",
    "                z = layer(i, z)\n",
    "                ret.append(z.copy())\n",
    "            \n",
    "            return ret\n",
    "        \n",
    "        def gradLoop(dEdIn, layerOutputs):\n",
    "            dEdWs = []\n",
    "            dEdBs = []\n",
    "            for k in reversed(range(self.hiddenlayers)):\n",
    "                newdEdWs, newdEdBs, dEdIn = gradLayer(k, dEdIn, layerOutputs[k])\n",
    "                dEdWs.append(newdEdWs)\n",
    "                dEdBs.append(newdEdBs)\n",
    "            \n",
    "            return dEdWs, dEdBs\n",
    "        \n",
    "        def myGrad(theta, actualOutp):\n",
    "            #get gradient given input (theta) and the target output (actualOutp)\n",
    "            \n",
    "            #get all layer outputs\n",
    "            outputs = intermediateLoop(theta)\n",
    "            \n",
    "            #list of all outputs, including input layer \"outputs\"\n",
    "            outputs = [theta] + outputs\n",
    "            \n",
    "            #calculate final output\n",
    "            last = T.dot(outputs[-1], self.fws)\n",
    "            last = last + self.fbs\n",
    "            last = theano.tensor.nnet.relu(last)\n",
    "            \n",
    "            #get error\n",
    "            difference = last - actualOutp\n",
    "            err = T.dot(difference, difference)\n",
    "            \n",
    "            #get final layer derivative\n",
    "            finaldOutdIn = T.gt(last, T.zeros_like(last))\n",
    "            finaldOutdIn = T.cast(finaldOutdIn, 'float32')\n",
    "            \n",
    "            #get derivative of error with respect to last layer inputs\n",
    "            initdEdIn = finaldOutdIn * (last - actualOutp)\n",
    "            dEdFbs = initdEdIn   \n",
    "            \n",
    "            \n",
    "            initdEdInshuffled = initdEdIn.dimshuffle(('x',0))\n",
    "            finalStructuredLayerOut = outputs[-1]\n",
    "            finalStructuredLayerOutShuffled = finalStructuredLayerOut.dimshuffle((0,'x'))\n",
    "            \n",
    "            dEdFws = finalStructuredLayerOutShuffled * initdEdInshuffled\n",
    "            \n",
    "            \n",
    "            finalStructuredLayerdOutdIn = T.gt(finalStructuredLayerOut, T.zeros_like(finalStructuredLayerOut))\n",
    "            finalStructuredLayerdOutdIn = T.cast(finalStructuredLayerdOutdIn, 'float32')\n",
    "            \n",
    "            finalStructuredLayerdEdOut = T.dot(initdEdIn, self.fws.T)\n",
    "            \n",
    "            finalStructuredLayerdEdIn = finalStructuredLayerdOutdIn * finalStructuredLayerdEdOut\n",
    "            #up to here is correct\n",
    "\n",
    "            dEdWs, dEdBs = gradLoop(finalStructuredLayerdEdIn, outputs)\n",
    "            \n",
    "            return err, list(reversed(dEdWs)), list(reversed(dEdBs)), dEdFws, dEdFbs #, list(reversed(dEdIns)),\n",
    "            \n",
    "            \n",
    "        final = T.fvector()\n",
    "        def loop(z):\n",
    "            ret = T.fvector()\n",
    "            for i in range(self.hiddenlayers):\n",
    "                z = layer(i, z)\n",
    "                ret = z\n",
    "            return ret\n",
    "        finalHiddenOutput = loop(inp)\n",
    "        final = T.dot(finalHiddenOutput, self.fws)\n",
    "        final = final + self.fbs\n",
    "        final = theano.tensor.nnet.relu(final)\n",
    "        \n",
    "        #Declare theano functions for full classifaction (including end relu linerar classifier)\n",
    "        self.classify = theano.function([inp], final)\n",
    "        self.partialClassify = theano.function([inp], finalHiddenOutput)\n",
    "        \n",
    "        self.partialClassifyTraining = theano.function(inputs= [index], outputs = finalHiddenOutput,\n",
    "                                                       givens = {\n",
    "                                                                        inp : self.sharedTrainingInps[index],\n",
    "                                                                    } )\n",
    "        self.partialClassifyTesting = theano.function(inputs=[index], outputs = finalHiddenOutput,\n",
    "                                                     givens = {\n",
    "                                                         inp : self.sharedTestingInps[index]\n",
    "                                                     })\n",
    "        \n",
    "        diff = final - actualOutp\n",
    "        squared = 0.5 * T.dot(diff, diff)\n",
    "\n",
    "#         print self.classify(np.array([0,1,2,3]).astype(theano.config.floatX))\n",
    "\n",
    "        index = T.iscalar()\n",
    "\n",
    "        squaredError, wgrads, bgrads, fwsgrads, fbsgrads = myGrad(inp, actualOutp)\n",
    "#         mygradients = myGrad(inp, actualOutp)\n",
    "        self.realGrad = theano.function(inputs = [inp, actualOutp], outputs = T.grad(squared, self.weights))\n",
    "        self.mygrads = theano.function(inputs = [inp, actualOutp], outputs = wgrads)\n",
    "        \n",
    "        #concatenate lists of the gradients so as to iteratively modify them -- don't worry, I'm not just adding them together\n",
    "        gradients = wgrads + bgrads + [fwsgrads, fbsgrads]\n",
    "        \n",
    "#         realgrads = T.grad(squared, self.params)\n",
    "#         realUpdates = OrderedDict((p, p - alpha * g) for p, g in zip(self.params, realgrads))\n",
    "        param_Updates = OrderedDict((p, p - alpha * g) for p, g in zip(self.params, gradients))\n",
    "        \n",
    "        self.intermediates = theano.function([inp], intermediateLoop(inp))\n",
    "        \n",
    "        self.train = theano.function(inputs = [index, alpha],\n",
    "                                                                    outputs = squaredError,\n",
    "                                                                    updates = param_Updates,\n",
    "                                                                    givens = {\n",
    "                                                                        inp : self.sharedTrainingInps[index],\n",
    "                                                                        actualOutp: self.sharedTrainingOutps[index]\n",
    "                                                                    })\n",
    "#         self.realtrain = theano.function(inputs = [index, alpha],\n",
    "#                                                                     outputs = squared,\n",
    "#                                                                     updates = realUpdates,\n",
    "#                                                                     givens = {\n",
    "#                                                                         inp : self.sharedTrainingInps[index],\n",
    "#                                                                         actualOutp: self.sharedTrainingOutps[index]\n",
    "#                                                                     })\n",
    "        self.test = theano.function(inputs = [index],\n",
    "            outputs = final,\n",
    "            givens = {\n",
    "                inp : self.sharedTestingInps[index]\n",
    "            })\n",
    "    \n",
    "    def descend(self, alpha, epochs, trainingInps, trainingOutps, testingInps, testingOutps, verbose):\n",
    "        training = zip(trainingInps, trainingOutps)\n",
    "        testing = zip(testingInps, testingOutps)\n",
    "        testLen = len(testing)\n",
    "        trainLen = len(trainingInps)\n",
    "        indorder = range(trainLen)\n",
    "        testingAccuracies = []\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            print \"starting epoch...\"\n",
    "            start = time.time()\n",
    "            shuffle(indorder)\n",
    "            for j in indorder:\n",
    "                self.train(j, alpha)\n",
    "            \n",
    "            testingAccuracy = 0.0\n",
    "            for j in range(len(testingOutps)):\n",
    "                if np.argmax(self.test(j)) == np.argmax(testingOutps[j]):\n",
    "                    testingAccuracy += 1.0\n",
    "            # for (testInp, testOutp) in testing:\n",
    "            #     if np.argmax(self.classify(testInp)) == np.argmax(testOutp):\n",
    "            #         testingAccuracy += 1.0\n",
    "                    \n",
    "            percentTestingAccuracy = testingAccuracy / testLen * 100.0\n",
    "            testingAccuracies.append(percentTestingAccuracy)\n",
    "            end = time.time()\n",
    "            if verbose:\n",
    "                print \"epoch \" + str(i + 1) + \" -- testing accuracy : \" + str(percentTestingAccuracy) + \" duration: \" + str(end - start) + \"s\"\n",
    "        \n",
    "        return max(testingAccuracies), testingAccuracies\n",
    "            \n",
    "        \n",
    "tn = tnnet(10, [[lambda x: x + 1], [lambda x: x * 2]], 1, [np.array([0,1,2,3])], [np.array([1,2,3,4])],  [np.array([1,2,3,4])],  [np.array([1,2,3,4])], 100)\n",
    "print tn.nnet.feedforward(np.array([0,1,2,3]))\n",
    "print tn.intermediates(np.array([0,1,2,3]).astype(theano.config.floatX))\n",
    "# print tn.nnet.weights\n",
    "# print tn.nnet.biases\n",
    "x = np.array([0,1,2,3]).astype(theano.config.floatX)\n",
    "classed = tn.classify(np.array([0,1,2,3]).astype(theano.config.floatX))\n",
    "# print '\\n'.join(map(str,classed))\n",
    "# diff = x * 0.5 - classed\n",
    "# print np.dot(diff, diff)\n",
    "# print tn.classify(np.array([0,1,2,3]).astype(theano.config.floatX))\n",
    "print '\\n'.join(map(str, tn.realGrad(x, x * 0.33)))\n",
    "print '\\n'.join(map(str, tn.mygrads(x, x*0.33)))\n",
    "map(type, tn.mygrads(x, x * 0.33))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "nj8CfYB8o8gQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "lDEgKax3o8gb",
    "outputId": "1c206e12-9712-4c4d-ab70-1687de132e4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating\n",
      "running initial singleGenConsolidate\n",
      "starting a singleGenConsolidate\n",
      "half way done a singleGenConsolidate\n",
      "finished a singleGenConsolidate\n",
      "starting to loop\n",
      "branchmultiplier: 33\n",
      "weights length: 25872\n",
      "average number of connections per neuron by layer: [1.0]\n",
      "spacial dimension: 7\n",
      "branching by layer: [3, 10, 4, 4, 2, 5, 5]\n",
      "beginning training\n",
      "trained in: 0.00302386283875\n",
      "115600.453125\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "autograd trained in: 0.00561690330505\n",
      "starting epoch...\n",
      "epoch 1 -- testing accuracy : 9.8 duration: 161.044973135s\n",
      "starting epoch...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-eb3ea0c518e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m \u001b[0mevolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmnistevaluate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-fe38bb5d846a>\u001b[0m in \u001b[0;36mevolve\u001b[1;34m(evaluator)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m     \u001b[1;33m(\u001b[0m\u001b[0mfinalPop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogbook\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meaMuPlusLambda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLAMBDA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCXPB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMUTPB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGENERATIONS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmyStats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhalloffame\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhallOFame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0mgen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"gen\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/deap/algorithms.pyc\u001b[0m in \u001b[0;36meaMuPlusLambda\u001b[1;34m(population, toolbox, mu, lambda_, cxpb, mutpb, ngen, stats, halloffame, verbose)\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[1;31m# Evaluate the individuals with an invalid fitness\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[0minvalid_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpopulation\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m     \u001b[0mfitnesses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoolbox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minvalid_ind\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minvalid_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfitnesses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m         \u001b[0mind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-66-eb3ea0c518e8>\u001b[0m in \u001b[0;36mmnistevaluate\u001b[1;34m(individual)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m\"autograd trained in: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtestStart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     \u001b[0mavgpercenttestAccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mavgpercenttestAccuracylist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.02\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainingimgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtraininglabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestingimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestinglabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mavgpercenttestAccuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-64-0ad62b9e291b>\u001b[0m in \u001b[0;36mdescend\u001b[1;34m(self, alpha, epochs, trainingInps, trainingOutps, testingInps, testingOutps, verbose)\u001b[0m\n\u001b[0;32m    411\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindorder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindorder\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 413\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    414\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m             \u001b[0mtestingAccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import deap.gp as gp\n",
    "import time\n",
    "import sys\n",
    "import sklearn.svm as svm\n",
    "sys.setrecursionlimit(1500)\n",
    "\n",
    "def mnistevaluate(individual):\n",
    "    weights = []\n",
    "    biases = []\n",
    "    branching = 0\n",
    "    consolidations = []\n",
    "    fws = []\n",
    "    fbs = []\n",
    "    hiddenlayers = 0\n",
    "    weightnum = 0\n",
    "    branching = 0\n",
    "    \n",
    "    print \"evaluating\"\n",
    "    funcs = []\n",
    "    for dimlist in individual:\n",
    "        newDimlist = []\n",
    "        for tree in dimlist:\n",
    "#             print gp.stringify(tree)\n",
    "            f = gp.compile(tree, pset)\n",
    "            newDimlist.append(f)\n",
    "        funcs.append(newDimlist)\n",
    "    \n",
    "    res = 20\n",
    "    tnet = tnnet(res, funcs, 2, trainingimgs, traininglabels, testingimgs, testinglabels, 200000)\n",
    "    mynet = tnet.nnet\n",
    "    weights = mynet.weights\n",
    "    biases = mynet.biases\n",
    "    branching = mynet.branchMultiplier\n",
    "    consolidations = mynet.consolidations\n",
    "    fws = mynet.finalweights\n",
    "    fbs = mynet.finalbiases\n",
    "    hiddenlayers = mynet.hiddenlayers\n",
    "    weightnum = mynet.weightnum\n",
    "    print \"branchmultiplier: \" + str(mynet.branchMultiplier)\n",
    "    print \"weights length: \" + str(len(flatten(mynet.weights)))\n",
    "#     print \"consolidations lengths\" + str(map(len, mynet.consolidations))\n",
    "    layerDensities = []\n",
    "    prevlayerLength = trainingimgs[0].size\n",
    "    for layer in mynet.weights:\n",
    "        layerLength = len(layer)\n",
    "        branched = prevlayerLength * mynet.branchMultiplier\n",
    "        layerDensities.append((1.0 * branched) / layerLength)\n",
    "        prevlayerLength = layerLength\n",
    "    print \"average number of connections per neuron by layer: \" + str(layerDensities)\n",
    "    print \"spacial dimension: \" + str(len(funcs))\n",
    "    print \"branching by layer: \" + str(map(len, funcs))\n",
    "    print \"beginning training\"\n",
    "    testStart = time.time()\n",
    "    x = tnet.train(0, 0.05)\n",
    "    print \"trained in: \" + str(time.time() - testStart)\n",
    "    print x\n",
    "    print tnet.classify(trainingimgs[0])\n",
    "#     testStart = time.time()\n",
    "#     x = tnet.realtrain(0, 0.05)\n",
    "    print \"autograd trained in: \" + str(time.time() - testStart)\n",
    "    \n",
    "    avgpercenttestAccuracy, avgpercenttestAccuracylist = tnet.descend(0.02, 5, trainingimgs,traininglabels, testingimgs, testinglabels, True)\n",
    "    return avgpercenttestAccuracy\n",
    "\n",
    "def mnistEvaluateRandomWeights(individual):\n",
    "    weights = []\n",
    "    biases = []\n",
    "    branching = 0\n",
    "    consolidations = []\n",
    "    fws = []\n",
    "    fbs = []\n",
    "    hiddenlayers = 0\n",
    "    weightnum = 0\n",
    "    branching = 0\n",
    "    \n",
    "    print \"evaluating\"\n",
    "    funcs = []\n",
    "    for dimlist in individual:\n",
    "        newDimlist = []\n",
    "        for tree in dimlist:\n",
    "#             print gp.stringify(tree)\n",
    "            f = gp.compile(tree, pset)\n",
    "            newDimlist.append(f)\n",
    "        funcs.append(newDimlist)\n",
    "    \n",
    "    res = 20\n",
    "    tnet = tnnet(res, funcs, 2, trainingimgs, traininglabels, testingimgs, testinglabels, 200000)\n",
    "    mynet = tnet.nnet\n",
    "    weights = mynet.weights\n",
    "    biases = mynet.biases\n",
    "    branching = mynet.branchMultiplier\n",
    "    consolidations = mynet.consolidations\n",
    "    fws = mynet.finalweights\n",
    "    fbs = mynet.finalbiases\n",
    "    hiddenlayers = mynet.hiddenlayers\n",
    "    weightnum = mynet.weightnum\n",
    "    print \"branchmultiplier: \" + str(mynet.branchMultiplier)\n",
    "    print \"weights length: \" + str(len(flatten(mynet.weights)))\n",
    "#     print \"consolidations lengths\" + str(map(len, mynet.consolidations))\n",
    "    layerDensities = []\n",
    "    prevlayerLength = trainingimgs[0].size\n",
    "    for layer in mynet.weights:\n",
    "        layerLength = len(layer)\n",
    "        branched = prevlayerLength * mynet.branchMultiplier\n",
    "        layerDensities.append((1.0 * branched) / layerLength)\n",
    "        prevlayerLength = layerLength\n",
    "    print \"average number of connections per neuron by layer: \" + str(layerDensities)\n",
    "    print \"spacial dimension: \" + str(len(funcs))\n",
    "    print \"branching by layer: \" + str(map(len, funcs))\n",
    "    print \"beginning training\"\n",
    "    testStart = time.time()\n",
    "    \n",
    "    #generate dataset with random weights\n",
    "    randomWeightsTrainingOutputs = []\n",
    "    for i in range(len(trainingimgs)):\n",
    "        randomWeightsTrainingOutputs.append(tnet.partialClassifyTraining(i))\n",
    "        \n",
    "    randomWeightsTestingOutputs = []\n",
    "    for i in range(len(testingimgs)):\n",
    "        randomWeightsTestingOutputs.append(tnet.partialClassifyTesting(i))\n",
    "        \n",
    "    mySVMclassifier = svm.LinearSVC()\n",
    "    mySVMclassifier.fit(randomWeightsTrainingOutputs, traininglabels)\n",
    "    accuracy = mySVMclassifier.score(randomWeightsTestingOutputs, testinglabels)\n",
    "    \n",
    "    return score\n",
    "    \n",
    "\n",
    "evolve(mnistevaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "sVPrn32Io8go",
    "outputId": "78405ad5-4013-41d4-8530-4fe2b807e272"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(fbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "NeYABakdo8g8",
    "outputId": "6ee523b4-f91c-499c-80c0-ef7a74d67c9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting theano net instance...\n"
     ]
    },
    {
     "ename": "UnusedInputError",
     "evalue": "theano.function was asked to create a function computing outputs given certain inputs, but the provided input variable at index 0 is not part of the computational graph needed to compute the outputs: inp.\nTo make this error into a warning, you can pass the parameter on_unused_input='warn' to theano.function. To disable it completely, use on_unused_input='ignore'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnusedInputError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-868a88d1e99c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m\"numpy classified in \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtestStart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mtnetFromParams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbiases\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfws\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfbs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsolidations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhiddenlayers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweightnum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbranching\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-868a88d1e99c>\u001b[0m in \u001b[0;36mtnetFromParams\u001b[1;34m(weights, biases, fws, fbs, consolidations, hiddenlayers, weightnum, branching)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbranchingmultiplier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbranching\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m\"starting theano net instance...\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mmytnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtnnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainingimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraininglabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestingimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestinglabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mtestStart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmytnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainingimgs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-a7fa26851401>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, resolution, functions, inputdimension, traindatainps, traindataoutps, testdatainps, testdataoutps, synapseThreshold, net)\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[0mfinal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassify\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m \u001b[1;31m#         print self.classify(np.array([0,1,2,3]).astype(theano.config.floatX))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/theano/compile/function.pyc\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[0;32m    318\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m                    output_keys=output_keys)\n\u001b[0m\u001b[0;32m    321\u001b[0m     \u001b[1;31m# We need to add the flag check_aliased inputs if we have any mutable or\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[1;31m# borrowed used defined inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/theano/compile/pfunc.pyc\u001b[0m in \u001b[0;36mpfunc\u001b[1;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[0;32m    477\u001b[0m                          \u001b[0maccept_inplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_inplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    478\u001b[0m                          \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 479\u001b[1;33m                          output_keys=output_keys)\n\u001b[0m\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36morig_function\u001b[1;34m(inputs, outputs, mode, accept_inplace, name, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[0;32m   1774\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1775\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1776\u001b[1;33m                    \u001b[0moutput_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1777\u001b[0m             defaults)\n\u001b[0;32m   1778\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, mode, accept_inplace, function_builder, profile, on_unused_input, fgraph, output_keys)\u001b[0m\n\u001b[0;32m   1413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1414\u001b[0m         \u001b[1;31m# Check if some input variables are unused\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1415\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_unused_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon_unused_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m         \u001b[1;31m# Make a list of (SymbolicInput|SymblicInputKits, indices,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m_check_unused_inputs\u001b[1;34m(self, inputs, outputs, on_unused_input)\u001b[0m\n\u001b[0;32m   1551\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mon_unused_input\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'raise'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1552\u001b[0m                     raise UnusedInputError(msg % (inputs.index(i),\n\u001b[1;32m-> 1553\u001b[1;33m                                                   i.variable, err_msg))\n\u001b[0m\u001b[0;32m   1554\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1555\u001b[0m                     raise ValueError(\"Invalid value for keyword \"\n",
      "\u001b[1;31mUnusedInputError\u001b[0m: theano.function was asked to create a function computing outputs given certain inputs, but the provided input variable at index 0 is not part of the computational graph needed to compute the outputs: inp.\nTo make this error into a warning, you can pass the parameter on_unused_input='warn' to theano.function. To disable it completely, use on_unused_input='ignore'."
     ]
    }
   ],
   "source": [
    "def tnetFromParams(weights, biases, fws, fbs, consolidations, hiddenlayers, weightnum, branching):\n",
    "    frame = nnet(10, [[lambda x: x + 1], [lambda x: x * 2]], 1, [np.array([0,1,2,3])], [np.array([1])], 100)\n",
    "    frame.weights = weights\n",
    "    frame.biases = biases\n",
    "    frame.finalweights = np.array(fws).astype(theano.config.floatX)\n",
    "    frame.finalbiases = np.array(fbs).astype(theano.config.floatX)\n",
    "    frame.consolidations = consolidations\n",
    "    frame.hiddenlayers = hiddenlayers\n",
    "    frame.weightnum = weightnum\n",
    "    frame.branchingmultiplier = branching\n",
    "    print \"starting theano net instance...\"\n",
    "    mytnet = tnnet(10, [[lambda x: x + 1], [lambda x: x * 2]], 1, trainingimgs, traininglabels, testingimgs, testinglabels, 5000, net = frame)\n",
    "    testStart = time.time()\n",
    "    x = mytnet.classify(trainingimgs[0])\n",
    "    print \"classified in \" + str(time.time() - testStart)\n",
    "    testStart = time.time()\n",
    "    x = frame.feedforward(trainingimgs[0])\n",
    "    print \"numpy classified in \" + str(time.time() - testStart)\n",
    "\n",
    "tnetFromParams(weights, biases, fws, fbs, consolidations, hiddenlayers, weightnum, branching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "yEp_G79Jo8hM",
    "outputId": "c5d71b76-ff5e-435a-c958-ef090f8006f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 0.752302922028\n",
      "Cost: 0.234828531853\n",
      "Cost: 0.217997165391\n",
      "Cost: 0.176582778796\n",
      "Cost: 0.0941889559431\n",
      "Cost: 0.0547008715418\n",
      "Cost: 0.0227962112237\n",
      "Cost: 0.0103721161976\n",
      "Cost: 0.00631427914256\n",
      "Cost: 0.00444667437915\n",
      "Cost: 0.00339910571615\n",
      "Cost: 0.00273639533448\n",
      "Cost: 0.00228238999109\n",
      "Cost: 0.00195317405859\n",
      "Cost: 0.00170428799655\n",
      "Cost: 0.00150985199376\n",
      "Cost: 0.00135402741352\n",
      "Cost: 0.00122653983734\n",
      "Cost: 0.00112027524709\n",
      "Cost: 0.00103046853549\n",
      "0.971243725343\n",
      "0.0324757818475\n",
      "0.97118115104\n",
      "0.0308740290756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 970 (CNMeM is disabled, cuDNN not available)\n"
     ]
    }
   ],
   "source": [
    "import theano.tensor.nnet as nnet\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "import numpy as np\n",
    "x = T.dvector()\n",
    "y = T.dscalar()\n",
    "def layer(x, w):\n",
    "    b = np.array([1], dtype=theano.config.floatX)\n",
    "    new_x = T.concatenate([x, b])\n",
    "    m = T.dot(w.T, new_x) #theta1: 3x3 * x: 3x1 = 3x1 ;;; theta2: 1x4 * 4x1\n",
    "    h = nnet.sigmoid(m)\n",
    "    return h\n",
    "def grad_desc(cost, theta):\n",
    "    alpha = 0.1 #learning rate\n",
    "    return theta - (alpha * T.grad(cost, wrt=theta))\n",
    "theta1 = theano.shared(np.array(np.random.rand(3,3), dtype=theano.config.floatX)) # randomly initialize\n",
    "theta2 = theano.shared(np.array(np.random.rand(4,1), dtype=theano.config.floatX))\n",
    "hid1 = layer(x, theta1) #hidden layer\n",
    "out1 = T.sum(layer(hid1, theta2)) #output layer\n",
    "fc = (out1 - y)**2 #cost expression\n",
    "\n",
    "\n",
    "cost = theano.function(inputs=[x, y], outputs=fc, updates=[\n",
    "        (theta1, grad_desc(fc, theta1)),\n",
    "        (theta2, grad_desc(fc, theta2))])\n",
    "run_forward = theano.function(inputs=[x], outputs=out1)\n",
    "inputs = np.array([[0,1],[1,0],[1,1],[0,0]]).reshape(4,2) #training data X\n",
    "exp_y = np.array([1, 1, 0, 0]) #training data Y\n",
    "cur_cost = 0\n",
    "for i in range(10000):\n",
    "    for k in range(len(inputs)):\n",
    "        cur_cost = cost(inputs[k], exp_y[k]) #call our Theano-compiled cost function, it will auto update weights\n",
    "    if i % 500 == 0: #only print the cost every 500 epochs/iterations (to save space)\n",
    "        print('Cost: %s' % (cur_cost,))\n",
    "        \n",
    "\n",
    "\n",
    "#Training done! Let's test it out\n",
    "print(run_forward([0,1]))\n",
    "print(run_forward([1,1]))\n",
    "print(run_forward([1,0]))\n",
    "print(run_forward([0,0]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3b6BDwT7o8hg",
    "outputId": "76a1e4e7-f4cf-411b-e5f3-1882464400a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GpuElemwise{exp,no_inplace}(<CudaNdarrayType(float32, vector)>), HostFromGpu(GpuElemwise{exp,no_inplace}.0)]\n",
      "Looping 1000 times took 0.332850 seconds\n",
      "Result is [ 1.23178029  1.61879349  1.52278066 ...,  2.20771813  2.29967761\n",
      "  1.62323296]\n",
      "Used the gpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 970 (CNMeM is disabled, cuDNN not available)\n"
     ]
    }
   ],
   "source": [
    "from theano import function, config, shared, sandbox\n",
    "import theano.tensor as T\n",
    "import numpy\n",
    "import time\n",
    "\n",
    "vlen = 10 * 30 * 768  # 10 x #cores x # threads per core\n",
    "iters = 1000\n",
    "\n",
    "rng = numpy.random.RandomState(22)\n",
    "x = shared(numpy.asarray(rng.rand(vlen), config.floatX))\n",
    "f = function([], T.exp(x))\n",
    "print(f.maker.fgraph.toposort())\n",
    "t0 = time.time()\n",
    "for i in range(iters):\n",
    "    r = f()\n",
    "t1 = time.time()\n",
    "print(\"Looping %d times took %f seconds\" % (iters, t1 - t0))\n",
    "print(\"Result is %s\" % (r,))\n",
    "if numpy.any([isinstance(x.op, T.Elemwise) for x in f.maker.fgraph.toposort()]):\n",
    "    print('Used the cpu')\n",
    "else:\n",
    "    print('Used the gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "ekPuNdbUo8h7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3G-IDP2bo8iK",
    "outputId": "e1f99a3d-02a6-4232-8845-70c8c603618c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  2.,  1.,  4.], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = T.fvector()\n",
    "y = x\n",
    "y = T.set_subtensor(y[3], 1)\n",
    "out = y\n",
    "f = theano.function([x], out)\n",
    "f(np.array(range(5)).astype(theano.config.floatX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "a1MNNkCvo8iW",
    "outputId": "86b58a00-20e5-49b1-a6dc-545994854e51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2,  4,  4,  6,  6, 10, 10,  8,  8, 12]),\n",
       " array([1, 2, 3, 4, 5, 6]),\n",
       " array([  3.,   5.,   8.,   9.,  10.]))"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = np.array([0.0,0.0,0.0])\n",
    "ws = np.array([1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\n",
    "dEdIns = np.array([1,2,3,4,5,6])\n",
    "prevOut = np.array([2,2,2,2,2])\n",
    "bMult = 2\n",
    "bMultOnes = np.array([1.0,1.0])\n",
    "\n",
    "layerConsols = [[0], [1,2], [3,4], [7,8], [5,6], [9]]\n",
    "flattened = flatten(layerConsols)\n",
    "inverseConsols = [0] * len(flattened)\n",
    "for i in range(len(layerConsols)):\n",
    "    for sub in layerConsols[i]:\n",
    "        inverseConsols[sub] = i\n",
    "\n",
    "inverseConsols = np.array([0,1,1,2,2,4,4,3,3,5])\n",
    "\n",
    "    \n",
    "def gradLayer(nextdEdInputs, layerOutput): #returns (dEdWs, dEdBs, newdEdInputs)\n",
    "        expandedLayerOutput = np.repeat(layerOutput, bMult)\n",
    "        inverseddEdInputs = nextdEdInputs.take(inverseConsols)\n",
    "        dEdWs = expandedLayerOutput * inverseddEdInputs\n",
    "        dEdBs = nextdEdInputs\n",
    "        #upt to here correct\n",
    "        def foo(x):\n",
    "            if x >0.0:\n",
    "                return 1.0\n",
    "            else:\n",
    "                return 0.0\n",
    "        gtCast = np.vectorize(foo)\n",
    "#         dOutsdIns = np.gt(layerOutput, np.zeros_like(layerOutput))\n",
    "#         dOutsdIns = np.cast(dOutsdIns, 'float32')\n",
    "\n",
    "        dOutsdIns = gtCast(layerOutput)\n",
    "        dEdConnections = ws * inverseddEdInputs\n",
    "        dEdConnectionGroups = dEdConnections.reshape((dEdConnections.size // bMult, bMult))\n",
    "        dEdOuts = np.dot(dEdConnectionGroups, bMultOnes) #could need to be axis 1\n",
    "\n",
    "        newdEdInputs = dEdOuts * dOutsdIns\n",
    "\n",
    "        return (dEdWs, dEdBs, newdEdInputs)\n",
    "gradLayer(dEdIns, prevOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "M-PVWbN1o8ir"
   },
   "outputs": [],
   "source": [
    "x = np.array(range(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hcPuP7cAo8iz",
    "outputId": "f6336096-b5f9-4c2d-e44d-e662951cee47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [3, 4, 5]])"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape((2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Fr91u3DHo8i_"
   },
   "outputs": [],
   "source": [
    "import numerai\n",
    "trainingfeats, traininglabels, testingfeats, testinglabels = numerai.readTraining()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "5pIuvsvao8jE",
    "outputId": "334b69d7-dfb4-4693-a26d-2bc06017f70d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testingfeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "zSHm_uoUo8jP",
    "outputId": "23988138-fe8b-4a6c-e3b8-e7b4d0f19050"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "tXkvywWyo8jZ"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm evolve.pyc\n",
    "rm fulcrum.pyc\n",
    "rm fractalNetwork2.pyc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ImKcWwlHo8jn",
    "outputId": "d34e1c0b-9a3c-4f1a-87c9-d1761ad389af"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'run'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-a940d54d3ba1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfulcrum\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfulcrum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'module' object has no attribute 'run'"
     ]
    }
   ],
   "source": [
    "import fulcrum\n",
    "fulcrum.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Uzw4trTho8j0",
    "outputId": "bdd00cdb-ec65-4beb-fadf-484cecc5dc8c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 == 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "e5asE65Xo8kA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "Neuro120fractal.ipynb",
   "provenance": [
    {
     "file_id": "0B-aDu7AYJQFwS0Y4WFdUNGtmRlk",
     "timestamp": 1523566751533
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python [conda env:theano_p27]",
   "language": "python",
   "name": "conda-env-theano_p27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
