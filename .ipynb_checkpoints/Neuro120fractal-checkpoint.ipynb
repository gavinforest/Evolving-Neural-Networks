{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "vvrt4WJ7o8e6"
   },
   "outputs": [],
   "source": [
    "#Set up generating mathematical functions in tree structures from the following\n",
    "#primitives, these will be used for calculating displacements of neurons\n",
    "from deap import gp\n",
    "import operator\n",
    "import math\n",
    "def square(x):\n",
    "    return x*x\n",
    "def absSqrt(x):\n",
    "    return math.sqrt(abs(x))\n",
    "pset = gp.PrimitiveSet(\"nodePrims\", arity=1)\n",
    "pset.addPrimitive(max, 2)\n",
    "pset.addPrimitive(operator.mul, 2)\n",
    "pset.addPrimitive(operator.add, 2)\n",
    "pset.addPrimitive(operator.sub, 2)\n",
    "pset.addPrimitive(math.sin, 1)\n",
    "pset.addPrimitive(math.cos, 1)\n",
    "pset.addPrimitive(absSqrt, 1)\n",
    "pset.addPrimitive(square, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "QCKS3iQIo8fK",
    "outputId": "a471f2b5-673b-4a53-838c-c6cb7dc4647d",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/theano_p27/lib/python2.7/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ec2-user/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ec2-user/anaconda3/envs/theano_p27/lib/python2.7/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ec2-user/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n",
      "/home/ec2-user/anaconda3/envs/theano_p27/lib/python2.7/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  RuntimeWarning)\n",
      "/home/ec2-user/anaconda3/envs/theano_p27/lib/python2.7/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\tmean   \tmin    \tmax\tstdDev \n",
      "0  \t30    \t15.7568\t1.70807\t256\t45.3038\n",
      "1  \t27    \t37.8743\t2.60795\t256\t73.3022\n",
      "2  \t26    \t104.187\t4.0806 \t256\t111.668\n",
      "3  \t20    \t200.196\t25.8889\t256\t96.6709\n",
      "4  \t23    \t263.336\t256    \t549.426\t45.8111\n",
      "5  \t26    \t278.007\t256    \t549.426\t77.2859\n",
      "6  \t24    \t307.35 \t256    \t549.426\t111.492\n",
      "7  \t24    \t410.049\t256    \t549.426\t146.53 \n",
      "8  \t27    \t726.118\t256    \t8790.82\t1294.37\n",
      "9  \t25    \t961.496\t549.426\t8790.82\t1796.17\n",
      "10 \t24    \t1785.64\t549.426\t8790.82\t2942.77\n",
      "11 \t25    \t4258.05\t549.426\t8790.82\t4100.04\n",
      "12 \t27    \t8174.6 \t549.426\t8790.82\t2164.1 \n",
      "13 \t25    \t8790.82\t8790.82\t8790.82\t0      \n",
      "14 \t21    \t8881.51\t8790.82\t10000  \t318.488\n",
      "15 \t26    \t9093.11\t8790.82\t10000  \t523.591\n",
      "16 \t22    \t9516.33\t8790.82\t10000  \t592.376\n",
      "17 \t25    \t9969.77\t8790.82\t10000  \t188.783\n",
      "18 \t25    \t10000  \t10000  \t10000  \t0      \n",
      "19 \t22    \t10000  \t10000  \t10000  \t0      \n",
      "20 \t19    \t10000  \t10000  \t10000  \t0      \n",
      "21 \t25    \t10000  \t10000  \t10000  \t0      \n",
      "22 \t23    \t10000  \t10000  \t10000  \t0      \n",
      "23 \t24    \t10000  \t10000  \t10000  \t0      \n",
      "24 \t27    \t10000  \t10000  \t10000  \t0      \n",
      "25 \t26    \t10000  \t10000  \t10000  \t0      \n",
      "26 \t23    \t10000  \t10000  \t10000  \t0      \n",
      "27 \t23    \t10000  \t10000  \t10000  \t0      \n",
      "28 \t25    \t10000  \t10000  \t10000  \t0      \n",
      "29 \t25    \t10000  \t10000  \t10000  \t0      \n",
      "30 \t22    \t10000  \t10000  \t10000  \t0      \n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Code to implement the evolution of the models and hyperparameters for generating them\n",
    "%matplotlib notebook\n",
    "from deap import creator, base, tools, algorithms\n",
    "from random import randint\n",
    "import numpy as np\n",
    "import pickle\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "DataDims = 2\n",
    "MINDIMFUNCS = 1\n",
    "MAXDIMFUNCS = 10\n",
    "MINDIMS = DataDims\n",
    "MAXDIMS = 10\n",
    "POPSIZE = 30\n",
    "GENERATIONS = 30\n",
    "MU = 40\n",
    "LAMBDA = 30\n",
    "CXPB = 0.5\n",
    "MUTPB = 0.3\n",
    "WEIGHTSCALE = 0.05\n",
    "BIASSCALE = 0.05\n",
    "CARTESIANPROB = 0.25\n",
    "\n",
    "\n",
    "def genTreeList():\n",
    "    return [gp.PrimitiveTree(gp.genHalfAndHalf(pset=pset, min_=1,max_=6)) for i in range(randint(MINDIMFUNCS,MAXDIMFUNCS))]\n",
    "def genFuncList():\n",
    "    return [genTreeList() for j in range(randint(MINDIMS,MAXDIMS))]\n",
    "\n",
    "def genCartesianList():\n",
    "    if random.random() < CARTESIANPROB:\n",
    "        \n",
    "\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,) )\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "# def myMutate(individual):\n",
    "#     new = [[gp.mutNodeReplacement(x,pset=pset) for x in l] for l in toolbox.clone(individual)]\n",
    "#     return (tools.initIterate(creator.Individual, lambda: new),)\n",
    "\n",
    "\n",
    "def getFitMap(ls):\n",
    "    fitnesses = []\n",
    "    for l in ls:\n",
    "        fitnesses.append(l.fitness.values[0])\n",
    "    return fitnesses\n",
    "\n",
    "def evolve(evaluator):\n",
    "    \n",
    "    \n",
    "    \n",
    "    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,) )\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "    \n",
    "    toolbox = base.Toolbox()\n",
    "    toolbox.register(\"individual\", tools.initIterate, creator.Individual, genFuncList)\n",
    "    \n",
    "    def myMutate(individual):\n",
    "        new = [[gp.mutNodeReplacement(x,pset=pset) for x in l] for l in toolbox.clone(individual)]\n",
    "        new = [[x[0] for x in l] for l in new]\n",
    "        return (tools.initIterate(creator.Individual, lambda: new),)\n",
    "\n",
    "    toolbox.register(\"mate\", tools.cxUniform, indpb=0.5)\n",
    "    toolbox.register(\"mutate\", myMutate)\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize = 4)\n",
    "    toolbox.register(\"evaluate\", evaluator)\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "    pop = toolbox.population(POPSIZE)\n",
    "    \n",
    "    \n",
    "\n",
    "    myStats = tools.Statistics()\n",
    "    myStats.register(\"mean\", lambda ls: np.mean(getFitMap(ls)))\n",
    "    myStats.register(\"min\", lambda ls: min(getFitMap(ls)))\n",
    "    myStats.register(\"max\", lambda ls: max(getFitMap(ls)))\n",
    "    myStats.register(\"stdDev\", lambda ls: np.std(getFitMap(ls)))\n",
    "\n",
    "    hallOFame = tools.HallOfFame(5) # hall of fame of size 5\n",
    "\n",
    "\n",
    "    (finalPop, logbook) = algorithms.eaMuPlusLambda(pop, toolbox, MU, LAMBDA, CXPB, MUTPB, GENERATIONS, myStats, halloffame=hallOFame, verbose=True)\n",
    "\n",
    "    gen = logbook.select(\"gen\")\n",
    "    fit_maxs = logbook.select(\"max\")\n",
    "    fit_avgs = logbook.select(\"mean\")\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "    line1 = ax1.plot(gen, fit_maxs, \"b-\", label=\"Maximum Fitness\")\n",
    "    ax1.set_xlabel(\"Generation\")\n",
    "    ax1.set_ylabel(\"Fitness\", color=\"b\")\n",
    "    for tl in ax1.get_yticklabels():\n",
    "        tl.set_color(\"b\")\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    line2 = ax2.plot(gen, fit_avgs, \"r-\", label=\"Average Fitness\")\n",
    "    ax2.set_ylabel(\"Size\", color=\"r\")\n",
    "    for tl in ax2.get_yticklabels():\n",
    "        tl.set_color(\"r\")\n",
    "\n",
    "    lns = line1 + line2\n",
    "    labs = [l.get_label() for l in lns]\n",
    "    ax1.legend(lns, labs, loc=\"center right\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def flatten(mylist):\n",
    "    return list(itertools.chain.from_iterable(mylist))\n",
    "    \n",
    "def myEval(individual):\n",
    "    funcs = []\n",
    "    for dimlist in individual:\n",
    "        newDimlist = []\n",
    "        for tree in dimlist:\n",
    "#             print gp.stringify(tree)\n",
    "            f = gp.compile(tree, pset)\n",
    "            newDimlist.append(f)\n",
    "        funcs.append(newDimlist)\n",
    "    flattened = flatten(funcs)\n",
    "    mapped = map(lambda f: f(1), flattened)\n",
    "    return max(mapped),\n",
    "    \n",
    "    \n",
    "evolve(myEval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "MSJBPuYeo8fm",
    "outputId": "19052e0c-7a92-439e-eb8b-ccc170a9eeaa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuDNN version 7005 on context None\n",
      "Mapped name None to device cuda: GRID K520 (0000:00:03.0)\n"
     ]
    }
   ],
   "source": [
    "#Load MNIST data to train/test models on\n",
    "import theano\n",
    "import mnist\n",
    "import numpy as np\n",
    "\n",
    "train_images = mnist.train_images()\n",
    "train_labels = mnist.train_labels()\n",
    "\n",
    "test_images = mnist.test_images()\n",
    "test_labels = mnist.test_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "MSJBPuYeo8fm",
    "outputId": "19052e0c-7a92-439e-eb8b-ccc170a9eeaa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2af8d79110>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parse mnist data into form that we will use\n",
    "def labelToArray(x):\n",
    "    blank = [0] * 10\n",
    "    blank[x] = 1\n",
    "    return np.array(blank)\n",
    "\n",
    "trainingimgs = [train_images[i].astype(theano.config.floatX).ravel() * (1.0/256) for i in range(train_images.shape[0])]\n",
    "traininglabels = [labelToArray(train_labels[i]).astype(theano.config.floatX) for i in range(train_labels.shape[0])]\n",
    "testingimgs = [test_images[i].astype(theano.config.floatX).ravel() * (1.0/256) for i in range(test_images.shape[0])]\n",
    "testinglabels = [labelToArray(test_labels[i]).astype(theano.config.floatX) * (1.0 / 256) for i in range(test_labels.shape[0])]\n",
    "plt.imshow(trainingimgs[0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "oTGC3727o8f0",
    "outputId": "b31754f4-b054-4e8c-d625-9dc6e12cf7dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running initial dictSingleGenConsolidate\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "starting to loop\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "first version took: 0.000350952148438\n",
      "looped\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "first version took: 0.000384092330933\n",
      "looped\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "first version took: 0.000290870666504\n",
      "looped\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "first version took: 0.000196933746338\n",
      "looped\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "first version took: 0.000216960906982\n",
      "looped\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "first version took: 0.000659942626953\n",
      "looped\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "first version took: 0.00019907951355\n",
      "looped\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "first version took: 0.000662088394165\n",
      "looped\n",
      "[0.90845209]\n",
      "biased and relued: [0.01396064 0.09239123 0.08187209 0.20823819 0.1082504 ]\n",
      "biased and relued: [0.0042657  0.03112751 0.01120704 0.00691882 0.02620807]\n",
      "biased and relued: [0.0227507  0.02536512 0.02551081 0.04106259 0.02380239]\n",
      "biased and relued: [0.01698156 0.05009565 0.01962276 0.00167944 0.0210561 ]\n",
      "biased and relued: [0.04813543 0.04390304 0.03733971 0.00445861 0.00889606]\n",
      "biased and relued: [0.04532248 0.01460465 0.03860469 0.00579987 0.04887984]\n",
      "biased and relued: [0.04004649 0.0144441  0.00610571 0.04587439 0.02561324]\n",
      "biased and relued: [0.03767447 0.02052907 0.00919034 0.01975864 0.04653184]\n",
      "biased and relued: [0.00841578 0.0480526  0.02418079 0.0143561  0.02961801]\n",
      "[0.90845209]\n"
     ]
    }
   ],
   "source": [
    "#Miscellaneous functions that get used for calculating growth of networks\n",
    "\n",
    "import theano.tensor as T\n",
    "from theano import shared\n",
    "import theano\n",
    "from autograd import grad as Grad\n",
    "import autograd.numpy as np\n",
    "import autograd.numpy.linalg as LA\n",
    "import itertools\n",
    "import typing\n",
    "import time\n",
    "import math\n",
    "from itertools import izip\n",
    "#We're modeling neurons as points in a high dimensional space, but to keep them\n",
    "#from just going all over the place and not interacting to create interesting \n",
    "#structures, we're going to limit the size of that space to a box of this width\n",
    "SPACESPAN = 2.0\n",
    "\n",
    "#Take one dimension of a neuron's position -- if it's outside the box,\n",
    "#wrap it around so it goes in the box. Otherwise, do nothing.\n",
    "def box(x):\n",
    "    if x > 0 + SPACESPAN / 2.0:\n",
    "        return -1.0 + x\n",
    "    elif x < 0 - SPACESPAN / 2.0:\n",
    "        return 1.0 + x\n",
    "    else:\n",
    "        return x\n",
    "      \n",
    "      \n",
    "#Want neurons that are close together to overlap, so we have a \"resolution\" of \n",
    "#the space such that if neurons are closer than the \"resolution\", they overlap. \n",
    "#resDenominator can be thought of as how many pixels are in a row of the box the\n",
    "#neurons live in.\n",
    "def discretize(x, resDenominator):\n",
    "    if x > 0.0:\n",
    "        return np.floor(1.0 * x * resDenominator) / resDenominator\n",
    "    elif x < 0.0:\n",
    "        return np.floor(1.0 * x * resDenominator) / resDenominator\n",
    "    else:\n",
    "        return 0.0\n",
    "    \n",
    "def mnistlabelToArray(x):\n",
    "    blank = [0] * 10\n",
    "    blank[x] = 1\n",
    "    return np.array(blank)\n",
    "\n",
    "\n",
    "def flatten(mylist):\n",
    "    return list(itertools.chain.from_iterable(mylist))\n",
    "\n",
    "#Consolidation is strange but crucial. Basically you have a big array of where the\n",
    "#neurons are in space, then you apply the displacement/\"growth\" rules to each\n",
    "#dimension of those positions. Now you have a huge list of neuron positions, and\n",
    "#consolidating is calculating what neurons overlap, and creating a list of indices\n",
    "#that tells which neurons are going as input to a neuron in the next layer. You\n",
    "#could do this with a bitmask, but the networks are usually sparse enough that \n",
    "#it would be extremely inefficient, but maybe with a low resDenominator the space\n",
    "#will overlap enough that it will be efficient. Improving this would be nice, but\n",
    "#I don't know if its necessary, given this is slow but not terribly slow.\n",
    "\n",
    "#to be honest I have to look over this a lot too to figure out whats going on.\n",
    "\n",
    "\n",
    "def dictSingleGenConsolidate(arrays):\n",
    "    #takes as input [[position, position,...],[position, position,...], ...]\n",
    "    #want to find, in the flattened list above, which the indices of all neurons that overlap with the first position,\n",
    "    #then the indices of all the neurons that overlap with the second position, and so on until done\n",
    "    \n",
    "    arraylen = len(arrays)\n",
    "    irange = range(arraylen)\n",
    "    \n",
    "    positionDict = {}\n",
    "    neuronPositionTuples = map(lambda l: tuple(l), arrays)\n",
    "    positionTuplesOrdered = []\n",
    "\n",
    "    print \"starting a dictSingleGenConsolidate\" \n",
    "\n",
    "    for posTuple,i in zip(neuronPositionTuples, irange):\n",
    "        if posTuple not in positionDict:\n",
    "            positionDict[posTuple] = [i]\n",
    "            positionTuplesOrdered.append(posTuple)\n",
    "        else:\n",
    "            positionDict[posTuple].append(i)\n",
    "\n",
    "    indices = [positionDict[posTuple] for posTuple in positionTuplesOrdered]\n",
    "    \n",
    "    print \"finished a dictSingleGenConsolidate\"\n",
    "        \n",
    "    #returns a list [[index, index, index,...], [index, index, index,...]] where the ith sublist corresponds to the ith neuron\n",
    "    #in the next layer up, and each sublist contains the indices of the neurons that connect to them.\n",
    "    return indices\n",
    "\n",
    "  \n",
    "def newSingleGenConsolidate(arrays):\n",
    "    bigMatrix = np.array(arrays)\n",
    "    arraylen = len(arrays)\n",
    "    initArraylen = len(arrays)\n",
    "    indices = []\n",
    "    flattenedIndices = []\n",
    "    \n",
    "    irange = range(arraylen)\n",
    "    \n",
    "    counter = True\n",
    "    print \"starting a newSingleGenConsolidate\"\n",
    "    flattenedIndices = np.ones()\n",
    "    for i in irange:\n",
    "        if i not in flattenedIndices:\n",
    "            subgroupArr = np.argwhere(np.all((bigMatrix-bigMatrix[i])==0, axis=0))\n",
    "            subgroup = subgroupArr.tolist()\n",
    "            indices.append(subgroup)\n",
    "            flattenedIndices += subgroup\n",
    "            arraylen -= subgroupArr.size\n",
    "            if counter and arraylen/initArraylen < 0.5:\n",
    "                print \"half way done a newSingleGenConsolidate\"\n",
    "                counter = False\n",
    "    \n",
    "    print \"finished a newSingleGenConsolidate\"\n",
    "    return indices\n",
    "            \n",
    "            \n",
    "            \n",
    "def singleGenConsolidate(arrays):\n",
    "    #takes as input [[position, position,...],[position, position,...], ...]\n",
    "    #want to find, in the flattened list above, which the indices of all neurons that overlap with the first position,\n",
    "    #then the indices of all the neurons that overlap with the second position, and so on until done\n",
    "    \n",
    "    indices = []\n",
    "    flattenedIndices = []\n",
    "    arraylen = len(arrays)\n",
    "    initArraylen = len(arrays) * 1.0\n",
    "    irange = range(arraylen)\n",
    "    \n",
    "    counter = True\n",
    "    print \"starting a singleGenConsolidate\"\n",
    "    for i in irange:\n",
    "        if i not in flattenedIndices:\n",
    "            subgroup = [i] + [j for j in irange[i + 1:] if np.array_equal(arrays[i], arrays[j])]\n",
    "            arraylen -= len(subgroup)\n",
    "            indices.append(subgroup)\n",
    "            flattenedIndices += subgroup\n",
    "            if counter and arraylen/initArraylen < 0.5:\n",
    "                print \"half way done a singleGenConsolidate\"\n",
    "                counter = False\n",
    "    \n",
    "    print \"finished a singleGenConsolidate\"\n",
    "    \n",
    "    #returns a list [[index, index, index,...], [index, index, index,...]] where the ith sublist corresponds to the ith neuron\n",
    "    #in the next layer up, and each sublist contains the indices of the neurons that connect to them.\n",
    "    return indices\n",
    "\n",
    "\n",
    "\n",
    "def nprelu(x):\n",
    "    np.maximum(0,x)\n",
    "\n",
    "\n",
    "def getSubV2np(index, inds, complete):\n",
    "    return complete[inds[index]:inds[index + 1]]\n",
    "\n",
    "def getSubV3np(index, indinds, inds, complete):\n",
    "    subInds = inds[indinds[index] : indinds[index + 1] + 1]\n",
    "    return subInds, complete\n",
    "  \n",
    "#this is a consolidation list actually being used\n",
    "def singleConsol(tensor, indices):\n",
    "    return (np.choose(indices, tensor)).sum()\n",
    "\n",
    "def positionConsolidate(arrays, consolidations):\n",
    "    return [arrays[sublist[0]] for sublist in consolidations]\n",
    "\n",
    "def numpyConsolidate(array, consols):\n",
    "    new = []\n",
    "    for sublist in consols:\n",
    "        x = 0.0\n",
    "        for i in sublist:\n",
    "            x += array[i]\n",
    "        new.append(x)\n",
    "\n",
    "    return new\n",
    "\n",
    "def npConsolidate(array, consolinds, consols):\n",
    "    ordered = array.take(consols)\n",
    "    f = lambda i : ordered[consolinds[i]: consolinds[i + 1]].sum()\n",
    "    veced = np.vectorize(f)\n",
    "    return veced(np.arange(consolinds.size))\n",
    "\n",
    "\n",
    "def generalfeedforward((weights, biases, finalweights, finalbiases), consolMasks, hiddenlayers, branchMultiplier, inp):\n",
    "    #implements a fractalnet in numpy, using consolidation masks instead of lists.\n",
    "    for i in range(hiddenlayers):\n",
    "        inp = np.repeat(inp, branchMultiplier)\n",
    "        inp = np.multiply(weights[i], inp)\n",
    "        inp = np.concatenate((inp, np.array([0.0]).astype('float32')))\n",
    "        inp = inp.take(consolMasks[i]).sum(axis = 1)\n",
    "        inp = nprelu(np.add(inp, biases[i]))\n",
    "    \n",
    "    print inp\n",
    "    finalout = nprelu(np.dot(inp, finalweights) + finalbiases)\n",
    "    return finalout\n",
    "\n",
    "\n",
    "class nnet:\n",
    "    weights = []\n",
    "    biases = []\n",
    "    consolidations = []\n",
    "    finalweights = []\n",
    "    finalbiases = []\n",
    "    weightnum = 0\n",
    "    hiddenlayers = 0\n",
    "    \n",
    "    def __init__(self, resolution, functions, inputdimension, datainp, dataoutp, synapseThreshold):\n",
    "        self.resDenominator = resolution\n",
    "        self.funcs = functions\n",
    "        self.dimensions = len(self.funcs)\n",
    "        \n",
    "        #branch multiplier says how many neurons grow out of each neuron every\n",
    "        #time a new layer is grown. This is the same fo\n",
    "        \n",
    "        self.branchMultiplier = len(flatten(self.funcs))\n",
    "        self.TBranchMult = shared(np.array([self.branchMultiplier]))\n",
    "#         self.dataset = [shared(dat.astype(theano.config.floatX)) for dat in datainp]\n",
    "#         self.datalabels = [shared(outp.astype(theano.config.floatX)) for outp in dataoutp]\n",
    "        self.dataSample = datainp[0] #numpy\n",
    "        self.dataOutSample = dataoutp[0]\n",
    "        self.inputdimension = inputdimension\n",
    "        \n",
    "        if self.dataSample.size ** (1.0/ inputdimension) > self.resDenominator * 2.0:\n",
    "            print \"resDenominator may be too small for effective learning\"\n",
    "            \n",
    "        self.threshold = synapseThreshold\n",
    "\n",
    "    def applyFuncs(self, narray): #checked\n",
    "        #grows a single neuron's new positions, given vector position (represented as a list)\n",
    "        boxvec = np.vectorize(lambda x: discretize(box(x), self.resDenominator))\n",
    "        displaced = []\n",
    "        \n",
    "        for dim in range(self.dimensions):\n",
    "            for f in self.funcs[dim]:\n",
    "                \n",
    "                zeroes = np.zeros_like(narray)\n",
    "                displacement = f(narray[dim]) % SPACESPAN\n",
    "                zeroes[dim] = displacement\n",
    "                \n",
    "                newArray = np.add(narray, zeroes)\n",
    "                newArrayBoxed = boxvec(newArray)\n",
    "                displaced.append(newArrayBoxed)\n",
    "                \n",
    "        \n",
    "        return displaced\n",
    "        \n",
    "\n",
    "    def applyFuncsMult(self, narrays): \n",
    "        #given list of neuron positions (lists), grow them and return a list of list of positions, where the first list is the \n",
    "        #first neuron's \"outgrowths\", the second list is the second neuron's \"outgrowths\" and so on.\n",
    "        \n",
    "        return flatten([self.applyFuncs(x) for x in narrays])\n",
    "    \n",
    "    def locate(self, sample):  #only 1 or 2 implemented\n",
    "        #given input data as an array, represent that data spacially as a neurons that can then be grown\n",
    "        \n",
    "        insize = sample.size\n",
    "        sample = np.ravel(sample) \n",
    "        tensorFrame = [0] * self.dimensions\n",
    "        located = [0] * insize\n",
    "        \n",
    "        boxvec = np.vectorize(lambda x: discretize(box(x), self.resDenominator))\n",
    "        \n",
    "        #self.inputdimension is the dimension the input should be represented in\n",
    "        \n",
    "        if self.inputdimension == 1:\n",
    "            #arrange neurons in a line along the first dimension\n",
    "            for i in range(insize):\n",
    "                myTens = tensorFrame[:]\n",
    "                myTens[0] = (2.0 * i) / insize - 1.0\n",
    "                located[i] = boxvec(np.array(myTens))\n",
    "        \n",
    "        if self.inputdimension == 2:\n",
    "            #arrange neurons in a grid in the first two dimensions that has integer dimensions, calculated to be as \n",
    "            #close to square as possible for convenience\n",
    "            located = []\n",
    "            factorPairs = [(i,(insize / i)) for i in range(1, int(math.floor(insize**0.5))) if insize % i == 0]\n",
    "            pair = factorPairs[-1]\n",
    "            for i in range(pair[0]):\n",
    "                for j in range(pair[1]):\n",
    "                    myTens = tensorFrame[:]\n",
    "                    myTens[0] = 2.0 * i/pair[0] - 1.0\n",
    "                    myTens[1] = 2.0 * j/pair[1] - 1.0\n",
    "                    located.append(boxvec(np.array(myTens)))\n",
    "                            \n",
    "        return located\n",
    "        \n",
    "    def genConsolidate(self): #finds consolidation list from located self.dataSample\n",
    "        consols = []\n",
    "#         print len(self.dataSample.ravel())\n",
    "\n",
    "        located = self.locate(self.dataSample)\n",
    "        #type is [position, position, ...], don't care about dataSample's actual values right now, just its dimensions\n",
    "        \n",
    "#         print len(located)\n",
    "#         print type(located[0])\n",
    "        print \"running initial dictSingleGenConsolidate\"\n",
    "    \n",
    "        #Grow the neurons, generate consolidations list, consolidate, then start a loop\n",
    "        located = self.applyFuncsMult(located)\n",
    "        consols.append(dictSingleGenConsolidate(located))\n",
    "        located = positionConsolidate(located, consols[-1]) \n",
    "\n",
    "        \n",
    "        print \"starting to loop\"\n",
    "        #stop the growth when it hits a certain number of weights\n",
    "        while len(flatten(flatten(consols))) + len(flatten(consols[-1])) * self.branchMultiplier < self.threshold:\n",
    "            located = self.applyFuncsMult(located)\n",
    "            testStart = time.time()\n",
    "            consols.append(dictSingleGenConsolidate(located))\n",
    "            print \"first version took: \" + str(time.time() - testStart)\n",
    "#             testStart = time.time()\n",
    "#             x = newSingleGenConsolidate(located)\n",
    "#             print \"new version took: \" + str(time.time() - testStart)\n",
    "            \n",
    "            located = positionConsolidate(located, consols[-1]) \n",
    "            print \"looped\"\n",
    "            \n",
    "        self.consolidations = consols\n",
    "        \n",
    "        #In contrast to using the consolidation list, which is a list of lists of variable length, you can also pad them to create\n",
    "        #a list of fixed lengths lists (maximum of the previous variable lengths) that makes things neater but sacrifices some\n",
    "        #memory (and possibly some speed, but depending on implementation it might be faster). Pad with out of bounds indices\n",
    "        #that theano and numpy will default to zero.\n",
    "        self.consolMasks = []\n",
    "        for layerConsols in self.consolidations:\n",
    "#             print \"initial \" + str(layerConsols)\n",
    "            maxInLength = max(map(len, layerConsols))\n",
    "            inLength = len(flatten(layerConsols))\n",
    "            extended = map(lambda l: l + [inLength] * (maxInLength - len(l)), layerConsols)\n",
    "#             print \"extended: \" + str(extended)\n",
    "            self.consolMasks.append(np.array(extended).astype('int32'))\n",
    "        return consols\n",
    "    \n",
    "    def genWeights(self):\n",
    "        myWeightNum = 0\n",
    "        self.hiddenlayers = 0\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        self.finalweights = []\n",
    "        self.finalbiases = []\n",
    "        for consol in self.consolidations:\n",
    "            weightVec = (np.random.rand(len(flatten(consol))) * WEIGHTSCALE).astype(theano.config.floatX).tolist()\n",
    "            biasVec   = (np.random.rand(len(consol)) * BIASSCALE).astype(theano.config.floatX).tolist()\n",
    "            self.weights.append(weightVec)\n",
    "            self.biases.append(biasVec)\n",
    "            myWeightNum += len(weightVec)\n",
    "\n",
    "            #convert to shared data type for later speed\n",
    "            self.hiddenlayers += 1\n",
    "        \n",
    "        outsize = len(self.dataOutSample)\n",
    "        \n",
    "        self.finalweights = np.random.rand(len(self.consolidations[-1]),outsize).astype('float32')        #final interconnected layer for output\n",
    "        self.finalbiases = np.random.rand(outsize).astype('float32')\n",
    "\n",
    "        myWeightNum += len(self.consolidations[-1]) * outsize\n",
    "#         self.weightNum = myWeightNum\n",
    "        \n",
    "    def feedforward(self, inp):\n",
    "        \n",
    "        for i in range(self.hiddenlayers):\n",
    "            inp = np.repeat(inp, self.branchMultiplier)\n",
    "#             print \"repeated: \" + str(inp)\n",
    "            inp = np.multiply(self.weights[i], inp)\n",
    "#             print \"weighted: \" + str(inp)\n",
    "            inp = numpyConsolidate(inp, self.consolidations[i])\n",
    "#             print \"consolidated: \" + str(inp)\n",
    "            inp = np.maximum(0, np.add(inp, self.biases[i]))\n",
    "            print \"biased and relued: \" + str(inp)\n",
    "        \n",
    "#         print \"before finals: \" + str(inp)\n",
    "#         print \"finalweights: \" + str(self.finalweights)\n",
    "#         print \"finalbiases: \" + str(self.finalbiases)\n",
    "        finalout = (np.dot(inp, self.finalweights) + self.finalbiases)\n",
    "#         print \"final: \" + str(finalout)\n",
    "        return finalout\n",
    "\n",
    "    def nfeedforward(self, inp):\n",
    "        for i in range(self.hiddenlayers):\n",
    "            inp = np.repeat(inp, self.branchMultiplier)\n",
    "            inp = np.multiply(self.weights[i], inp)\n",
    "            inp = np.concatenate((inp, np.array([0.0]).astype('float32')))\n",
    "            inp = inp.take(self.consolMasks[i]).sum(axis = 1)\n",
    "            inp = np.maximum(0,np.add(inp, self.biases[i]))\n",
    "        return np.dot(inp, self.finalweights) + self.finalbiases\n",
    "    \n",
    "    def test(inputs, outputs):\n",
    "        \n",
    "        def foo(x):\n",
    "            if x > 0.5:\n",
    "                return 1.0\n",
    "            return 0.0\n",
    "\n",
    "        binarize = np.vectorize(foo)\n",
    "        \n",
    "        errors = [LA.norm(outp - binarize(self.feedforward(inp))) for inp,outp in izip(inputs,outputs)]\n",
    "        return sum(errors)/len(inputs) * 100.0\n",
    "        \n",
    "    \n",
    "    def numpytrain(self, alpha, epochs, batchsize, inputlist, outputlist, verbose, testdatainputs, testdatalabels):\n",
    "        print \"starting training\"\n",
    "        \n",
    "        def error((weights, biases, finalweights, finalbiases), inp, outp):\n",
    "            return LA.norm(outp - generalfeedforward((weights,biases,finalweights,finalbiases), \n",
    "                                                     self.consolMasks, self.hiddenlayers, self.branchMultiplier, inp))\n",
    "        #use autograd to automatically differentiate error function\n",
    "        error_grad = Grad(error)\n",
    "        \n",
    "        inlen = len(inputlist)\n",
    "        outlen = len(outputlist)\n",
    "\n",
    "        if inlen != outlen:\n",
    "            Exception(\"number of input vectors (\"+str(inlen)+\") not equal not number of ouptut vectors (\"+str(outlen)+\")\")\n",
    "            \n",
    "        if alpha == 0.0:\n",
    "            raise(\"why is alpha zero?\")\n",
    "            \n",
    "        if type(batchsize) != int:\n",
    "            raise(\"Why is batchsize not an int?\")\n",
    "        \n",
    "        if batchsize == 0 or batchsize > inlen:\n",
    "            raise(\"batchsize of \"+str(batchsize)+\"is not allowed. Note than inputveclist has length \"+str(inlen))\n",
    "            \n",
    "        #just some error checks\n",
    "        \n",
    "        randindexlist = range(inlen)\n",
    "        start = time.time()\n",
    "        avgpercenttesterror = \"No test set\"\n",
    "        avgpercenttesterrorlist = []\n",
    "        \n",
    "        #using stochastic gradient descent training method\n",
    "        for epoch in xrange(epochs):\n",
    "            #random.shuffle(randindexlist)\n",
    "            #for batch in range(inlen/batchsize):\n",
    "            \n",
    "#                 low = batch * batchsize\n",
    "#                 upper = (batch + 1) * batchsize\n",
    "#                 if upper > inlen: upper = inlen \n",
    "                \n",
    "#                 total_Egradweights = None\n",
    "#                 total_Egradbiases = None\n",
    "                \n",
    "#                 for i in randindexlist[low:upper]:\n",
    "            for inp,outp in izip(inputlist,outputlist):\n",
    "                Egradws, Egradbs, Egadfws, Egradfbs = error_grad((self.weights, self.biases, \n",
    "                                                       self.finalweights, self.finalbiases), inp, outp) #formerly used indexes from randindexlist\n",
    "#                     if total_Egradweights:\n",
    "#                         total_Egradweights = [x + y for x,y in izip(Egradweights,total_Egradweights)]\n",
    "#                         total_Egradbiases = [x + y for x,y in izip(Egradbiases,total_Egradbiases)]\n",
    "#                     else:\n",
    "#                         total_Egradweights = Egradweights\n",
    "#                         total_Egradbiases = Egradbiases\n",
    "                \n",
    "#                 total_Egradweights = [x / (batchsize * 1.0) for x in total_Egradweights]\n",
    "#                 total_Egradbiases = [x / (batchsize * 1.0) for x in total_Egradbiases]\n",
    "                \n",
    "#                 self.weights = [curr-grad*alpha for curr, grad in izip(self.weights, total_Egradweights)]\n",
    "#                 self.biases = [curr-grad*alpha for curr, grad in izip(self.biases, total_Egradbiases)]\n",
    "                self.weights = [curr-grad*alpha for curr, grad in izip(self.weights, Egradws)]\n",
    "                self.biases = [curr-grad*alpha for curr, grad in izip(self.biases, Egradbs)]\n",
    "                self.finalweights = self.finalweights - alpha * Egradfws\n",
    "                self.finalbiases = self.finalbiases - alpha * Egradfbs\n",
    "            \n",
    "            if len(testinputlist) == len(testoutputlist) and len(testinputlist) != 0:\n",
    "                avgpercenttesterror = self.test(testinputlist, testoutputlist)\n",
    "                avgpercenttesterrorlist.append(avgpercenttesterror)\n",
    "            else:\n",
    "                print \"bad test set\"\n",
    "            \n",
    "            elapsed = time.time() - start\n",
    "            start = time.time()\n",
    "            if verbose:\n",
    "                print \"epoch: \" + str(epoch) + \"\\t percenterror: \" + str(avgpercenttesterror) + \"% \\t time elapsed this epoch: \" + str(elapsed) + \"s\"\n",
    "            \n",
    "        return (avgpercenttesterror, avgpercenttesterrorlist)\n",
    "\n",
    "# singleGenConsolidate([np.array([0,0,0]), np.array([0,1,2,3]), np.array([0,0,0])])\n",
    "testnet = nnet(10, [[lambda x: x + 1], [lambda x: x * 2]], 1, [np.array([0,1,2,3])], [np.array([1])], 100)\n",
    "testnet.genConsolidate()\n",
    "testnet.genWeights()\n",
    "numpyConsolidate(np.array([1,2,3]), [[0,2], [1]])\n",
    "print testnet.nfeedforward(np.array([0,1,2,3]))\n",
    "print testnet.feedforward(np.array([0,1,2,3]))\n",
    "# print mynet.consolidations\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "from theano import shared,config,function\n",
    "import itertools\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "# theano.config.exception_verbosity = \"high\"\n",
    "\n",
    "def flatten(mylist):\n",
    "    return list(itertools.chain.from_iterable(mylist))\n",
    "  \n",
    "\n",
    "\n",
    "class V2IndexedShared:\n",
    "    def __init__(self, atype):\n",
    "        self.myType = atype\n",
    "    \n",
    "    def fromList(self,D2List):\n",
    "        self.complete = shared(np.array(flatten(D2List)).astype(self.myType))\n",
    "        self.length = shared(len(D2List))\n",
    "        inds = [0]\n",
    "        for sublist in D2List:\n",
    "            inds.append(len(sublist) + inds[-1])\n",
    "        self.inds = shared(np.array(inds).astype('int32'))\n",
    "        return self\n",
    "\n",
    "    \n",
    "class V3IndexedShared:\n",
    "    def __init__(self,D3List, atype):\n",
    "        self.complete = shared(np.array(flatten(flatten(D3List))).astype(atype))\n",
    "#         self.complete = np.array(flatten(flatten(D3List))).astype(atype)\n",
    "\n",
    "        self.myType = atype\n",
    "        self.length = shared(len(D3List))\n",
    "        D2Inds = [0]\n",
    "        D3Inds = [0]\n",
    "        \n",
    "        for sublistOLists in D3List:\n",
    "            \n",
    "            for sublist in sublistOLists:\n",
    "                D2Inds.append(len(sublist) + D2Inds[-1])\n",
    "                \n",
    "            D3Inds.append(len(sublistOLists) + D3Inds[-1])\n",
    "            \n",
    "                \n",
    "        self.D2Inds = shared(np.array(D2Inds).astype('int32'))\n",
    "        self.D3Inds = shared(np.array(D3Inds).astype('int32'))\n",
    "        \n",
    "#         self.D2Inds = np.array(D2Inds).astype('int32')\n",
    "#         self.D3Inds = np.array(D3Inds).astype('int32')\n",
    "#         print D3Inds\n",
    "#         print D2Inds\n",
    "#         print np.array(flatten(flatten(D3List)))\n",
    "    \n",
    "\n",
    "def relu(x):\n",
    "    return T.maximum(x, 0)\n",
    "\n",
    "#instead of having nested lists of variable sizes, the following two classes implement either a list of lists and a lists of \n",
    "#lists of lists. It implements it by having a \"complete\" array, then a array of indexes for the beginning and end of the slices\n",
    "#of that array, then an array for the beginning and end of slices (of the slices array)\n",
    "\n",
    "\n",
    "def getSubV2(index, inds, complete):\n",
    "    return complete[inds[index]:inds[index + 1]]\n",
    "\n",
    "def getSubV2Check():\n",
    "    tind = T.iscalar('ind')\n",
    "    tinds = T.ivector('inds')\n",
    "    tcomp = T.vector('complete')\n",
    "    \n",
    "    nind = np.asscalar(np.array([0]).astype('int32'))\n",
    "    ninds = np.array([0,2,4]).astype('int32')\n",
    "    comp = np.array([0,1,2,3,4]).astype(theano.config.floatX)\n",
    "    \n",
    "    f = theano.function([tind, tinds, tcomp], getSubV2(tind, tinds, tcomp))\n",
    "    print f(nind,ninds,comp)\n",
    "getSubV2Check()\n",
    "def getV2Length(inds):\n",
    "    return inds.size -1\n",
    "\n",
    "def getSubV3(index, indinds, inds, complete):\n",
    "    subInds = inds[indinds[index] : indinds[index + 1] + 1]\n",
    "    return subInds, complete\n",
    "\n",
    "def getSubV3Check():\n",
    "    D3List = [[[0,1,2,], [3,4,5]], [[6,7,8], [9,10,11]]]\n",
    "    consolcomplete = [0,1,2,3,4,5,6,7,8,9,10,11]\n",
    "    consolinds = [0,3,6,9,12]\n",
    "    consolindinds = [0,2,4]\n",
    "    print getSubV3(1, consolindinds, consolinds, consolcomplete)\n",
    "    print consolinds[2:5]\n",
    "    t = V3IndexedShared(D3List, 'int32')\n",
    "    \n",
    "# getSubV3Check()\n",
    "\n",
    "#the following pair of functions implements consolidation of a tensor using theano scan -- not the fastest, but its inherently\n",
    "#difficult to vectorize.\n",
    "def singleConsol(tensor, indices):\n",
    "    return (T.choose(indices, tensor)).sum()\n",
    "\n",
    "def consolidateTensor(tensor, consolinds, consolcomplete):\n",
    "    irange = T.arange(getV2Length(consolinds))\n",
    "    consolidated, updates = theano.scan(fn = lambda ind, tens, coninds, concomp: singleConsol(tens, getSubV2(ind, coninds, concomp)),\n",
    "                                        sequences = irange,\n",
    "                                        non_sequences=[tensor, consolinds, consolcomplete])\n",
    "    return consolidated\n",
    "\n",
    "def consolidateTensorCheck():\n",
    "    x = T.vector('x')\n",
    "    inds = T.ivector('inds')\n",
    "    complete = T.ivector('complete')\n",
    "    y = consolidateTensor(x,inds,complete)\n",
    "    f = theano.function([x,inds,complete], y)\n",
    "    print f(np.array([1.0,2.0,4.0,8.0]).astype(theano.config.floatX), np.array([0,3,4]).astype('int32'), np.array([1,2,3,0]).astype('int32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "QSaXtAM_o8gB",
    "outputId": "e4de1289-9fd1-49fe-8413-9bf3e368acce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running initial dictSingleGenConsolidate\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "starting to loop\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "first version took: 0.000212907791138\n",
      "looped\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "first version took: 0.000159025192261\n",
      "looped\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "first version took: 0.00014591217041\n",
      "looped\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "first version took: 0.000146150588989\n",
      "looped\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "first version took: 0.000142097473145\n",
      "looped\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "first version took: 0.000888109207153\n",
      "looped\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "first version took: 0.000629186630249\n",
      "looped\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "first version took: 0.000213861465454\n",
      "looped\n",
      "biased and relued: [0.00855147 0.14221761 0.03758007 0.15557193 0.10545873]\n",
      "biased and relued: [0.04289878 0.04844066 0.05144129 0.02492977 0.00379656]\n",
      "biased and relued: [0.02988205 0.01811004 0.03083597 0.04777678 0.0028535 ]\n",
      "biased and relued: [0.03379158 0.04328057 0.0371004  0.01080697 0.02786867]\n",
      "biased and relued: [0.01368212 0.010427   0.03059227 0.00649829 0.02368724]\n",
      "biased and relued: [0.03908738 0.02342816 0.02109397 0.04615814 0.03454913]\n",
      "biased and relued: [0.03731416 0.05213372 0.04863184 0.01071024 0.04014703]\n",
      "biased and relued: [0.03577915 0.01888644 0.00577496 0.03359182 0.00283465]\n",
      "biased and relued: [0.0415775  0.04666474 0.01597713 0.01938965 0.00570717]\n",
      "[0.1388675  0.54720096 0.74654898 0.07410294]\n",
      "[array([0.00855147, 0.1422176 , 0.03758007, 0.15557194, 0.10545874],\n",
      "      dtype=float32), array([0.04289878, 0.04844066, 0.05144129, 0.02492977, 0.00379656],\n",
      "      dtype=float32), array([0.02988205, 0.01811004, 0.03083597, 0.04777678, 0.0028535 ],\n",
      "      dtype=float32), array([0.03379158, 0.04328056, 0.0371004 , 0.01080697, 0.02786867],\n",
      "      dtype=float32), array([0.01368212, 0.010427  , 0.03059227, 0.00649829, 0.02368724],\n",
      "      dtype=float32), array([0.03908738, 0.02342816, 0.02109397, 0.04615814, 0.03454913],\n",
      "      dtype=float32), array([0.03731416, 0.05213372, 0.04863184, 0.01071024, 0.04014703],\n",
      "      dtype=float32), array([0.03577915, 0.01888644, 0.00577496, 0.03359182, 0.00283465],\n",
      "      dtype=float32), array([0.0415775 , 0.04666474, 0.01597713, 0.01938965, 0.00570717],\n",
      "      dtype=float32)]\n",
      "[-0.0000000e+00 -0.0000000e+00 -4.5918055e-13 -3.3289200e-13\n",
      " -4.4482110e-13 -9.1836109e-13 -6.6723168e-13 -2.8613297e-12]\n",
      "[-1.2274079e-12 -1.2274079e-12 -8.6109727e-13 -9.1898255e-13\n",
      " -2.4283513e-13 -1.8855143e-13 -9.4195496e-13 -9.4195496e-13\n",
      " -6.3853019e-13 -2.8779117e-12]\n",
      "[-1.4273881e-10 -1.4273881e-10 -7.1439569e-12 -7.1439569e-12\n",
      " -7.5864861e-12 -4.2055474e-12 -2.0381164e-12 -1.9551943e-12\n",
      " -5.5991128e-13 -3.4943682e-12]\n",
      "[-1.2127083e-09 -1.2127083e-09 -3.4557288e-11 -3.4557288e-11\n",
      " -5.8840696e-11 -4.2431877e-11 -6.5743293e-11 -7.0589805e-11\n",
      " -5.4450077e-12 -6.2572510e-11]\n",
      "[-2.7010024e-08 -2.7010024e-08 -1.1958814e-09 -1.1958814e-09\n",
      " -1.0251179e-09 -8.7990731e-10 -2.5630809e-10 -3.5734590e-10\n",
      " -7.7003676e-10 -1.4603663e-08]\n",
      "[-1.2352601e-07 -1.2352601e-07 -8.7796055e-09 -8.7796055e-09\n",
      " -2.5758903e-08 -6.2728816e-08 -1.3324606e-08 -5.6231859e-09\n",
      " -1.9944817e-08 -2.4431006e-07]\n",
      "[-7.63956723e-06 -7.63956723e-06 -6.06546337e-07 -6.06546337e-07\n",
      " -5.46115018e-07 -7.00572741e-07 -1.53300391e-06  1.74128070e-06\n",
      " -8.94464335e-07 -1.05717145e-05]\n",
      "[-1.7052257e-04 -1.7052257e-04 -2.2158053e-04 -2.2158053e-04\n",
      " -2.0669671e-04 -1.1448661e-04 -2.5213492e-05  4.1235919e-05\n",
      " -1.7063430e-04 -8.9878729e-04]\n",
      "[-0.00409192 -0.00409192 -0.00194696 -0.00194696 -0.00059533  0.00067632\n",
      "  0.00393403 -0.00367283 -0.00029222 -0.00144025]\n",
      "[-0.0000000e+00 -0.0000000e+00 -4.5918055e-13 -3.3289200e-13\n",
      " -4.4482110e-13 -9.1836109e-13 -6.6723168e-13 -2.8613297e-12]\n",
      "[-1.2274079e-12 -1.2274079e-12 -8.6109727e-13 -9.1898255e-13\n",
      " -2.4283513e-13 -1.8855143e-13 -9.4195496e-13 -9.4195496e-13\n",
      " -6.3853019e-13 -2.8779117e-12]\n",
      "[-1.4273881e-10 -1.4273881e-10 -7.1439569e-12 -7.1439569e-12\n",
      " -7.5864861e-12 -4.2055474e-12 -2.0381164e-12 -1.9551943e-12\n",
      " -5.5991128e-13 -3.4943682e-12]\n",
      "[-1.2127083e-09 -1.2127083e-09 -3.4557288e-11 -3.4557288e-11\n",
      " -5.8840696e-11 -4.2431877e-11 -6.5743293e-11 -7.0589805e-11\n",
      " -5.4450077e-12 -6.2572510e-11]\n",
      "[-2.7010024e-08 -2.7010024e-08 -1.1958814e-09 -1.1958814e-09\n",
      " -1.0251179e-09 -8.7990731e-10 -2.5630809e-10 -3.5734590e-10\n",
      " -7.7003676e-10 -1.4603663e-08]\n",
      "[-1.2352601e-07 -1.2352601e-07 -8.7796055e-09 -8.7796055e-09\n",
      " -2.5758903e-08 -6.2728816e-08 -1.3324606e-08 -5.6231859e-09\n",
      " -1.9944817e-08 -2.4431006e-07]\n",
      "[-7.63956723e-06 -7.63956723e-06 -6.06546337e-07 -6.06546337e-07\n",
      " -5.46115018e-07 -7.00572741e-07 -1.53300391e-06  1.74128070e-06\n",
      " -8.94464335e-07 -1.05717145e-05]\n",
      "[-1.7052257e-04 -1.7052257e-04 -2.2158053e-04 -2.2158053e-04\n",
      " -2.0669671e-04 -1.1448661e-04 -2.5213492e-05  4.1235919e-05\n",
      " -1.7063430e-04 -8.9878729e-04]\n",
      "[-0.00409192 -0.00409192 -0.00194696 -0.00194696 -0.00059533  0.00067632\n",
      "  0.00393403 -0.00367283 -0.00029222 -0.00144025]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[numpy.ndarray,\n",
       " numpy.ndarray,\n",
       " numpy.ndarray,\n",
       " numpy.ndarray,\n",
       " numpy.ndarray,\n",
       " numpy.ndarray,\n",
       " numpy.ndarray,\n",
       " numpy.ndarray,\n",
       " numpy.ndarray]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this class is essentially the same as nnet above, except that I implemented it in Theano for speed. All of the derivatives are \n",
    "#explicitly calculated, as I wasn't able to get theano to differentiate it. A lot of the set up is actually accomplished by the \n",
    "#previous class that used numpy.\n",
    "    \n",
    "from random import shuffle\n",
    "import theano\n",
    "theano.config.floatX = 'float32'\n",
    "\n",
    "class tnnet:\n",
    "    def __init__(self, resolution, functions, inputdimension, traindatainps, traindataoutps, testdatainps, testdataoutps, synapseThreshold, net = None):\n",
    "        \n",
    "        mynet = None\n",
    "        if net == None:\n",
    "            mynet = nnet(resolution, functions, inputdimension, traindatainps, traindataoutps, synapseThreshold)\n",
    "            mynet.genConsolidate()\n",
    "            mynet.genWeights()\n",
    "        else:\n",
    "            mynet = net\n",
    "        self.nnet = mynet\n",
    "        \n",
    "\n",
    "        self.sharedTrainingInps = shared(np.array(traindatainps).astype(theano.config.floatX))\n",
    "        self.sharedTrainingOutps = shared(np.array(traindataoutps).astype(theano.config.floatX))\n",
    "        self.sharedTestingInps = shared(np.array(testdatainps).astype(theano.config.floatX))\n",
    "        self.sharedTestingOutps = shared(np.array(testdataoutps).astype(theano.config.floatX))\n",
    "\n",
    "\n",
    "#         print \"weights: \" + str(mynet.weights)\n",
    "#         print \"biases: \" + str(mynet.biases)\n",
    "#         print mynet.feedforward(np.array([0,1,2,3]).astype(theano.config.floatX))\n",
    "#         inp_lengths = [len(consol) for consol in mynet.consolidations]\n",
    "#         inp_lengths = [datainps[0].size] + inp_lengths\n",
    "#         self.inp_lengths = np.array(inp_lengths).astype('int32')\n",
    "#         print \"inp_lengths: \" + str(inp_lengths)\n",
    "#         print \"dinp length: \" + str(datainps[0].size)\n",
    "#         print \"consolidations: \" + str(mynet.consolidations)\n",
    "        \n",
    "#         self.maxInp = np.amax(inp_lengths)\n",
    "#         self.maxPad = shared(np.array([0] * (np.amax(inp_lengths) - min(inp_lengths))).astype(theano.config.floatX))\n",
    "#         self.maxZeroes = shared(np.array([0.0] * self.maxInp).astype(theano.config.floatX))\n",
    "        \n",
    "#         initialPaddingLength = np.amax(inp_lengths) - datainps[0].size\n",
    "#         self.initialPadding = shared(np.array([0.0] * initialPaddingLength).astype(theano.config.floatX))\n",
    "#         self.inp_lengths = shared(self.inp_lengths)\n",
    "        \n",
    "        tweights = V2IndexedShared(theano.config.floatX)\n",
    "        tweights.fromList(mynet.weights)\n",
    "        self.weights = map(lambda x: shared(np.array(x).astype(theano.config.floatX)), mynet.weights)\n",
    "        \n",
    "        tbiases = V2IndexedShared(theano.config.floatX)\n",
    "        tbiases.fromList(mynet.biases)\n",
    "#         print tbiases.complete.get_value()\n",
    "        self.biases = map(lambda x: shared(np.array(x).astype(theano.config.floatX)), mynet.biases)\n",
    "    \n",
    "        tcons = V3IndexedShared(mynet.consolidations, 'int32')\n",
    "#         print \"final weights: \" + str(mynet.finalweights)\n",
    "        tfws = shared((mynet.finalweights).astype(theano.config.floatX))\n",
    "        tfbs = shared((mynet.finalbiases).astype(theano.config.floatX))\n",
    "        self.weightnum = mynet.weightnum\n",
    "        self.hiddenlayers = mynet.hiddenlayers\n",
    "        \n",
    "        self.consolMasks = []\n",
    "        self.dEdWsinverseConsols = []\n",
    "        self.oneMultipliers = []\n",
    "        \n",
    "        #this loop fulfills two important functions. First, it makes consolmasks from consolidation lists\n",
    "        #Second, it creates inverse consolidation lists, going from the next layer back to the original layer,\n",
    "        #which is crucial for backpropagation.\n",
    "        for layerConsols in mynet.consolidations:\n",
    "#             print \"initial \" + str(layerConsols)\n",
    "            maxInLength = max(map(len, layerConsols))\n",
    "            inLength = len(flatten(layerConsols))\n",
    "            extended = map(lambda l: l + [inLength] * (maxInLength - len(l)), layerConsols)\n",
    "#             print \"extended: \" + str(extended)\n",
    "            self.consolMasks.append(shared(np.array(extended).astype('int32')))\n",
    "            self.oneMultipliers.append(shared(np.array([1.0] * maxInLength).astype(theano.config.floatX)))\n",
    "            \n",
    "            flattened = flatten(layerConsols)\n",
    "            frame = [0] * len(flattened)\n",
    "            for i in range(len(layerConsols)):\n",
    "                for sub in layerConsols[i]:\n",
    "                    frame[sub] = i\n",
    "            \n",
    "            self.dEdWsinverseConsols.append(shared(np.array(frame).astype('int32')))\n",
    "        \n",
    "#         print self.nnet.consolidations[0]\n",
    "#         print self.dEdWsinverseConsols[0].get_value()\n",
    "            \n",
    "        \n",
    "        \n",
    "        inp = T.fvector('inp')\n",
    "#         paddedInp = T.concatenate([inp, self.initialPadding])\n",
    "        actualOutp = T.fvector('actualOutp')\n",
    "        alpha = T.fscalar('alpha')\n",
    "        \n",
    "        self.consolidations = map(lambda x: V2IndexedShared('int32').fromList(x), self.nnet.consolidations)\n",
    "        \n",
    "        self.winds = tweights.inds\n",
    "        self.ws = tweights.complete\n",
    "        self.binds = tbiases.inds\n",
    "        self.bs = tbiases.complete\n",
    "        self.consindinds = tcons.D3Inds\n",
    "        self.consinds = tcons.D2Inds\n",
    "        self.cons = tcons.complete\n",
    "        self.bMult = shared(np.asscalar(np.array([mynet.branchMultiplier]).astype('int32')))\n",
    "        self.fws = tfws\n",
    "        self.fbs = tfbs\n",
    "#         print \"weights: \" + '\\n'.join(map(str, self.nnet.weights))\n",
    "# #         print self.nnet.biases\n",
    "#         print \"inverse Consols: \" + '\\n'.join(map(lambda x: str(x.get_value().tolist()), self.dEdWsinverseConsols))\n",
    "#         print \"consols: \" + '\\n'.join(map(str, self.nnet.consolidations))\n",
    "        self.zeropad = shared(np.array([0.0]).astype(theano.config.floatX))\n",
    "        \n",
    "        self.bMultOnes = shared(np.array([1.0] * self.nnet.branchMultiplier).astype(theano.config.floatX))\n",
    "        \n",
    "        self.params = self.weights + self.biases + [self.fws, self.fbs]\n",
    "#         self.constparams = [self.consindinds, self.consinds, self.cons, self.winds, self.binds, self.bMult]\n",
    "        \n",
    "#         def singleCons(consInds, tens):\n",
    "#             asum, _ = theano.scan(fn = lambda i, tensor: tensor[i],\n",
    "#                                  sequences = consInds,\n",
    "#                                  non_sequences = tens)\n",
    "#             return asum.sum()\n",
    "        \n",
    "        \n",
    "#         def layer(ind, inpLength, inp):\n",
    "#             weights = getSubV2(ind, self.winds, self.ws)\n",
    "#             biases = getSubV2(ind, self.binds, self.bs)\n",
    "#             consolinds, consols = getSubV3(ind, self.consindinds, self.consinds, self.cons)\n",
    "#             inp = T.repeat(inp[0:inpLength], self.bMult)\n",
    "#             inp = weights * inp\n",
    "            \n",
    "#             #consolidation code\n",
    "#             numConsolidatedRange = T.arange(consolinds.size - 1)\n",
    "#             inp, _ = theano.scan(fn = lambda ind, x, coninds, concomp: singleCons(getSubV2(ind, coninds, concomp), x),\n",
    "#                                                 sequences = numConsolidatedRange,\n",
    "#                                                 non_sequences=[inp, consolinds, consols])\n",
    "#             inp = inp + biases\n",
    "#             inp = relu(inp)\n",
    "#             padding = self.maxPad[0 : self.maxInp - inp.size]\n",
    "#             inp = T.concatenate([inp, padding])\n",
    "#             return inp\n",
    "       \n",
    "        def layer(ind, x):\n",
    "            #get output of layer ind with input x\n",
    "            \n",
    "#             print \"in layer\"\n",
    "#             consolinds = self.consolidations[ind].inds\n",
    "#             consols = self.consolidations[ind].complete\n",
    "            \n",
    "            x = T.repeat(x, self.bMult) * self.weights[ind]\n",
    "            x = T.concatenate([x, T.zeros((5,),dtype=theano.config.floatX)])\n",
    "            x = (x.take(self.consolMasks[ind]).astype(theano.config.floatX)) #.sum(axis = 1)\n",
    "            x = T.dot(x, self.oneMultipliers[ind])\n",
    "# #             inp, _ = theano.map(fn = lambda i: inp[i],\n",
    "# #                                sequences = consols)\n",
    "# #             #consolidation code\n",
    "#             r = T.arange(consolinds.size - 1).astype(theano.config.floatX)\n",
    "#             for i in xrange(len(self.nnet.consolidations[ind])):\n",
    "#                 r = T.set_subtensor(r[i], x[consolinds[i]:consolinds[i + 1]].sum())\n",
    "#             numConsolidatedRange = T.arange(consolinds.size - 1).astype('int32')\n",
    "# #             inp2, _ = theano.map(fn = lambda i: inp1[consolinds[i]: consolinds[i + 1]].sum(),\n",
    "# #                                                 sequences = numConsolidatedRange)\n",
    "#             r, _ = theano.map(fn = lambda i, x: x[consolinds[i]: consolinds[i+1]].sum(),\n",
    "#                                                 sequences = numConsolidatedRange,\n",
    "#                                                 non_sequences=[x])\n",
    "            return theano.tensor.nnet.relu(x + self.biases[ind])\n",
    "#             return r\n",
    "\n",
    "        def gradLayer(ind, nextdEdInputs, layerOutput): #returns (dEdWs, dEdBs, newdEdInputs)\n",
    "            expandedLayerOutput = T.repeat(layerOutput, self.bMult)\n",
    "            inverse = self.dEdWsinverseConsols[ind]\n",
    "            inverseddEdInputs = nextdEdInputs.take(inverse)\n",
    "            dEdWs = expandedLayerOutput * inverseddEdInputs\n",
    "            dEdBs = nextdEdInputs\n",
    "            #upt to here correct\n",
    "            \n",
    "            dOutsdIns = T.gt(layerOutput, T.zeros_like(layerOutput))\n",
    "            dOutsdIns = T.cast(dOutsdIns, 'float32')\n",
    "            \n",
    "            dEdConnections = self.weights[ind] * inverseddEdInputs\n",
    "            dEdConnectionGroups = dEdConnections.reshape((dEdConnections.size // self.bMult, self.bMult))\n",
    "            dEdOuts = T.dot(dEdConnectionGroups, self.bMultOnes) #could need to be axis 1\n",
    "            \n",
    "            newdEdInputs = dEdOuts * dOutsdIns\n",
    "            \n",
    "            return (dEdWs, dEdBs, newdEdInputs)\n",
    "        \n",
    "        def intermediateLoop(z):\n",
    "            ret = []\n",
    "            for i in range(self.hiddenlayers):\n",
    "                z = layer(i, z)\n",
    "                ret.append(z.copy())\n",
    "            \n",
    "            return ret\n",
    "        \n",
    "        def gradLoop(dEdIn, layerOutputs):\n",
    "            dEdWs = []\n",
    "            dEdBs = []\n",
    "            for k in reversed(range(self.hiddenlayers)):\n",
    "                newdEdWs, newdEdBs, dEdIn = gradLayer(k, dEdIn, layerOutputs[k])\n",
    "                dEdWs.append(newdEdWs)\n",
    "                dEdBs.append(newdEdBs)\n",
    "            \n",
    "            return dEdWs, dEdBs\n",
    "        \n",
    "        def myGrad(theta, actualOutp):\n",
    "            #get gradient given input (theta) and the target output (actualOutp)\n",
    "            \n",
    "            #get all layer outputs\n",
    "            outputs = intermediateLoop(theta)\n",
    "            \n",
    "            #list of all outputs, including input layer \"outputs\"\n",
    "            outputs = [theta] + outputs\n",
    "            \n",
    "            #calculate final output\n",
    "            last = T.dot(outputs[-1], self.fws)\n",
    "            last = last + self.fbs\n",
    "            last = theano.tensor.nnet.relu(last)\n",
    "            \n",
    "            #get error\n",
    "            difference = last - actualOutp\n",
    "            err = T.dot(difference, difference)\n",
    "            \n",
    "            #get final layer derivative\n",
    "            finaldOutdIn = T.gt(last, T.zeros_like(last))\n",
    "            finaldOutdIn = T.cast(finaldOutdIn, 'float32')\n",
    "            \n",
    "            #get derivative of error with respect to last layer inputs\n",
    "            initdEdIn = finaldOutdIn * (last - actualOutp)\n",
    "            dEdFbs = initdEdIn   \n",
    "            \n",
    "            \n",
    "            initdEdInshuffled = initdEdIn.dimshuffle(('x',0))\n",
    "            finalStructuredLayerOut = outputs[-1]\n",
    "            finalStructuredLayerOutShuffled = finalStructuredLayerOut.dimshuffle((0,'x'))\n",
    "            \n",
    "            dEdFws = finalStructuredLayerOutShuffled * initdEdInshuffled\n",
    "            \n",
    "            \n",
    "            finalStructuredLayerdOutdIn = T.gt(finalStructuredLayerOut, T.zeros_like(finalStructuredLayerOut))\n",
    "            finalStructuredLayerdOutdIn = T.cast(finalStructuredLayerdOutdIn, 'float32')\n",
    "            \n",
    "            finalStructuredLayerdEdOut = T.dot(initdEdIn, self.fws.T)\n",
    "            \n",
    "            finalStructuredLayerdEdIn = finalStructuredLayerdOutdIn * finalStructuredLayerdEdOut\n",
    "            #up to here is correct\n",
    "\n",
    "            dEdWs, dEdBs = gradLoop(finalStructuredLayerdEdIn, outputs)\n",
    "            \n",
    "            return err, list(reversed(dEdWs)), list(reversed(dEdBs)), dEdFws, dEdFbs #, list(reversed(dEdIns)),\n",
    "            \n",
    "            \n",
    "        final = T.fvector()\n",
    "        def loop(z):\n",
    "            ret = T.fvector()\n",
    "            for i in range(self.hiddenlayers):\n",
    "                z = layer(i, z)\n",
    "                ret = z\n",
    "            return ret\n",
    "        finalHiddenOutput = loop(inp)\n",
    "        final = T.dot(finalHiddenOutput, self.fws)\n",
    "        final = final + self.fbs\n",
    "        final = theano.tensor.nnet.relu(final)\n",
    "        \n",
    "        #Declare theano functions for full classifaction (including end relu linerar classifier)\n",
    "        self.classify = theano.function([inp], final)\n",
    "        self.partialClassify = theano.function([inp], finalHiddenOutput)\n",
    "        \n",
    "        index = T.iscalar()\n",
    "        \n",
    "        self.partialClassifyTraining = theano.function(inputs= [index], outputs = finalHiddenOutput,\n",
    "                                                       givens = {\n",
    "                                                                        inp : self.sharedTrainingInps[index],\n",
    "                                                                    } )\n",
    "        self.partialClassifyTesting = theano.function(inputs=[index], outputs = finalHiddenOutput,\n",
    "                                                     givens = {\n",
    "                                                         inp : self.sharedTestingInps[index]\n",
    "                                                     })\n",
    "        \n",
    "        diff = final - actualOutp\n",
    "        squared = 0.5 * T.dot(diff, diff)\n",
    "\n",
    "#         print self.classify(np.array([0,1,2,3]).astype(theano.config.floatX))\n",
    "\n",
    "        index = T.iscalar()\n",
    "\n",
    "        squaredError, wgrads, bgrads, fwsgrads, fbsgrads = myGrad(inp, actualOutp)\n",
    "#         mygradients = myGrad(inp, actualOutp)\n",
    "        self.realGrad = theano.function(inputs = [inp, actualOutp], outputs = T.grad(squared, self.weights))\n",
    "        self.mygrads = theano.function(inputs = [inp, actualOutp], outputs = wgrads)\n",
    "        \n",
    "        #concatenate lists of the gradients so as to iteratively modify them -- don't worry, I'm not just adding them together\n",
    "        gradients = wgrads + bgrads + [fwsgrads, fbsgrads]\n",
    "        \n",
    "#         realgrads = T.grad(squared, self.params)\n",
    "#         realUpdates = OrderedDict((p, p - alpha * g) for p, g in zip(self.params, realgrads))\n",
    "        param_Updates = OrderedDict((p, p - alpha * g) for p, g in zip(self.params, gradients))\n",
    "        \n",
    "        self.intermediates = theano.function([inp], intermediateLoop(inp))\n",
    "        \n",
    "        self.train = theano.function(inputs = [index, alpha],\n",
    "                                                                    outputs = squaredError,\n",
    "                                                                    updates = param_Updates,\n",
    "                                                                    givens = {\n",
    "                                                                        inp : self.sharedTrainingInps[index],\n",
    "                                                                        actualOutp: self.sharedTrainingOutps[index]\n",
    "                                                                    })\n",
    "#         self.realtrain = theano.function(inputs = [index, alpha],\n",
    "#                                                                     outputs = squared,\n",
    "#                                                                     updates = realUpdates,\n",
    "#                                                                     givens = {\n",
    "#                                                                         inp : self.sharedTrainingInps[index],\n",
    "#                                                                         actualOutp: self.sharedTrainingOutps[index]\n",
    "#                                                                     })\n",
    "        self.test = theano.function(inputs = [index],\n",
    "            outputs = final,\n",
    "            givens = {\n",
    "                inp : self.sharedTestingInps[index]\n",
    "            })\n",
    "    \n",
    "    def descend(self, alpha, epochs, trainingInps, trainingOutps, testingInps, testingOutps, verbose):\n",
    "        training = zip(trainingInps, trainingOutps)\n",
    "        testing = zip(testingInps, testingOutps)\n",
    "        testLen = len(testing)\n",
    "        trainLen = len(trainingInps)\n",
    "        indorder = range(trainLen)\n",
    "        testingAccuracies = []\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            print \"starting epoch...\"\n",
    "            start = time.time()\n",
    "            shuffle(indorder)\n",
    "            for j in indorder:\n",
    "                self.train(j, alpha)\n",
    "            \n",
    "            testingAccuracy = 0.0\n",
    "            for j in range(len(testingOutps)):\n",
    "                if np.argmax(self.test(j)) == np.argmax(testingOutps[j]):\n",
    "                    testingAccuracy += 1.0\n",
    "            # for (testInp, testOutp) in testing:\n",
    "            #     if np.argmax(self.classify(testInp)) == np.argmax(testOutp):\n",
    "            #         testingAccuracy += 1.0\n",
    "                    \n",
    "            percentTestingAccuracy = testingAccuracy / testLen * 100.0\n",
    "            testingAccuracies.append(percentTestingAccuracy)\n",
    "            end = time.time()\n",
    "            if verbose:\n",
    "                print \"epoch \" + str(i + 1) + \" -- testing accuracy : \" + str(percentTestingAccuracy) + \" duration: \" + str(end - start) + \"s\"\n",
    "        \n",
    "        return max(testingAccuracies), testingAccuracies\n",
    "            \n",
    "        \n",
    "tn = tnnet(10, [[lambda x: x + 1], [lambda x: x * 2]], 1, [np.array([0,1,2,3])], [np.array([1,2,3,4])],  [np.array([1,2,3,4])],  [np.array([1,2,3,4])], 100)\n",
    "print tn.nnet.feedforward(np.array([0,1,2,3]))\n",
    "print tn.intermediates(np.array([0,1,2,3]).astype(theano.config.floatX))\n",
    "# print tn.nnet.weights\n",
    "# print tn.nnet.biases\n",
    "x = np.array([0,1,2,3]).astype(theano.config.floatX)\n",
    "classed = tn.classify(np.array([0,1,2,3]).astype(theano.config.floatX))\n",
    "# print '\\n'.join(map(str,classed))\n",
    "# diff = x * 0.5 - classed\n",
    "# print np.dot(diff, diff)\n",
    "# print tn.classify(np.array([0,1,2,3]).astype(theano.config.floatX))\n",
    "print '\\n'.join(map(str, tn.realGrad(x, x * 0.33)))\n",
    "print '\\n'.join(map(str, tn.mygrads(x, x*0.33)))\n",
    "map(type, tn.mygrads(x, x * 0.33))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "nj8CfYB8o8gQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theano.config.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "lDEgKax3o8gb",
    "outputId": "1c206e12-9712-4c4d-ab70-1687de132e4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating\n",
      "running initial dictSingleGenConsolidate\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "starting to loop\n",
      "branchmultiplier: 51\n",
      "weights length: 39984\n",
      "final layer output length: 6824\n",
      "average number of connections per neuron by layer: [5.859320046893318]\n",
      "spacial dimension: 7\n",
      "branching by dimension: [10, 10, 1, 9, 10, 9, 2]\n",
      "beginning partial classification\n",
      "partial classification took:  66.1427588463\n",
      "starting to build keras linear classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/theano_p27/lib/python2.7/site-packages/ipykernel/__main__.py:134: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=10, kernel_initializer=\"normal\", activation=\"softmax\", input_dim=6824)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.9911 - categorical_accuracy: 0.7800\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.5567 - categorical_accuracy: 0.8654\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.4741 - categorical_accuracy: 0.8796\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.4341 - categorical_accuracy: 0.8865\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.4094 - categorical_accuracy: 0.8907\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.3924 - categorical_accuracy: 0.8938\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.3797 - categorical_accuracy: 0.8966\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.3698 - categorical_accuracy: 0.8983\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.3618 - categorical_accuracy: 0.9002\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.3551 - categorical_accuracy: 0.9014\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.3495 - categorical_accuracy: 0.9021\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.3446 - categorical_accuracy: 0.9039\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.3402 - categorical_accuracy: 0.9049\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.3364 - categorical_accuracy: 0.9060\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.3330 - categorical_accuracy: 0.9068\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.3300 - categorical_accuracy: 0.9075\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.3273 - categorical_accuracy: 0.9083\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.3247 - categorical_accuracy: 0.9093\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.3224 - categorical_accuracy: 0.9097\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.3202 - categorical_accuracy: 0.9103\n",
      "10000/10000 [==============================] - 0s 35us/step\n",
      "<keras.callbacks.History object at 0x7f2a68e4af90>\n",
      "keras building and training took: 63.6637091637\n",
      "linear model training accuracy,testing accuracy: 0.9103333333333333  ,  0.9158\n",
      "evaluating\n",
      "running initial dictSingleGenConsolidate\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "starting to loop\n",
      "branchmultiplier: 8\n",
      "weights length: 6272\n",
      "final layer output length: 2598\n",
      "average number of connections per neuron by layer: [2.414164742109315]\n",
      "spacial dimension: 3\n",
      "branching by dimension: [3, 3, 2]\n",
      "beginning partial classification\n",
      "partial classification took:  23.5786890984\n",
      "starting to build keras linear classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/theano_p27/lib/python2.7/site-packages/ipykernel/__main__.py:134: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=10, kernel_initializer=\"normal\", activation=\"softmax\", input_dim=2598)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 2.1925 - categorical_accuracy: 0.4950\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 1.9912 - categorical_accuracy: 0.6945\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 1.8213 - categorical_accuracy: 0.7241\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 1.6786 - categorical_accuracy: 0.7423\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 1.5585 - categorical_accuracy: 0.7547\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 1.4571 - categorical_accuracy: 0.7668\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 1.3712 - categorical_accuracy: 0.7753\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 1.2977 - categorical_accuracy: 0.7824\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 1.2342 - categorical_accuracy: 0.7902\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 1.1792 - categorical_accuracy: 0.7950\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 1.1308 - categorical_accuracy: 0.8008\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 1.0884 - categorical_accuracy: 0.8045\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 1.0505 - categorical_accuracy: 0.8091\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 1.0167 - categorical_accuracy: 0.8122\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.9863 - categorical_accuracy: 0.8155\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.9587 - categorical_accuracy: 0.8182\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.9337 - categorical_accuracy: 0.8205\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.9109 - categorical_accuracy: 0.8227\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.8900 - categorical_accuracy: 0.8245\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.8707 - categorical_accuracy: 0.8269\n",
      "10000/10000 [==============================] - 0s 25us/step\n",
      "<keras.callbacks.History object at 0x7f2a612ad710>\n",
      "keras building and training took: 51.8875770569\n",
      "linear model training accuracy,testing accuracy: 0.8269333333333333  ,  0.837\n",
      "evaluating\n",
      "running initial dictSingleGenConsolidate\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "starting to loop\n",
      "branchmultiplier: 26\n",
      "weights length: 20384\n",
      "final layer output length: 4112\n",
      "average number of connections per neuron by layer: [4.957198443579767]\n",
      "spacial dimension: 5\n",
      "branching by dimension: [7, 3, 7, 3, 6]\n",
      "beginning partial classification\n",
      "partial classification took:  37.0649700165\n",
      "starting to build keras linear classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/theano_p27/lib/python2.7/site-packages/ipykernel/__main__.py:134: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=10, kernel_initializer=\"normal\", activation=\"softmax\", input_dim=4112)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 1.4023 - categorical_accuracy: 0.7349\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.8150 - categorical_accuracy: 0.8374\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.6590 - categorical_accuracy: 0.8536\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.5828 - categorical_accuracy: 0.8637\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.5362 - categorical_accuracy: 0.8701\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.5043 - categorical_accuracy: 0.8740\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.4808 - categorical_accuracy: 0.8779\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.4625 - categorical_accuracy: 0.8804\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.4480 - categorical_accuracy: 0.8832\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.4359 - categorical_accuracy: 0.8845\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.4258 - categorical_accuracy: 0.8866\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.4172 - categorical_accuracy: 0.8881\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.4096 - categorical_accuracy: 0.8896\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.4030 - categorical_accuracy: 0.8909\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.3972 - categorical_accuracy: 0.8917\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.3919 - categorical_accuracy: 0.8926\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.3872 - categorical_accuracy: 0.8937\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.3828 - categorical_accuracy: 0.8941\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.3789 - categorical_accuracy: 0.8947\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.3753 - categorical_accuracy: 0.8960\n",
      "10000/10000 [==============================] - 0s 30us/step\n",
      "<keras.callbacks.History object at 0x7f2a66471110>\n",
      "keras building and training took: 55.4362230301\n",
      "linear model training accuracy,testing accuracy: 0.8959833333333334  ,  0.9034\n",
      "evaluating\n",
      "running initial dictSingleGenConsolidate\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "starting to loop\n",
      "branchmultiplier: 61\n",
      "weights length: 47824\n",
      "final layer output length: 11416\n",
      "average number of connections per neuron by layer: [4.189208128941836]\n",
      "spacial dimension: 10\n",
      "branching by dimension: [9, 4, 3, 2, 8, 10, 9, 10, 2, 4]\n",
      "beginning partial classification\n",
      "partial classification took:  110.32301116\n",
      "starting to build keras linear classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/theano_p27/lib/python2.7/site-packages/ipykernel/__main__.py:134: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=10, kernel_initializer=\"normal\", activation=\"softmax\", input_dim=11416)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.7750 - categorical_accuracy: 0.8204\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.4579 - categorical_accuracy: 0.8811\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.4041 - categorical_accuracy: 0.8911\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.3780 - categorical_accuracy: 0.8957\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.3615 - categorical_accuracy: 0.8990\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.3498 - categorical_accuracy: 0.9016\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.3409 - categorical_accuracy: 0.9043\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.3341 - categorical_accuracy: 0.9060\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.3285 - categorical_accuracy: 0.9079\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.3237 - categorical_accuracy: 0.9091\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.3198 - categorical_accuracy: 0.9097\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.3162 - categorical_accuracy: 0.9109\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.3131 - categorical_accuracy: 0.9116\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.3103 - categorical_accuracy: 0.9128\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.3077 - categorical_accuracy: 0.9132\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.3055 - categorical_accuracy: 0.9146\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.3036 - categorical_accuracy: 0.9144\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.3017 - categorical_accuracy: 0.9153\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.3000 - categorical_accuracy: 0.9152\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.2985 - categorical_accuracy: 0.9160\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "<keras.callbacks.History object at 0x7f2a664f2a50>\n",
      "keras building and training took: 72.7179510593\n",
      "linear model training accuracy,testing accuracy: 0.9160166666666667  ,  0.9182\n",
      "evaluating\n",
      "running initial dictSingleGenConsolidate\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "starting to loop\n",
      "branchmultiplier: 35\n",
      "weights length: 27440\n",
      "final layer output length: 4744\n",
      "average number of connections per neuron by layer: [5.7841483979763915]\n",
      "spacial dimension: 6\n",
      "branching by dimension: [8, 5, 3, 10, 8, 1]\n",
      "beginning partial classification\n",
      "partial classification took:  47.6995630264\n",
      "starting to build keras linear classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/theano_p27/lib/python2.7/site-packages/ipykernel/__main__.py:134: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=10, kernel_initializer=\"normal\", activation=\"softmax\", input_dim=4744)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 1.2173 - categorical_accuracy: 0.7565\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.6885 - categorical_accuracy: 0.8479\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.5699 - categorical_accuracy: 0.8649\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.5121 - categorical_accuracy: 0.8732\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.4766 - categorical_accuracy: 0.8788\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.4521 - categorical_accuracy: 0.8834\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.4340 - categorical_accuracy: 0.8860\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.4200 - categorical_accuracy: 0.8883\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.4085 - categorical_accuracy: 0.8901\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.3992 - categorical_accuracy: 0.8919\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.3913 - categorical_accuracy: 0.8933\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.3845 - categorical_accuracy: 0.8952\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.3786 - categorical_accuracy: 0.8961\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.3734 - categorical_accuracy: 0.8970\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.3687 - categorical_accuracy: 0.8983\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.3645 - categorical_accuracy: 0.8985\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.3607 - categorical_accuracy: 0.9000\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.3573 - categorical_accuracy: 0.9002\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.3540 - categorical_accuracy: 0.9009\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.3511 - categorical_accuracy: 0.9017\n",
      "10000/10000 [==============================] - 0s 28us/step\n",
      "<keras.callbacks.History object at 0x7f2a61165250>\n",
      "keras building and training took: 54.3379771709\n",
      "linear model training accuracy,testing accuracy: 0.90165  ,  0.9081\n",
      "evaluating\n",
      "running initial dictSingleGenConsolidate\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "starting to loop\n",
      "branchmultiplier: 16\n",
      "weights length: 12544\n",
      "final layer output length: 1640\n",
      "average number of connections per neuron by layer: [7.648780487804878]\n",
      "spacial dimension: 2\n",
      "branching by dimension: [6, 10]\n",
      "beginning partial classification\n"
     ]
    }
   ],
   "source": [
    "import deap.gp as gp\n",
    "import time\n",
    "import sys\n",
    "import sklearn.svm as svm\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras import metrics\n",
    "import copy\n",
    "sys.setrecursionlimit(1500)\n",
    "\n",
    "def mnistevaluate(individual):\n",
    "    weights = []\n",
    "    biases = []\n",
    "    branching = 0\n",
    "    consolidations = []\n",
    "    fws = []\n",
    "    fbs = []\n",
    "    hiddenlayers = 0\n",
    "    weightnum = 0\n",
    "    branching = 0\n",
    "    \n",
    "    print \"evaluating\"\n",
    "    funcs = []\n",
    "    for dimlist in individual:\n",
    "        newDimlist = []\n",
    "        for tree in dimlist:\n",
    "#             print gp.stringify(tree)\n",
    "            f = gp.compile(tree, pset)\n",
    "            newDimlist.append(f)\n",
    "        funcs.append(newDimlist)\n",
    "    \n",
    "    res = 20\n",
    "    tnet = tnnet(res, funcs, 2, trainingimgs, traininglabels, testingimgs, testinglabels, 200000)\n",
    "    mynet = tnet.nnet\n",
    "    weights = mynet.weights\n",
    "    biases = mynet.biases\n",
    "    branching = mynet.branchMultiplier\n",
    "    consolidations = mynet.consolidations\n",
    "    fws = mynet.finalweights\n",
    "    fbs = mynet.finalbiases\n",
    "    hiddenlayers = mynet.hiddenlayers\n",
    "    weightnum = mynet.weightnum\n",
    "    print \"branchmultiplier: \" + str(mynet.branchMultiplier)\n",
    "    print \"weights length: \" + str(len(flatten(mynet.weights)))\n",
    "#     print \"consolidations lengths\" + str(map(len, mynet.consolidations))\n",
    "    layerDensities = []\n",
    "    prevlayerLength = trainingimgs[0].size\n",
    "    for layer in mynet.weights:\n",
    "        layerLength = len(layer)\n",
    "        branched = prevlayerLength * mynet.branchMultiplier\n",
    "        layerDensities.append((1.0 * branched) / layerLength)\n",
    "        prevlayerLength = layerLength\n",
    "    print \"average number of connections per neuron by layer: \" + str(layerDensities)\n",
    "    print \"spacial dimension: \" + str(len(funcs))\n",
    "    print \"branching by layer: \" + str(map(len, funcs))\n",
    "    print \"beginning training\"\n",
    "    testStart = time.time()\n",
    "    x = tnet.train(0, 0.05)\n",
    "    print \"trained in: \" + str(time.time() - testStart)\n",
    "    print x\n",
    "    print tnet.classify(trainingimgs[0])\n",
    "#     testStart = time.time()\n",
    "#     x = tnet.realtrain(0, 0.05)\n",
    "    print \"autograd trained in: \" + str(time.time() - testStart)\n",
    "    \n",
    "    avgpercenttestAccuracy, avgpercenttestAccuracylist = tnet.descend(0.02, 5, trainingimgs,traininglabels, testingimgs, testinglabels, True)\n",
    "    return avgpercenttestAccuracy\n",
    "\n",
    "\n",
    "sampleHistoryObject = None\n",
    "netHistoryList = []\n",
    "def mnistEvaluateRandomWeights(individual):\n",
    "    weights = []\n",
    "    biases = []\n",
    "    branching = 0\n",
    "    consolidations = []\n",
    "    fws = []\n",
    "    fbs = []\n",
    "    hiddenlayers = 0\n",
    "    weightnum = 0\n",
    "    branching = 0\n",
    "    \n",
    "    print \"evaluating\"\n",
    "    funcs = []\n",
    "    for dimlist in individual:\n",
    "        newDimlist = []\n",
    "        for tree in dimlist:\n",
    "#             print gp.stringify(tree)\n",
    "            f = gp.compile(tree, pset)\n",
    "            newDimlist.append(f)\n",
    "        funcs.append(newDimlist)\n",
    "    \n",
    "    res = 20\n",
    "    tnet = tnnet(res, funcs, 2, trainingimgs, traininglabels, testingimgs, testinglabels, 50000)\n",
    "    mynet = tnet.nnet\n",
    "    weights = mynet.weights\n",
    "    biases = mynet.biases\n",
    "    branching = mynet.branchMultiplier\n",
    "    consolidations = mynet.consolidations\n",
    "    fws = mynet.finalweights\n",
    "    fbs = mynet.finalbiases\n",
    "    hiddenlayers = mynet.hiddenlayers\n",
    "    weightnum = mynet.weightnum\n",
    "    print \"branchmultiplier: \" + str(mynet.branchMultiplier)\n",
    "    print \"weights length: \" + str(len(flatten(mynet.weights)))\n",
    "#     print \"consolidations lengths\" + str(map(len, mynet.consolidations))\n",
    "    layerDensities = []\n",
    "    prevlayerLength = trainingimgs[0].size\n",
    "    for i in range(len(consolidations)):\n",
    "        layerDensities.append(np.mean(map(lambda l: len(l), consolidations[i])))\n",
    "    print \"final layer output length: \" + str(len(consolidations[-1]))\n",
    "    print \"average number of connections per neuron by layer: \" + str(layerDensities)\n",
    "    print \"spacial dimension: \" + str(len(funcs))\n",
    "    print \"branching by dimension: \" + str(map(len, funcs))\n",
    "    print \"beginning partial classification\"\n",
    "    testStart = time.time()\n",
    "    \n",
    "    #generate dataset with random weights\n",
    "    randomWeightsTrainingOutputs = []\n",
    "    for i in range(len(trainingimgs)):\n",
    "        randomWeightsTrainingOutputs.append(tnet.partialClassifyTraining(i))\n",
    "        \n",
    "    randomWeightsTestingOutputs = []\n",
    "    for i in range(len(testingimgs)):\n",
    "        randomWeightsTestingOutputs.append(tnet.partialClassifyTesting(i))\n",
    "    \n",
    "    outputSize = randomWeightsTrainingOutputs[0].size\n",
    "        \n",
    "    print \"partial classification took:  \" + str(time.time() - testStart)\n",
    "    testStart = time.time()\n",
    "    print \"starting to build keras linear classifier\"\n",
    "    \n",
    "    linearClassifier = Sequential()\n",
    "    linearClassifier.add(Dense(input_dim=outputSize, units=10, activation=\"softmax\", init=\"normal\"))\n",
    "    linearClassifier.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=[metrics.categorical_accuracy])\n",
    "    \n",
    "    trainingHistory = linearClassifier.fit(np.array(randomWeightsTrainingOutputs,dtype='float32'),np.array(traininglabels,dtype='float32'),epochs=20)\n",
    "    loss, accuracy = linearClassifier.evaluate(np.array(randomWeightsTestingOutputs,dtype='float32'),np.array(testinglabels,dtype='float32'))\n",
    "    \n",
    "    print trainingHistory\n",
    "    sampleHistoryObject = trainingHistory\n",
    "    \n",
    "    print \"keras building and training took: \" + str(time.time() - testStart)\n",
    "    print \"linear model training accuracy,testing accuracy: \" + str(trainingHistory.history['categorical_accuracy'][-1]) + \"  ,  \" + str(accuracy)\n",
    "    \n",
    "    netHistoryList.append({\"net\": copy.deepcopy(mynet), \"kerasHistoryDict\":trainingHistory.history, \"densities\":layerDensities,\n",
    "                           \"funcs\":funcs[:], \"kerasTestAccuracy\":accuracy})\n",
    "#     mySVMclassifier = svm.LinearSVC()\n",
    "    \n",
    "#     #svm doesn't want vectors as the class, just scalars\n",
    "#     mySVMclassifier.fit(randomWeightsTrainingOutputs, train_labels)\n",
    "    \n",
    "#     accuracy = mySVMclassifier.score(randomWeightsTestingOutputs, test_labels)\n",
    "#     print \"SVM Accuracy \" + str(accuracy)\n",
    "    \n",
    "    \n",
    "    return accuracy\n",
    "    \n",
    "\n",
    "evolve(mnistEvaluateRandomWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "sVPrn32Io8go",
    "outputId": "78405ad5-4013-41d4-8530-4fe2b807e272"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4)\n",
      "(100,)\n",
      "[1 1 0 0 0 0 0 1 0 1 0 1 1 1 1 0 0 0 1 1 1 0 0 1 0 1 1 1 0 1 1 1 0 1 1 1 0\n",
      " 1 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 1 0 0 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0\n",
      " 1 0 1 0 0 1 1 0 1 1 0 1 1 0 1 0 0 1 1 0 1 1 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_features=4, random_state=0)\n",
    "print str(X.shape)\n",
    "print str(y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "NeYABakdo8g8",
    "outputId": "6ee523b4-f91c-499c-80c0-ef7a74d67c9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting theano net instance...\n"
     ]
    },
    {
     "ename": "UnusedInputError",
     "evalue": "theano.function was asked to create a function computing outputs given certain inputs, but the provided input variable at index 0 is not part of the computational graph needed to compute the outputs: inp.\nTo make this error into a warning, you can pass the parameter on_unused_input='warn' to theano.function. To disable it completely, use on_unused_input='ignore'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnusedInputError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-868a88d1e99c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m\"numpy classified in \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtestStart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mtnetFromParams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbiases\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfws\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfbs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsolidations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhiddenlayers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweightnum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbranching\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-868a88d1e99c>\u001b[0m in \u001b[0;36mtnetFromParams\u001b[1;34m(weights, biases, fws, fbs, consolidations, hiddenlayers, weightnum, branching)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbranchingmultiplier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbranching\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m\"starting theano net instance...\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mmytnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtnnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainingimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraininglabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestingimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestinglabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mtestStart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmytnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainingimgs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-a7fa26851401>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, resolution, functions, inputdimension, traindatainps, traindataoutps, testdatainps, testdataoutps, synapseThreshold, net)\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[0mfinal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassify\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m \u001b[1;31m#         print self.classify(np.array([0,1,2,3]).astype(theano.config.floatX))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/theano/compile/function.pyc\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[0;32m    318\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m                    output_keys=output_keys)\n\u001b[0m\u001b[0;32m    321\u001b[0m     \u001b[1;31m# We need to add the flag check_aliased inputs if we have any mutable or\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[1;31m# borrowed used defined inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/theano/compile/pfunc.pyc\u001b[0m in \u001b[0;36mpfunc\u001b[1;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[0;32m    477\u001b[0m                          \u001b[0maccept_inplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_inplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    478\u001b[0m                          \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 479\u001b[1;33m                          output_keys=output_keys)\n\u001b[0m\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36morig_function\u001b[1;34m(inputs, outputs, mode, accept_inplace, name, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[0;32m   1774\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1775\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1776\u001b[1;33m                    \u001b[0moutput_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1777\u001b[0m             defaults)\n\u001b[0;32m   1778\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, mode, accept_inplace, function_builder, profile, on_unused_input, fgraph, output_keys)\u001b[0m\n\u001b[0;32m   1413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1414\u001b[0m         \u001b[1;31m# Check if some input variables are unused\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1415\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_unused_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon_unused_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m         \u001b[1;31m# Make a list of (SymbolicInput|SymblicInputKits, indices,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m_check_unused_inputs\u001b[1;34m(self, inputs, outputs, on_unused_input)\u001b[0m\n\u001b[0;32m   1551\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mon_unused_input\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'raise'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1552\u001b[0m                     raise UnusedInputError(msg % (inputs.index(i),\n\u001b[1;32m-> 1553\u001b[1;33m                                                   i.variable, err_msg))\n\u001b[0m\u001b[0;32m   1554\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1555\u001b[0m                     raise ValueError(\"Invalid value for keyword \"\n",
      "\u001b[1;31mUnusedInputError\u001b[0m: theano.function was asked to create a function computing outputs given certain inputs, but the provided input variable at index 0 is not part of the computational graph needed to compute the outputs: inp.\nTo make this error into a warning, you can pass the parameter on_unused_input='warn' to theano.function. To disable it completely, use on_unused_input='ignore'."
     ]
    }
   ],
   "source": [
    "def tnetFromParams(weights, biases, fws, fbs, consolidations, hiddenlayers, weightnum, branching):\n",
    "    frame = nnet(10, [[lambda x: x + 1], [lambda x: x * 2]], 1, [np.array([0,1,2,3])], [np.array([1])], 100)\n",
    "    frame.weights = weights\n",
    "    frame.biases = biases\n",
    "    frame.finalweights = np.array(fws).astype(theano.config.floatX)\n",
    "    frame.finalbiases = np.array(fbs).astype(theano.config.floatX)\n",
    "    frame.consolidations = consolidations\n",
    "    frame.hiddenlayers = hiddenlayers\n",
    "    frame.weightnum = weightnum\n",
    "    frame.branchingmultiplier = branching\n",
    "    print \"starting theano net instance...\"\n",
    "    mytnet = tnnet(10, [[lambda x: x + 1], [lambda x: x * 2]], 1, trainingimgs, traininglabels, testingimgs, testinglabels, 5000, net = frame)\n",
    "    testStart = time.time()\n",
    "    x = mytnet.classify(trainingimgs[0])\n",
    "    print \"classified in \" + str(time.time() - testStart)\n",
    "    testStart = time.time()\n",
    "    x = frame.feedforward(trainingimgs[0])\n",
    "    print \"numpy classified in \" + str(time.time() - testStart)\n",
    "\n",
    "tnetFromParams(weights, biases, fws, fbs, consolidations, hiddenlayers, weightnum, branching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "yEp_G79Jo8hM",
    "outputId": "c5d71b76-ff5e-435a-c958-ef090f8006f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 0.752302922028\n",
      "Cost: 0.234828531853\n",
      "Cost: 0.217997165391\n",
      "Cost: 0.176582778796\n",
      "Cost: 0.0941889559431\n",
      "Cost: 0.0547008715418\n",
      "Cost: 0.0227962112237\n",
      "Cost: 0.0103721161976\n",
      "Cost: 0.00631427914256\n",
      "Cost: 0.00444667437915\n",
      "Cost: 0.00339910571615\n",
      "Cost: 0.00273639533448\n",
      "Cost: 0.00228238999109\n",
      "Cost: 0.00195317405859\n",
      "Cost: 0.00170428799655\n",
      "Cost: 0.00150985199376\n",
      "Cost: 0.00135402741352\n",
      "Cost: 0.00122653983734\n",
      "Cost: 0.00112027524709\n",
      "Cost: 0.00103046853549\n",
      "0.971243725343\n",
      "0.0324757818475\n",
      "0.97118115104\n",
      "0.0308740290756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 970 (CNMeM is disabled, cuDNN not available)\n"
     ]
    }
   ],
   "source": [
    "import theano.tensor.nnet as nnet\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "import numpy as np\n",
    "x = T.dvector()\n",
    "y = T.dscalar()\n",
    "def layer(x, w):\n",
    "    b = np.array([1], dtype=theano.config.floatX)\n",
    "    new_x = T.concatenate([x, b])\n",
    "    m = T.dot(w.T, new_x) #theta1: 3x3 * x: 3x1 = 3x1 ;;; theta2: 1x4 * 4x1\n",
    "    h = nnet.sigmoid(m)\n",
    "    return h\n",
    "def grad_desc(cost, theta):\n",
    "    alpha = 0.1 #learning rate\n",
    "    return theta - (alpha * T.grad(cost, wrt=theta))\n",
    "theta1 = theano.shared(np.array(np.random.rand(3,3), dtype=theano.config.floatX)) # randomly initialize\n",
    "theta2 = theano.shared(np.array(np.random.rand(4,1), dtype=theano.config.floatX))\n",
    "hid1 = layer(x, theta1) #hidden layer\n",
    "out1 = T.sum(layer(hid1, theta2)) #output layer\n",
    "fc = (out1 - y)**2 #cost expression\n",
    "\n",
    "\n",
    "cost = theano.function(inputs=[x, y], outputs=fc, updates=[\n",
    "        (theta1, grad_desc(fc, theta1)),\n",
    "        (theta2, grad_desc(fc, theta2))])\n",
    "run_forward = theano.function(inputs=[x], outputs=out1)\n",
    "inputs = np.array([[0,1],[1,0],[1,1],[0,0]]).reshape(4,2) #training data X\n",
    "exp_y = np.array([1, 1, 0, 0]) #training data Y\n",
    "cur_cost = 0\n",
    "for i in range(10000):\n",
    "    for k in range(len(inputs)):\n",
    "        cur_cost = cost(inputs[k], exp_y[k]) #call our Theano-compiled cost function, it will auto update weights\n",
    "    if i % 500 == 0: #only print the cost every 500 epochs/iterations (to save space)\n",
    "        print('Cost: %s' % (cur_cost,))\n",
    "        \n",
    "\n",
    "\n",
    "#Training done! Let's test it out\n",
    "print(run_forward([0,1]))\n",
    "print(run_forward([1,1]))\n",
    "print(run_forward([1,0]))\n",
    "print(run_forward([0,0]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3b6BDwT7o8hg",
    "outputId": "76a1e4e7-f4cf-411b-e5f3-1882464400a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GpuElemwise{exp,no_inplace}(<CudaNdarrayType(float32, vector)>), HostFromGpu(GpuElemwise{exp,no_inplace}.0)]\n",
      "Looping 1000 times took 0.332850 seconds\n",
      "Result is [ 1.23178029  1.61879349  1.52278066 ...,  2.20771813  2.29967761\n",
      "  1.62323296]\n",
      "Used the gpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 970 (CNMeM is disabled, cuDNN not available)\n"
     ]
    }
   ],
   "source": [
    "from theano import function, config, shared, sandbox\n",
    "import theano.tensor as T\n",
    "import numpy\n",
    "import time\n",
    "\n",
    "vlen = 10 * 30 * 768  # 10 x #cores x # threads per core\n",
    "iters = 1000\n",
    "\n",
    "rng = numpy.random.RandomState(22)\n",
    "x = shared(numpy.asarray(rng.rand(vlen), config.floatX))\n",
    "f = function([], T.exp(x))\n",
    "print(f.maker.fgraph.toposort())\n",
    "t0 = time.time()\n",
    "for i in range(iters):\n",
    "    r = f()\n",
    "t1 = time.time()\n",
    "print(\"Looping %d times took %f seconds\" % (iters, t1 - t0))\n",
    "print(\"Result is %s\" % (r,))\n",
    "if numpy.any([isinstance(x.op, T.Elemwise) for x in f.maker.fgraph.toposort()]):\n",
    "    print('Used the cpu')\n",
    "else:\n",
    "    print('Used the gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "ekPuNdbUo8h7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3G-IDP2bo8iK",
    "outputId": "e1f99a3d-02a6-4232-8845-70c8c603618c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  2.,  1.,  4.], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = T.fvector()\n",
    "y = x\n",
    "y = T.set_subtensor(y[3], 1)\n",
    "out = y\n",
    "f = theano.function([x], out)\n",
    "f(np.array(range(5)).astype(theano.config.floatX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "a1MNNkCvo8iW",
    "outputId": "86b58a00-20e5-49b1-a6dc-545994854e51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2,  4,  4,  6,  6, 10, 10,  8,  8, 12]),\n",
       " array([1, 2, 3, 4, 5, 6]),\n",
       " array([  3.,   5.,   8.,   9.,  10.]))"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = np.array([0.0,0.0,0.0])\n",
    "ws = np.array([1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\n",
    "dEdIns = np.array([1,2,3,4,5,6])\n",
    "prevOut = np.array([2,2,2,2,2])\n",
    "bMult = 2\n",
    "bMultOnes = np.array([1.0,1.0])\n",
    "\n",
    "layerConsols = [[0], [1,2], [3,4], [7,8], [5,6], [9]]\n",
    "flattened = flatten(layerConsols)\n",
    "inverseConsols = [0] * len(flattened)\n",
    "for i in range(len(layerConsols)):\n",
    "    for sub in layerConsols[i]:\n",
    "        inverseConsols[sub] = i\n",
    "\n",
    "inverseConsols = np.array([0,1,1,2,2,4,4,3,3,5])\n",
    "\n",
    "    \n",
    "def gradLayer(nextdEdInputs, layerOutput): #returns (dEdWs, dEdBs, newdEdInputs)\n",
    "        expandedLayerOutput = np.repeat(layerOutput, bMult)\n",
    "        inverseddEdInputs = nextdEdInputs.take(inverseConsols)\n",
    "        dEdWs = expandedLayerOutput * inverseddEdInputs\n",
    "        dEdBs = nextdEdInputs\n",
    "        #upt to here correct\n",
    "        def foo(x):\n",
    "            if x >0.0:\n",
    "                return 1.0\n",
    "            else:\n",
    "                return 0.0\n",
    "        gtCast = np.vectorize(foo)\n",
    "#         dOutsdIns = np.gt(layerOutput, np.zeros_like(layerOutput))\n",
    "#         dOutsdIns = np.cast(dOutsdIns, 'float32')\n",
    "\n",
    "        dOutsdIns = gtCast(layerOutput)\n",
    "        dEdConnections = ws * inverseddEdInputs\n",
    "        dEdConnectionGroups = dEdConnections.reshape((dEdConnections.size // bMult, bMult))\n",
    "        dEdOuts = np.dot(dEdConnectionGroups, bMultOnes) #could need to be axis 1\n",
    "\n",
    "        newdEdInputs = dEdOuts * dOutsdIns\n",
    "\n",
    "        return (dEdWs, dEdBs, newdEdInputs)\n",
    "gradLayer(dEdIns, prevOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "M-PVWbN1o8ir"
   },
   "outputs": [],
   "source": [
    "x = np.array(range(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hcPuP7cAo8iz",
    "outputId": "f6336096-b5f9-4c2d-e44d-e662951cee47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [3, 4, 5]])"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape((2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Fr91u3DHo8i_"
   },
   "outputs": [],
   "source": [
    "import numerai\n",
    "trainingfeats, traininglabels, testingfeats, testinglabels = numerai.readTraining()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "5pIuvsvao8jE",
    "outputId": "334b69d7-dfb4-4693-a26d-2bc06017f70d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testingfeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "zSHm_uoUo8jP",
    "outputId": "23988138-fe8b-4a6c-e3b8-e7b4d0f19050"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "tXkvywWyo8jZ"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm evolve.pyc\n",
    "rm fulcrum.pyc\n",
    "rm fractalNetwork2.pyc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ImKcWwlHo8jn",
    "outputId": "d34e1c0b-9a3c-4f1a-87c9-d1761ad389af"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'run'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-a940d54d3ba1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfulcrum\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfulcrum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'module' object has no attribute 'run'"
     ]
    }
   ],
   "source": [
    "import fulcrum\n",
    "fulcrum.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Uzw4trTho8j0",
    "outputId": "bdd00cdb-ec65-4beb-fadf-484cecc5dc8c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 == 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "e5asE65Xo8kA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "Neuro120fractal.ipynb",
   "provenance": [
    {
     "file_id": "0B-aDu7AYJQFwS0Y4WFdUNGtmRlk",
     "timestamp": 1523566751533
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python [conda env:theano_p27]",
   "language": "python",
   "name": "conda-env-theano_p27-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
