{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "vvrt4WJ7o8e6"
   },
   "outputs": [],
   "source": [
    "#Set up generating mathematical functions in tree structures from the following\n",
    "#primitives, these will be used for calculating displacements of neurons\n",
    "from deap import gp\n",
    "import operator\n",
    "import math\n",
    "def square(x):\n",
    "    return x*x\n",
    "def absSqrt(x):\n",
    "    return math.sqrt(abs(x))\n",
    "pset = gp.PrimitiveSet(\"nodePrims\", arity=1)\n",
    "pset.addPrimitive(max, 2)\n",
    "pset.addPrimitive(operator.mul, 2)\n",
    "pset.addPrimitive(operator.add, 2)\n",
    "pset.addPrimitive(operator.sub, 2)\n",
    "pset.addPrimitive(math.sin, 1)\n",
    "pset.addPrimitive(math.cos, 1)\n",
    "pset.addPrimitive(absSqrt, 1)\n",
    "pset.addPrimitive(square, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "QCKS3iQIo8fK",
    "outputId": "a471f2b5-673b-4a53-838c-c6cb7dc4647d",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/theano_p27/lib/python2.7/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ec2-user/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ec2-user/anaconda3/envs/theano_p27/lib/python2.7/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ec2-user/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n",
      "/home/ec2-user/anaconda3/envs/theano_p27/lib/python2.7/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  RuntimeWarning)\n",
      "/home/ec2-user/anaconda3/envs/theano_p27/lib/python2.7/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\tmean  \tmin\tmax    \tstdDev \n",
      "0  \t30    \t20.273\t1  \t422.495\t74.9075\n",
      "1  \t22    \t1683.97\t4  \t65536  \t10225.1\n",
      "2  \t24    \t4983.96\t16 \t65536  \t17242.5\n",
      "3  \t24    \t21435.1\t16 \t65536  \t30601.5\n",
      "4  \t25    \t47609.9\t25 \t65536  \t29106.5\n",
      "5  \t24    \t65536  \t65536\t65536  \t0      \n",
      "6  \t25    \t65536  \t65536\t65536  \t0      \n",
      "7  \t25    \t65536  \t65536\t65536  \t0      \n",
      "8  \t22    \t65536  \t65536\t65536  \t0      \n",
      "9  \t22    \t65536  \t65536\t65536  \t0      \n",
      "10 \t22    \t65536  \t65536\t65536  \t0      \n",
      "11 \t29    \t65536  \t65536\t65536  \t0      \n",
      "12 \t23    \t65536  \t65536\t65536  \t0      \n",
      "13 \t27    \t65536  \t65536\t65536  \t0      \n",
      "14 \t26    \t65536  \t65536\t65536  \t0      \n",
      "15 \t25    \t65536  \t65536\t65536  \t0      \n",
      "16 \t25    \t65536  \t65536\t65536  \t0      \n",
      "17 \t25    \t65536  \t65536\t65536  \t0      \n",
      "18 \t24    \t65536  \t65536\t65536  \t0      \n",
      "19 \t23    \t65536  \t65536\t65536  \t0      \n",
      "20 \t26    \t65536  \t65536\t65536  \t0      \n",
      "21 \t23    \t65536  \t65536\t65536  \t0      \n",
      "22 \t26    \t65536  \t65536\t65536  \t0      \n",
      "23 \t22    \t65536  \t65536\t65536  \t0      \n",
      "24 \t23    \t65536  \t65536\t65536  \t0      \n",
      "25 \t24    \t65536  \t65536\t65536  \t0      \n",
      "26 \t23    \t65536  \t65536\t65536  \t0      \n",
      "27 \t27    \t65536  \t65536\t65536  \t0      \n",
      "28 \t24    \t65536  \t65536\t65536  \t0      \n",
      "29 \t22    \t65536  \t65536\t65536  \t0      \n",
      "30 \t24    \t65536  \t65536\t65536  \t0      \n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"639.2593044181615\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Code to implement the evolution of the models and hyperparameters for generating them\n",
    "%matplotlib notebook\n",
    "from deap import creator, base, tools, algorithms\n",
    "from random import randint\n",
    "import numpy as np\n",
    "import dill\n",
    "import pickle\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "DataDims = 2\n",
    "MINDIMFUNCS = 1\n",
    "MAXDIMFUNCS = 10\n",
    "MINDIMS = DataDims\n",
    "MAXDIMS = 10\n",
    "POPSIZE = 30\n",
    "GENERATIONS = 30\n",
    "MU = 40\n",
    "LAMBDA = 30\n",
    "CXPB = 0.5\n",
    "MUTPB = 0.3\n",
    "WEIGHTSCALE = 0.05\n",
    "BIASSCALE = 0.05\n",
    "CARTESIANPROB = 0.25\n",
    "CARTESIANDIMMAX = 2\n",
    "CARTESIANMUTATEPROB = 0.3\n",
    "\n",
    "def genTreeList():\n",
    "    return [gp.PrimitiveTree(gp.genHalfAndHalf(pset=pset, min_=1,max_=6)) for i in range(randint(MINDIMFUNCS,MAXDIMFUNCS))]\n",
    "def genFuncList():\n",
    "    return [genTreeList() for j in range(randint(MINDIMS,MAXDIMS))]\n",
    "\n",
    "#cartesian as in cartesian product -- this will allow it to generate real convolution by tiling\n",
    "#without this, it would only be able to branch out directly along axes.\n",
    "def genCartesianList():\n",
    "    funclist = genFuncList()\n",
    "        \n",
    "    if random.random() < CARTESIANPROB:\n",
    "        cartesianPair = random.sample(range(len(funclist)),CARTESIANDIMMAX)\n",
    "\n",
    "        for dim in cartesianPair:\n",
    "            funclist[dim].insert(0,\"cartesian\")\n",
    "    \n",
    "    return funclist\n",
    "        \n",
    "    \n",
    "        \n",
    "\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,) )\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "# def myMutate(individual):\n",
    "#     new = [[gp.mutNodeReplacement(x,pset=pset) for x in l] for l in toolbox.clone(individual)]\n",
    "#     return (tools.initIterate(creator.Individual, lambda: new),)\n",
    "\n",
    "\n",
    "def getFitMap(ls):\n",
    "    fitnesses = []\n",
    "    for l in ls:\n",
    "        fitnesses.append(l.fitness.values[0])\n",
    "    return fitnesses\n",
    "\n",
    "def evolve(evaluator):\n",
    "    \n",
    "    \n",
    "    \n",
    "    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,) )\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "    \n",
    "    toolbox = base.Toolbox()\n",
    "    toolbox.register(\"individual\", tools.initIterate, creator.Individual, genCartesianList)\n",
    "    \n",
    "    def myMutate(individual):\n",
    "        cartesianDims = [i for i in range(len(individual)) if individual[i][0] == \"cartesian\"]\n",
    "        new = [[gp.mutNodeReplacement(x,pset=pset) for x in l if x != \"cartesian\"] for l in toolbox.clone(individual)]\n",
    "        new = [[x[0] for x in l if x] for l in new]\n",
    "        \n",
    "        #mutate cartesian dims\n",
    "        if random.random() < CARTESIANMUTATEPROB:\n",
    "            #50-50 chance to add a random, non cartesian dimension as a cartesian dimension, or subtract a cartesian dimension\n",
    "            if random.random() < 0.5:\n",
    "                cartesianDims += random.sample([i for i in range(len(individual)) if i not in cartesianDims],1)\n",
    "            elif len(cartesianDims) >= 1:\n",
    "                cartesianDims = random.sample(cartesianDims, len(cartesianDims) - 1)\n",
    "        \n",
    "        #make sure not to go over maximum number of cartesian dims\n",
    "        if len(cartesianDims) > CARTESIANDIMMAX:\n",
    "            cartesianDims = random.sample(cartesianDims, CARTESIANDIMMAX)\n",
    "        \n",
    "        #include the cartesian flags in the individual\n",
    "        for dim in cartesianDims:\n",
    "            new[dim].insert(0,\"cartesian\")\n",
    "        \n",
    "        return (tools.initIterate(creator.Individual, lambda: new),)\n",
    "    \n",
    "    #takes two in individuals and the probability of each attribute switching\n",
    "    def myUniformCrossover(indv1, indv2, indpb):\n",
    "        shorterLength = min(len(indv1), len(indv2))\n",
    "        \n",
    "        dimTuples = []\n",
    "        for i in range(shorterLength):\n",
    "            if random.random() < indpb:\n",
    "                dimTuples.append(tools.cxUniform(indv1[i],indv2[i],indpb))\n",
    "            else:\n",
    "                dimTuples.append((indv1[i],indv2[i]))\n",
    "        \n",
    "        newIndv1 = [first for first,second in dimTuples]\n",
    "        newIndv2 = [second for first,second in dimTuples]\n",
    "        \n",
    "        #append last part of longer individual to its new, crossed over self\n",
    "        if len(indv1) != len(indv2):\n",
    "            if len(indv1) > shorterLength:\n",
    "                newIndv1 = newIndv1 + indv1[shorterLength:]\n",
    "            else:\n",
    "                newIndv2 = newIndv2 + indv2[shorterLength:]\n",
    "        \n",
    "        #because cxuniform goes element to element, the cartesian flag will stay at the beginning\n",
    "        newIndv1Carts = [i for i in range(len(newIndv1)) if newIndv1[i][0] == \"cartesian\"]\n",
    "        newIndv2Carts = [i for i in range(len(newIndv2)) if newIndv2[i][0] == \"cartesian\"]\n",
    "        \n",
    "        if len(newIndv1Carts) > CARTESIANDIMMAX:\n",
    "            newIndv1CartsTrimmed = set(random.sample(newIndv1Carts, CARTESIANDIMMAX))\n",
    "            #idiomatic set subtraction! \n",
    "            for dim in set(newIndv1Carts) - newIndv1CartsTrimmed:\n",
    "                newIndv1[dim].remove(\"cartesian\")\n",
    "        \n",
    "        if len(newIndv2Carts) > CARTESIANDIMMAX:\n",
    "            newIndv2CartsTrimmed = set(random.sample(newIndv2Carts, CARTESIANDIMMAX))\n",
    "            #idiomatic set subtraction! \n",
    "            for dim in set(newIndv2Carts) - newIndv2CartsTrimmed:\n",
    "                newIndv2[dim].remove(\"cartesian\")\n",
    "        \n",
    "        #use this strange function to effectively erase fitness values, put it in the right class etc.\n",
    "        return (tools.initIterate(creator.Individual, lambda: newIndv1),tools.initIterate(creator.Individual, lambda: newIndv2))\n",
    "                \n",
    "            \n",
    "        \n",
    "        \n",
    "                                    \n",
    "\n",
    "    toolbox.register(\"mate\", myUniformCrossover, indpb=0.5)\n",
    "    toolbox.register(\"mutate\", myMutate)\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize = 4)\n",
    "    toolbox.register(\"evaluate\", evaluator)\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "    pop = toolbox.population(POPSIZE)\n",
    "    \n",
    "    \n",
    "\n",
    "    myStats = tools.Statistics()\n",
    "    myStats.register(\"mean\", lambda ls: np.mean(getFitMap(ls)))\n",
    "    myStats.register(\"min\", lambda ls: min(getFitMap(ls)))\n",
    "    myStats.register(\"max\", lambda ls: max(getFitMap(ls)))\n",
    "    myStats.register(\"stdDev\", lambda ls: np.std(getFitMap(ls)))\n",
    "\n",
    "    hallOFame = tools.HallOfFame(5) # hall of fame of size 5\n",
    "\n",
    "\n",
    "    (finalPop, logbook) = algorithms.eaMuPlusLambda(pop, toolbox, MU, LAMBDA, CXPB, MUTPB, GENERATIONS, myStats, halloffame=hallOFame, verbose=True)\n",
    "    \n",
    "    \n",
    "    gen = logbook.select(\"gen\")\n",
    "    fit_maxs = logbook.select(\"max\")\n",
    "    fit_avgs = logbook.select(\"mean\")\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "    line1 = ax1.plot(gen, fit_maxs, \"b-\", label=\"Maximum Fitness\")\n",
    "    ax1.set_xlabel(\"Generation\")\n",
    "    ax1.set_ylabel(\"Fitness\", color=\"b\")\n",
    "    for tl in ax1.get_yticklabels():\n",
    "        tl.set_color(\"b\")\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    line2 = ax2.plot(gen, fit_avgs, \"r-\", label=\"Average Fitness\")\n",
    "    ax2.set_ylabel(\"Size\", color=\"r\")\n",
    "    for tl in ax2.get_yticklabels():\n",
    "        tl.set_color(\"r\")\n",
    "\n",
    "    lns = line1 + line2\n",
    "    labs = [l.get_label() for l in lns]\n",
    "    ax1.legend(lns, labs, loc=\"center right\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def flatten(mylist):\n",
    "    return list(itertools.chain.from_iterable(mylist))\n",
    "    \n",
    "def myEval(individual):\n",
    "    funcs = []\n",
    "    for dimlist in individual:\n",
    "        newDimlist = []\n",
    "        for tree in dimlist:\n",
    "            if tree != \"cartesian\":\n",
    "#             print gp.stringify(tree)\n",
    "                f = gp.compile(tree, pset)\n",
    "                newDimlist.append(f)\n",
    "        funcs.append(newDimlist)\n",
    "    flattened = flatten(funcs)\n",
    "    mapped = map(lambda f: f(1), flattened)\n",
    "    return max(mapped),\n",
    "    \n",
    "    \n",
    "evolve(myEval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "MSJBPuYeo8fm",
    "outputId": "19052e0c-7a92-439e-eb8b-ccc170a9eeaa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuDNN version 7005 on context None\n",
      "Mapped name None to device cuda: GRID K520 (0000:00:03.0)\n"
     ]
    }
   ],
   "source": [
    "#Load MNIST data to train/test models on\n",
    "import theano\n",
    "import mnist\n",
    "import numpy as np\n",
    "\n",
    "train_images = mnist.train_images()\n",
    "train_labels = mnist.train_labels()\n",
    "\n",
    "test_images = mnist.test_images()\n",
    "test_labels = mnist.test_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "MSJBPuYeo8fm",
    "outputId": "19052e0c-7a92-439e-eb8b-ccc170a9eeaa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0bbfead110>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parse mnist data into form that we will use\n",
    "def labelToArray(x):\n",
    "    blank = [0] * 10\n",
    "    blank[x] = 1\n",
    "    return np.array(blank)\n",
    "\n",
    "trainingimgs = [train_images[i].astype(theano.config.floatX).ravel() * (1.0/256) for i in range(train_images.shape[0])]\n",
    "traininglabels = [labelToArray(train_labels[i]).astype(theano.config.floatX) for i in range(train_labels.shape[0])]\n",
    "testingimgs = [test_images[i].astype(theano.config.floatX).ravel() * (1.0/256) for i in range(test_images.shape[0])]\n",
    "testinglabels = [labelToArray(test_labels[i]).astype(theano.config.floatX) * (1.0 / 256) for i in range(test_labels.shape[0])]\n",
    "plt.imshow(trainingimgs[0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "oTGC3727o8f0",
    "outputId": "b31754f4-b054-4e8c-d625-9dc6e12cf7dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running initial dictSingleGenConsolidate\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "starting to loop\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "first version took: 0.000557899475098\n",
      "looped\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "first version took: 0.000209093093872\n",
      "looped\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "first version took: 0.000220060348511\n",
      "looped\n",
      "[81.79955085]\n",
      "biased and relued: [0.04132605 3.04462336 9.21956473]\n",
      "biased and relued: [ 0.09219244  2.85825314 25.32000125]\n",
      "biased and relued: [ 0.12605852  1.42839068 46.46877853]\n",
      "biased and relued: [ 0.19220933  0.88626372 89.28850035]\n",
      "[81.79955085]\n"
     ]
    }
   ],
   "source": [
    "#Miscellaneous functions that get used for calculating growth of networks\n",
    "\n",
    "import theano.tensor as T\n",
    "from theano import shared\n",
    "import theano\n",
    "from autograd import grad as Grad\n",
    "import autograd.numpy as np\n",
    "import autograd.numpy.linalg as LA\n",
    "import itertools\n",
    "import typing\n",
    "import time\n",
    "import math\n",
    "from itertools import izip\n",
    "from itertools import product as cartesianProd\n",
    "import itertools\n",
    "#We're modeling neurons as points in a high dimensional space, but to keep them\n",
    "#from just going all over the place and not interacting to create interesting \n",
    "#structures, we're going to limit the size of that space to a box of this width\n",
    "SPACESPAN = 2.0\n",
    "\n",
    "#Take one dimension of a neuron's position -- if it's outside the box,\n",
    "#wrap it around so it goes in the box. Otherwise, do nothing.\n",
    "def box(x):\n",
    "    if x > 0 + SPACESPAN / 2.0:\n",
    "        return -1.0 + x\n",
    "    elif x < 0 - SPACESPAN / 2.0:\n",
    "        return 1.0 + x\n",
    "    else:\n",
    "        return x\n",
    "      \n",
    "      \n",
    "#Want neurons that are close together to overlap, so we have a \"resolution\" of \n",
    "#the space such that if neurons are closer than the \"resolution\", they overlap. \n",
    "#resDenominator can be thought of as how many pixels are in a row of the box the\n",
    "#neurons live in.\n",
    "def discretize(x, resDenominator):\n",
    "    if x > 0.0:\n",
    "        return np.floor(1.0 * x * resDenominator) / resDenominator\n",
    "    elif x < 0.0:\n",
    "        return np.floor(1.0 * x * resDenominator) / resDenominator\n",
    "    else:\n",
    "        return 0.0\n",
    "    \n",
    "def mnistlabelToArray(x):\n",
    "    blank = [0] * 10\n",
    "    blank[x] = 1\n",
    "    return np.array(blank)\n",
    "\n",
    "\n",
    "def flatten(mylist):\n",
    "    return list(itertools.chain.from_iterable(mylist))\n",
    "\n",
    "#Consolidation is strange but crucial. Basically you have a big array of where the\n",
    "#neurons are in space, then you apply the displacement/\"growth\" rules to each\n",
    "#dimension of those positions. Now you have a huge list of neuron positions, and\n",
    "#consolidating is calculating what neurons overlap, and creating a list of indices\n",
    "#that tells which neurons are going as input to a neuron in the next layer. You\n",
    "#could do this with a bitmask, but the networks are usually sparse enough that \n",
    "#it would be extremely inefficient, but maybe with a low resDenominator the space\n",
    "#will overlap enough that it will be efficient. Improving this would be nice, but\n",
    "#I don't know if its necessary, given this is slow but not terribly slow.\n",
    "\n",
    "#to be honest I have to look over this a lot too to figure out whats going on.\n",
    "\n",
    "\n",
    "def dictSingleGenConsolidate(arrays):\n",
    "    #takes as input [[position, position,...],[position, position,...], ...]\n",
    "    #want to find, in the flattened list above, which the indices of all neurons that overlap with the first position,\n",
    "    #then the indices of all the neurons that overlap with the second position, and so on until done\n",
    "    \n",
    "    arraylen = len(arrays)\n",
    "    irange = range(arraylen)\n",
    "    \n",
    "    positionDict = {}\n",
    "    neuronPositionTuples = map(lambda l: tuple(l), arrays)\n",
    "    positionTuplesOrdered = []\n",
    "\n",
    "    print \"starting a dictSingleGenConsolidate\" \n",
    "\n",
    "    for posTuple,i in zip(neuronPositionTuples, irange):\n",
    "        if posTuple not in positionDict:\n",
    "            positionDict[posTuple] = [i]\n",
    "            positionTuplesOrdered.append(posTuple)\n",
    "        else:\n",
    "            positionDict[posTuple].append(i)\n",
    "\n",
    "    indices = [positionDict[posTuple] for posTuple in positionTuplesOrdered]\n",
    "    \n",
    "    print \"finished a dictSingleGenConsolidate\"\n",
    "        \n",
    "    #returns a list [[index, index, index,...], [index, index, index,...]] where the ith sublist corresponds to the ith neuron\n",
    "    #in the next layer up, and each sublist contains the indices of the neurons that connect to them.\n",
    "    return indices\n",
    "\n",
    "  \n",
    "def newSingleGenConsolidate(arrays):\n",
    "    bigMatrix = np.array(arrays)\n",
    "    arraylen = len(arrays)\n",
    "    initArraylen = len(arrays)\n",
    "    indices = []\n",
    "    flattenedIndices = []\n",
    "    \n",
    "    irange = range(arraylen)\n",
    "    \n",
    "    counter = True\n",
    "    print \"starting a newSingleGenConsolidate\"\n",
    "    flattenedIndices = np.ones()\n",
    "    for i in irange:\n",
    "        if i not in flattenedIndices:\n",
    "            subgroupArr = np.argwhere(np.all((bigMatrix-bigMatrix[i])==0, axis=0))\n",
    "            subgroup = subgroupArr.tolist()\n",
    "            indices.append(subgroup)\n",
    "            flattenedIndices += subgroup\n",
    "            arraylen -= subgroupArr.size\n",
    "            if counter and arraylen/initArraylen < 0.5:\n",
    "                print \"half way done a newSingleGenConsolidate\"\n",
    "                counter = False\n",
    "    \n",
    "    print \"finished a newSingleGenConsolidate\"\n",
    "    return indices\n",
    "            \n",
    "            \n",
    "            \n",
    "def singleGenConsolidate(arrays):\n",
    "    #takes as input [[position, position,...],[position, position,...], ...]\n",
    "    #want to find, in the flattened list above, which the indices of all neurons that overlap with the first position,\n",
    "    #then the indices of all the neurons that overlap with the second position, and so on until done\n",
    "    \n",
    "    indices = []\n",
    "    flattenedIndices = []\n",
    "    arraylen = len(arrays)\n",
    "    initArraylen = len(arrays) * 1.0\n",
    "    irange = range(arraylen)\n",
    "    \n",
    "    counter = True\n",
    "    print \"starting a singleGenConsolidate\"\n",
    "    for i in irange:\n",
    "        if i not in flattenedIndices:\n",
    "            subgroup = [i] + [j for j in irange[i + 1:] if np.array_equal(arrays[i], arrays[j])]\n",
    "            arraylen -= len(subgroup)\n",
    "            indices.append(subgroup)\n",
    "            flattenedIndices += subgroup\n",
    "            if counter and arraylen/initArraylen < 0.5:\n",
    "                print \"half way done a singleGenConsolidate\"\n",
    "                counter = False\n",
    "    \n",
    "    print \"finished a singleGenConsolidate\"\n",
    "    \n",
    "    #returns a list [[index, index, index,...], [index, index, index,...]] where the ith sublist corresponds to the ith neuron\n",
    "    #in the next layer up, and each sublist contains the indices of the neurons that connect to them.\n",
    "    return indices\n",
    "\n",
    "\n",
    "\n",
    "def nprelu(x):\n",
    "    np.maximum(0,x)\n",
    "\n",
    "\n",
    "def getSubV2np(index, inds, complete):\n",
    "    return complete[inds[index]:inds[index + 1]]\n",
    "\n",
    "def getSubV3np(index, indinds, inds, complete):\n",
    "    subInds = inds[indinds[index] : indinds[index + 1] + 1]\n",
    "    return subInds, complete\n",
    "  \n",
    "#this is a consolidation list actually being used\n",
    "def singleConsol(tensor, indices):\n",
    "    return (np.choose(indices, tensor)).sum()\n",
    "\n",
    "def positionConsolidate(arrays, consolidations):\n",
    "    return [arrays[sublist[0]] for sublist in consolidations]\n",
    "\n",
    "def numpyConsolidate(array, consols):\n",
    "    new = []\n",
    "    for sublist in consols:\n",
    "        x = 0.0\n",
    "        for i in sublist:\n",
    "            x += array[i]\n",
    "        new.append(x)\n",
    "\n",
    "    return new\n",
    "\n",
    "def npConsolidate(array, consolinds, consols):\n",
    "    ordered = array.take(consols)\n",
    "    f = lambda i : ordered[consolinds[i]: consolinds[i + 1]].sum()\n",
    "    veced = np.vectorize(f)\n",
    "    return veced(np.arange(consolinds.size))\n",
    "\n",
    "\n",
    "def generalfeedforward((weights, biases, finalweights, finalbiases), consolMasks, hiddenlayers, branchMultiplier, inp):\n",
    "    #implements a fractalnet in numpy, using consolidation masks instead of lists.\n",
    "    for i in range(hiddenlayers):\n",
    "        inp = np.repeat(inp, branchMultiplier)\n",
    "        inp = np.multiply(weights[i], inp)\n",
    "        inp = np.concatenate((inp, np.array([0.0]).astype('float32')))\n",
    "        inp = inp.take(consolMasks[i]).sum(axis = 1)\n",
    "        inp = nprelu(np.add(inp, biases[i]))\n",
    "    \n",
    "    print inp\n",
    "    finalout = nprelu(np.dot(inp, finalweights) + finalbiases)\n",
    "    return finalout\n",
    "\n",
    "\n",
    "class nnet:\n",
    "    weights = []\n",
    "    biases = []\n",
    "    consolidations = []\n",
    "    finalweights = []\n",
    "    finalbiases = []\n",
    "    weightnum = 0\n",
    "    hiddenlayers = 0\n",
    "    \n",
    "    def __init__(self, resolution, functions, inputdimension, datainp, dataoutp, synapseThreshold):\n",
    "        self.resDenominator = resolution\n",
    "        self.funcs = functions\n",
    "        self.dimensions = len(self.funcs)\n",
    "        \n",
    "        #branch multiplier says how many neurons grow out of each neuron every\n",
    "        #time a new layer is grown. This is the same fo\n",
    "        self.cartesianDims = [i for i in range(len(self.funcs)) if self.funcs[i][0] == \"cartesian\"]\n",
    "        \n",
    "        self.branchMultiplier = np.sum([len(self.funcs[i]) for i in range(len(self.funcs)) if i not in self.cartesianDims])\n",
    "\n",
    "        #you'd think this \"if\" case is unecessry and np.prod([]) == 0, but you would be mistaken. Gotta love weird defaults\n",
    "        if len(self.cartesianDims) > 0:\n",
    "            self.branchMultiplier += np.prod([len(self.funcs[i]) - 1 for i in self.cartesianDims])\n",
    "        self.branchMultiplier = int(self.branchMultiplier)\n",
    "\n",
    "        \n",
    "        self.TBranchMult = shared(np.array([self.branchMultiplier]))\n",
    "#         self.dataset = [shared(dat.astype(theano.config.floatX)) for dat in datainp]\n",
    "#         self.datalabels = [shared(outp.astype(theano.config.floatX)) for outp in dataoutp]\n",
    "        self.dataSample = datainp[0] #numpy\n",
    "        self.dataOutSample = dataoutp[0]\n",
    "        self.inputdimension = inputdimension\n",
    "        \n",
    "        if self.dataSample.size ** (1.0/ inputdimension) > self.resDenominator * 2.0:\n",
    "            print \"resDenominator may be too small for effective learning\"\n",
    "            \n",
    "        self.threshold = synapseThreshold\n",
    "\n",
    "    def applyFuncs(self, narray): #checked\n",
    "        #grows a single neuron's new positions, given vector position (represented as a list)\n",
    "        boxvec = np.vectorize(lambda x: discretize(box(x), self.resDenominator))\n",
    "        displaced = []\n",
    "        \n",
    "        toCartesianProduct = []\n",
    "        \n",
    "        for dim in range(self.dimensions):\n",
    "            if self.funcs[dim][0] != \"cartesian\":\n",
    "                for f in self.funcs[dim]:\n",
    "\n",
    "                    zeroes = np.zeros_like(narray)\n",
    "                    displacement = f(narray[dim]) % SPACESPAN\n",
    "                    zeroes[dim] = displacement\n",
    "\n",
    "                    newArray = np.add(narray, zeroes)\n",
    "                    newArrayBoxed = boxvec(newArray)\n",
    "                    displaced.append(newArrayBoxed)\n",
    "            else:\n",
    "                newDisplacements = []\n",
    "                for f in self.funcs[dim][1:]:\n",
    "                    zeroes = np.zeros_like(narray)\n",
    "                    displacement = f(narray[dim]) % SPACESPAN\n",
    "                    zeroes[dim] = displacement\n",
    "                    newDisplacements.append(zeroes)\n",
    "                \n",
    "                toCartesianProduct.append(newDisplacements)\n",
    "        \n",
    "        if len(toCartesianProduct) > 0:\n",
    "            cartesianProdDisplacaments = [np.sum(tupleProduct, axis=0 ) \n",
    "                                             for tupleProduct in cartesianProd(*tuple(toCartesianProduct))]\n",
    "            displacedPositions = [boxvec(np.add(narray,displacement)) for displacement in cartesianProdDisplacaments]\n",
    "            displaced = displacedPositions + displaced\n",
    "            \n",
    "                \n",
    "        \n",
    "        return displaced\n",
    "        \n",
    "\n",
    "    def applyFuncsMult(self, narrays): \n",
    "        #given list of neuron positions (lists), grow them and return a list of list of positions, where the first list is the \n",
    "        #first neuron's \"outgrowths\", the second list is the second neuron's \"outgrowths\" and so on.\n",
    "        \n",
    "        return flatten([self.applyFuncs(x) for x in narrays])\n",
    "    \n",
    "    def locate(self, sample):  #only 1 or 2 implemented\n",
    "        #given input data as an array, represent that data spacially as a neurons that can then be grown\n",
    "        \n",
    "        insize = sample.size\n",
    "        sample = np.ravel(sample) \n",
    "        tensorFrame = [0] * self.dimensions\n",
    "        located = [0] * insize\n",
    "        \n",
    "        boxvec = np.vectorize(lambda x: discretize(box(x), self.resDenominator))\n",
    "        \n",
    "        #self.inputdimension is the dimension the input should be represented in\n",
    "        \n",
    "        if self.inputdimension == 1:\n",
    "            #arrange neurons in a line along the first dimension\n",
    "            for i in range(insize):\n",
    "                myTens = tensorFrame[:]\n",
    "                myTens[0] = (2.0 * i) / insize - 1.0\n",
    "                located[i] = boxvec(np.array(myTens))\n",
    "        \n",
    "        if self.inputdimension == 2:\n",
    "            #arrange neurons in a grid in the first two dimensions that has integer dimensions, calculated to be as \n",
    "            #close to square as possible for convenience\n",
    "            located = []\n",
    "            factorPairs = [(i,(insize / i)) for i in range(1, int(math.floor(insize**0.5))) if insize % i == 0]\n",
    "            pair = factorPairs[-1]\n",
    "            for i in range(pair[0]):\n",
    "                for j in range(pair[1]):\n",
    "                    myTens = tensorFrame[:]\n",
    "                    myTens[0] = 2.0 * i/pair[0] - 1.0\n",
    "                    myTens[1] = 2.0 * j/pair[1] - 1.0\n",
    "                    located.append(boxvec(np.array(myTens)))\n",
    "                            \n",
    "        return located\n",
    "        \n",
    "    def genConsolidate(self): #finds consolidation list from located self.dataSample\n",
    "        consols = []\n",
    "#         print len(self.dataSample.ravel())\n",
    "\n",
    "        located = self.locate(self.dataSample)\n",
    "        #type is [position, position, ...], don't care about dataSample's actual values right now, just its dimensions\n",
    "        \n",
    "#         print len(located)\n",
    "#         print type(located[0])\n",
    "        print \"running initial dictSingleGenConsolidate\"\n",
    "    \n",
    "        #Grow the neurons, generate consolidations list, consolidate, then start a loop\n",
    "        located = self.applyFuncsMult(located)\n",
    "        consols.append(dictSingleGenConsolidate(located))\n",
    "        located = positionConsolidate(located, consols[-1]) \n",
    "\n",
    "        \n",
    "        print \"starting to loop\"\n",
    "        #stop the growth when it hits a certain number of weights\n",
    "        while len(flatten(flatten(consols))) + len(flatten(consols[-1])) * self.branchMultiplier < self.threshold:\n",
    "            located = self.applyFuncsMult(located)\n",
    "            testStart = time.time()\n",
    "            consols.append(dictSingleGenConsolidate(located))\n",
    "            print \"first version took: \" + str(time.time() - testStart)\n",
    "#             testStart = time.time()\n",
    "#             x = newSingleGenConsolidate(located)\n",
    "#             print \"new version took: \" + str(time.time() - testStart)\n",
    "            \n",
    "            located = positionConsolidate(located, consols[-1]) \n",
    "            print \"looped\"\n",
    "            \n",
    "        self.consolidations = consols\n",
    "        \n",
    "        #In contrast to using the consolidation list, which is a list of lists of variable length, you can also pad them to create\n",
    "        #a list of fixed lengths lists (maximum of the previous variable lengths) that makes things neater but sacrifices some\n",
    "        #memory (and possibly some speed, but depending on implementation it might be faster). Pad with out of bounds indices\n",
    "        #that theano and numpy will default to zero.\n",
    "        self.consolMasks = []\n",
    "        for layerConsols in self.consolidations:\n",
    "#             print \"initial \" + str(layerConsols)\n",
    "            maxInLength = max(map(len, layerConsols))\n",
    "            inLength = len(flatten(layerConsols))\n",
    "            extended = map(lambda l: l + [inLength] * (maxInLength - len(l)), layerConsols)\n",
    "#             print \"extended: \" + str(extended)\n",
    "            self.consolMasks.append(np.array(extended).astype('int32'))\n",
    "        return consols\n",
    "    \n",
    "    def genWeights(self):\n",
    "        myWeightNum = 0\n",
    "        self.hiddenlayers = 0\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        self.finalweights = []\n",
    "        self.finalbiases = []\n",
    "        #automatically implement weight sharing for cartesian product neurons\n",
    "        cartesianLength = np.prod([len(self.funcs[i]) -1 for i in self.cartesianDims])\n",
    "        for consol in self.consolidations:\n",
    "            weightVec = (np.random.rand(len(flatten(consol))) * WEIGHTSCALE).astype(theano.config.floatX)\n",
    "            biasVec   = (np.random.rand(len(consol)) * BIASSCALE).astype(theano.config.floatX)\n",
    "            myWeightNum += len(weightVec)\n",
    "\n",
    "            #convert to shared data type for later speed\n",
    "            self.hiddenlayers += 1\n",
    "            \n",
    "            #implement weight sharing for cartesian products. I made sure to place the cartesian product elements at the \n",
    "            #beginning of each list of grown neuron positions, which doesn't change connectivity patterns, but does change\n",
    "            #the organization of the weights list. Note that I'm not assuming a cartesian product length here, given\n",
    "            #I will limit it in the randomWeightsMnistEvaluate function before I instantiate this class.\n",
    "            if len(self.cartesianDims) != 0:\n",
    "                nonCartesianFuncsLength = np.sum([len(self.funcs[i]) for i in range(len(self.funcs)) if i not in self.cartesianDims])\n",
    "                cartesianTileSize = np.prod([len(self.funcs[i]) - 1 for i in self.cartesianDims])\n",
    "                \n",
    "#                 print \"weightVec is: \" + str(weightVec)\n",
    "#                 print weightVec.shape\n",
    "                numBranchingNeurons = weightVec.size / self.branchMultiplier\n",
    "                #using xrange to avoid making unecessarily huge list in memory\n",
    "                \n",
    "                sharedWeight = np.random.rand(cartesianTileSize)\n",
    "                #could I do literally the exact same thing by reshaping the weightvec array into two dimensions\n",
    "                #then doing this without a loop? Yes. But numpy reshaping that changes dimensions can make an entirely\n",
    "                #new array in memory, and I would need to do that twice. This might actually be faster.\n",
    "                for i in xrange(numBranchingNeurons):\n",
    "                    weightVec[i*self.branchMultiplier:i*self.branchMultiplier + cartesianTileSize] = sharedWeight\n",
    "                \n",
    "#                 print \"weight shared weightVec is: \" + str(weightVec)\n",
    "\n",
    "            #convert them to lists so that we can then convert them in V2IndexedShareds later on for use in tnnet,\n",
    "            #for which nnet is essentially just a precursor. Inefficiency here doesn't really effect anything.\n",
    "            self.weights.append(weightVec.tolist())\n",
    "            self.biases.append(biasVec.tolist())\n",
    "                \n",
    "                \n",
    "        \n",
    "        outsize = len(self.dataOutSample)\n",
    "        \n",
    "        self.finalweights = np.random.rand(len(self.consolidations[-1]),outsize).astype('float32')        #final interconnected layer for output\n",
    "        self.finalbiases = np.random.rand(outsize).astype('float32')\n",
    "\n",
    "        myWeightNum += len(self.consolidations[-1]) * outsize\n",
    "#         self.weightNum = myWeightNum\n",
    "        \n",
    "    def feedforward(self, inp):\n",
    "        \n",
    "        for i in range(self.hiddenlayers):\n",
    "            inp = np.repeat(inp, self.branchMultiplier)\n",
    "#             print \"repeated: \" + str(inp)\n",
    "            inp = np.multiply(self.weights[i], inp)\n",
    "#             print \"weighted: \" + str(inp)\n",
    "            inp = numpyConsolidate(inp, self.consolidations[i])\n",
    "#             print \"consolidated: \" + str(inp)\n",
    "            inp = np.maximum(0, np.add(inp, self.biases[i]))\n",
    "            print \"biased and relued: \" + str(inp)\n",
    "        \n",
    "#         print \"before finals: \" + str(inp)\n",
    "#         print \"finalweights: \" + str(self.finalweights)\n",
    "#         print \"finalbiases: \" + str(self.finalbiases)\n",
    "        finalout = (np.dot(inp, self.finalweights) + self.finalbiases)\n",
    "#         print \"final: \" + str(finalout)\n",
    "        return finalout\n",
    "\n",
    "    def nfeedforward(self, inp):\n",
    "        for i in range(self.hiddenlayers):\n",
    "            inp = np.repeat(inp, self.branchMultiplier)\n",
    "            inp = np.multiply(self.weights[i], inp)\n",
    "            inp = np.concatenate((inp, np.array([0.0]).astype('float32')))\n",
    "            inp = inp.take(self.consolMasks[i]).sum(axis = 1)\n",
    "            inp = np.maximum(0,np.add(inp, self.biases[i]))\n",
    "        return np.dot(inp, self.finalweights) + self.finalbiases\n",
    "    \n",
    "    def test(inputs, outputs):\n",
    "        \n",
    "        def foo(x):\n",
    "            if x > 0.5:\n",
    "                return 1.0\n",
    "            return 0.0\n",
    "\n",
    "        binarize = np.vectorize(foo)\n",
    "        \n",
    "        errors = [LA.norm(outp - binarize(self.feedforward(inp))) for inp,outp in izip(inputs,outputs)]\n",
    "        return sum(errors)/len(inputs) * 100.0\n",
    "        \n",
    "    \n",
    "    def numpytrain(self, alpha, epochs, batchsize, inputlist, outputlist, verbose, testdatainputs, testdatalabels):\n",
    "        print \"starting training\"\n",
    "        \n",
    "        def error((weights, biases, finalweights, finalbiases), inp, outp):\n",
    "            return LA.norm(outp - generalfeedforward((weights,biases,finalweights,finalbiases), \n",
    "                                                     self.consolMasks, self.hiddenlayers, self.branchMultiplier, inp))\n",
    "        #use autograd to automatically differentiate error function\n",
    "        error_grad = Grad(error)\n",
    "        \n",
    "        inlen = len(inputlist)\n",
    "        outlen = len(outputlist)\n",
    "\n",
    "        if inlen != outlen:\n",
    "            Exception(\"number of input vectors (\"+str(inlen)+\") not equal not number of ouptut vectors (\"+str(outlen)+\")\")\n",
    "            \n",
    "        if alpha == 0.0:\n",
    "            raise(\"why is alpha zero?\")\n",
    "            \n",
    "        if type(batchsize) != int:\n",
    "            raise(\"Why is batchsize not an int?\")\n",
    "        \n",
    "        if batchsize == 0 or batchsize > inlen:\n",
    "            raise(\"batchsize of \"+str(batchsize)+\"is not allowed. Note than inputveclist has length \"+str(inlen))\n",
    "            \n",
    "        #just some error checks\n",
    "        \n",
    "        randindexlist = range(inlen)\n",
    "        start = time.time()\n",
    "        avgpercenttesterror = \"No test set\"\n",
    "        avgpercenttesterrorlist = []\n",
    "        \n",
    "        #using stochastic gradient descent training method\n",
    "        for epoch in xrange(epochs):\n",
    "            #random.shuffle(randindexlist)\n",
    "            #for batch in range(inlen/batchsize):\n",
    "            \n",
    "#                 low = batch * batchsize\n",
    "#                 upper = (batch + 1) * batchsize\n",
    "#                 if upper > inlen: upper = inlen \n",
    "                \n",
    "#                 total_Egradweights = None\n",
    "#                 total_Egradbiases = None\n",
    "                \n",
    "#                 for i in randindexlist[low:upper]:\n",
    "            for inp,outp in izip(inputlist,outputlist):\n",
    "                Egradws, Egradbs, Egadfws, Egradfbs = error_grad((self.weights, self.biases, \n",
    "                                                       self.finalweights, self.finalbiases), inp, outp) #formerly used indexes from randindexlist\n",
    "#                     if total_Egradweights:\n",
    "#                         total_Egradweights = [x + y for x,y in izip(Egradweights,total_Egradweights)]\n",
    "#                         total_Egradbiases = [x + y for x,y in izip(Egradbiases,total_Egradbiases)]\n",
    "#                     else:\n",
    "#                         total_Egradweights = Egradweights\n",
    "#                         total_Egradbiases = Egradbiases\n",
    "                \n",
    "#                 total_Egradweights = [x / (batchsize * 1.0) for x in total_Egradweights]\n",
    "#                 total_Egradbiases = [x / (batchsize * 1.0) for x in total_Egradbiases]\n",
    "                \n",
    "#                 self.weights = [curr-grad*alpha for curr, grad in izip(self.weights, total_Egradweights)]\n",
    "#                 self.biases = [curr-grad*alpha for curr, grad in izip(self.biases, total_Egradbiases)]\n",
    "                self.weights = [curr-grad*alpha for curr, grad in izip(self.weights, Egradws)]\n",
    "                self.biases = [curr-grad*alpha for curr, grad in izip(self.biases, Egradbs)]\n",
    "                self.finalweights = self.finalweights - alpha * Egradfws\n",
    "                self.finalbiases = self.finalbiases - alpha * Egradfbs\n",
    "            \n",
    "            if len(testinputlist) == len(testoutputlist) and len(testinputlist) != 0:\n",
    "                avgpercenttesterror = self.test(testinputlist, testoutputlist)\n",
    "                avgpercenttesterrorlist.append(avgpercenttesterror)\n",
    "            else:\n",
    "                print \"bad test set\"\n",
    "            \n",
    "            elapsed = time.time() - start\n",
    "            start = time.time()\n",
    "            if verbose:\n",
    "                print \"epoch: \" + str(epoch) + \"\\t percenterror: \" + str(avgpercenttesterror) + \"% \\t time elapsed this epoch: \" + str(elapsed) + \"s\"\n",
    "            \n",
    "        return (avgpercenttesterror, avgpercenttesterrorlist)\n",
    "\n",
    "# singleGenConsolidate([np.array([0,0,0]), np.array([0,1,2,3]), np.array([0,0,0])])\n",
    "testnet = nnet(10, [[\"cartesian\", lambda x: x + 1, lambda x: x+2], [\"cartesian\", lambda x: x * 2, lambda x: x * 3]], 1, [np.array([0,1,2,3])], [np.array([1])], 100)\n",
    "testnet.genConsolidate()\n",
    "testnet.genWeights()\n",
    "numpyConsolidate(np.array([1,2,3]), [[0,2], [1]])\n",
    "print testnet.nfeedforward(np.array([0,1,2,3]))\n",
    "print testnet.feedforward(np.array([0,1,2,3]))\n",
    "# print mynet.consolidations\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "from theano import shared,config,function\n",
    "import itertools\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "# theano.config.exception_verbosity = \"high\"\n",
    "\n",
    "def flatten(mylist):\n",
    "    return list(itertools.chain.from_iterable(mylist))\n",
    "  \n",
    "\n",
    "\n",
    "class V2IndexedShared:\n",
    "    def __init__(self, atype):\n",
    "        self.myType = atype\n",
    "    \n",
    "    def fromList(self,D2List):\n",
    "        self.complete = shared(np.array(flatten(D2List)).astype(self.myType))\n",
    "        self.length = shared(len(D2List))\n",
    "        inds = [0]\n",
    "        for sublist in D2List:\n",
    "            inds.append(len(sublist) + inds[-1])\n",
    "        self.inds = shared(np.array(inds).astype('int32'))\n",
    "        return self\n",
    "\n",
    "    \n",
    "class V3IndexedShared:\n",
    "    def __init__(self,D3List, atype):\n",
    "        self.complete = shared(np.array(flatten(flatten(D3List))).astype(atype))\n",
    "#         self.complete = np.array(flatten(flatten(D3List))).astype(atype)\n",
    "\n",
    "        self.myType = atype\n",
    "        self.length = shared(len(D3List))\n",
    "        D2Inds = [0]\n",
    "        D3Inds = [0]\n",
    "        \n",
    "        for sublistOLists in D3List:\n",
    "            \n",
    "            for sublist in sublistOLists:\n",
    "                D2Inds.append(len(sublist) + D2Inds[-1])\n",
    "                \n",
    "            D3Inds.append(len(sublistOLists) + D3Inds[-1])\n",
    "            \n",
    "                \n",
    "        self.D2Inds = shared(np.array(D2Inds).astype('int32'))\n",
    "        self.D3Inds = shared(np.array(D3Inds).astype('int32'))\n",
    "        \n",
    "#         self.D2Inds = np.array(D2Inds).astype('int32')\n",
    "#         self.D3Inds = np.array(D3Inds).astype('int32')\n",
    "#         print D3Inds\n",
    "#         print D2Inds\n",
    "#         print np.array(flatten(flatten(D3List)))\n",
    "    \n",
    "\n",
    "def relu(x):\n",
    "    return T.maximum(x, 0)\n",
    "\n",
    "#instead of having nested lists of variable sizes, the following two classes implement either a list of lists and a lists of \n",
    "#lists of lists. It implements it by having a \"complete\" array, then a array of indexes for the beginning and end of the slices\n",
    "#of that array, then an array for the beginning and end of slices (of the slices array)\n",
    "\n",
    "\n",
    "def getSubV2(index, inds, complete):\n",
    "    return complete[inds[index]:inds[index + 1]]\n",
    "\n",
    "def getSubV2Check():\n",
    "    tind = T.iscalar('ind')\n",
    "    tinds = T.ivector('inds')\n",
    "    tcomp = T.vector('complete')\n",
    "    \n",
    "    nind = np.asscalar(np.array([0]).astype('int32'))\n",
    "    ninds = np.array([0,2,4]).astype('int32')\n",
    "    comp = np.array([0,1,2,3,4]).astype(theano.config.floatX)\n",
    "    \n",
    "    f = theano.function([tind, tinds, tcomp], getSubV2(tind, tinds, tcomp))\n",
    "    print f(nind,ninds,comp)\n",
    "getSubV2Check()\n",
    "def getV2Length(inds):\n",
    "    return inds.size -1\n",
    "\n",
    "def getSubV3(index, indinds, inds, complete):\n",
    "    subInds = inds[indinds[index] : indinds[index + 1] + 1]\n",
    "    return subInds, complete\n",
    "\n",
    "def getSubV3Check():\n",
    "    D3List = [[[0,1,2,], [3,4,5]], [[6,7,8], [9,10,11]]]\n",
    "    consolcomplete = [0,1,2,3,4,5,6,7,8,9,10,11]\n",
    "    consolinds = [0,3,6,9,12]\n",
    "    consolindinds = [0,2,4]\n",
    "    print getSubV3(1, consolindinds, consolinds, consolcomplete)\n",
    "    print consolinds[2:5]\n",
    "    t = V3IndexedShared(D3List, 'int32')\n",
    "    \n",
    "# getSubV3Check()\n",
    "\n",
    "#the following pair of functions implements consolidation of a tensor using theano scan -- not the fastest, but its inherently\n",
    "#difficult to vectorize.\n",
    "def singleConsol(tensor, indices):\n",
    "    return (T.choose(indices, tensor)).sum()\n",
    "\n",
    "def consolidateTensor(tensor, consolinds, consolcomplete):\n",
    "    irange = T.arange(getV2Length(consolinds))\n",
    "    consolidated, updates = theano.scan(fn = lambda ind, tens, coninds, concomp: singleConsol(tens, getSubV2(ind, coninds, concomp)),\n",
    "                                        sequences = irange,\n",
    "                                        non_sequences=[tensor, consolinds, consolcomplete])\n",
    "    return consolidated\n",
    "\n",
    "def consolidateTensorCheck():\n",
    "    x = T.vector('x')\n",
    "    inds = T.ivector('inds')\n",
    "    complete = T.ivector('complete')\n",
    "    y = consolidateTensor(x,inds,complete)\n",
    "    f = theano.function([x,inds,complete], y)\n",
    "    print f(np.array([1.0,2.0,4.0,8.0]).astype(theano.config.floatX), np.array([0,3,4]).astype('int32'), np.array([1,2,3,0]).astype('int32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "QSaXtAM_o8gB",
    "outputId": "e4de1289-9fd1-49fe-8413-9bf3e368acce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running initial dictSingleGenConsolidate\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "starting to loop\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "first version took: 0.000629901885986\n",
      "looped\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "first version took: 0.000344038009644\n",
      "looped\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "first version took: 0.000550985336304\n",
      "looped\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "first version took: 0.000200986862183\n",
      "looped\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "first version took: 0.000527858734131\n",
      "looped\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "first version took: 0.000336885452271\n",
      "looped\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "first version took: 0.000205039978027\n",
      "looped\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "first version took: 0.000198841094971\n",
      "looped\n",
      "biased and relued: [0.03647235 0.08699919 0.04379181 0.21789371 0.01532887]\n",
      "biased and relued: [0.03970769 0.05352465 0.01036031 0.04529496 0.01552133]\n",
      "biased and relued: [0.01748796 0.03717213 0.00895094 0.01062623 0.03163252]\n",
      "biased and relued: [0.01336848 0.05111834 0.00780323 0.02613946 0.01704639]\n",
      "biased and relued: [0.00123963 0.04004409 0.00639926 0.02220073 0.01166623]\n",
      "biased and relued: [0.01660602 0.04563525 0.0195201  0.00678446 0.02005074]\n",
      "biased and relued: [0.00710637 0.03259708 0.02777959 0.00720023 0.03563839]\n",
      "biased and relued: [0.02479658 0.01070777 0.02949263 0.02281365 0.01888324]\n",
      "biased and relued: [0.02868101 0.03126103 0.02300217 0.04489189 0.01444867]\n",
      "[0.39217908 0.67091035 0.44545708 0.61728014]\n",
      "[array([0.03647235, 0.08699919, 0.04379181, 0.2178937 , 0.01532887],\n",
      "      dtype=float32), array([0.03970769, 0.05352465, 0.01036031, 0.04529496, 0.01552133],\n",
      "      dtype=float32), array([0.01748796, 0.03717213, 0.00895094, 0.01062623, 0.03163252],\n",
      "      dtype=float32), array([0.01336848, 0.05111834, 0.00780323, 0.02613946, 0.01704639],\n",
      "      dtype=float32), array([0.00123963, 0.0400441 , 0.00639926, 0.02220073, 0.01166623],\n",
      "      dtype=float32), array([0.01660602, 0.04563525, 0.0195201 , 0.00678446, 0.02005074],\n",
      "      dtype=float32), array([0.00710637, 0.03259708, 0.02777959, 0.00720023, 0.03563839],\n",
      "      dtype=float32), array([0.02479658, 0.01070776, 0.02949263, 0.02281365, 0.01888324],\n",
      "      dtype=float32), array([0.02868101, 0.03126103, 0.02300217, 0.04489189, 0.01444867],\n",
      "      dtype=float32)]\n",
      "[ 0.0000000e+00  0.0000000e+00 -3.0994020e-13 -1.3781813e-12\n",
      " -1.8186584e-12 -6.1988039e-13 -2.7279875e-12 -1.3694278e-12]\n",
      "[ 1.02028635e-13  1.02028635e-13 -1.19635573e-12 -6.84366788e-13\n",
      " -3.44482065e-13 -1.81037390e-12 -2.99633126e-12 -2.99633126e-12\n",
      " -2.10792633e-13 -1.21380594e-13]\n",
      "[ 2.48893636e-12  2.48893636e-12 -1.12469235e-11 -1.12469235e-11\n",
      " -2.17697084e-12 -3.12597366e-12 -1.36666633e-11 -2.94087740e-11\n",
      " -3.26143604e-12 -4.77487754e-12]\n",
      "[ 1.2363060e-11  1.2363060e-11 -2.2449376e-10 -2.2449376e-10\n",
      " -5.4057425e-11 -4.6458691e-11 -5.5154072e-11 -1.2624658e-10\n",
      " -1.9103838e-10 -5.4482219e-10]\n",
      "[ 3.25185073e-10  3.25185073e-10 -8.46715764e-09 -8.46715764e-09\n",
      " -1.29251454e-09 -2.88893420e-09 -9.67742331e-09 -1.37240335e-08\n",
      " -2.82353607e-09 -1.06709468e-08]\n",
      "[ 6.0983674e-10  6.0983674e-10 -1.4720715e-07 -1.4720715e-07\n",
      " -2.3524493e-08 -9.8750867e-08 -3.4259281e-07 -1.4374601e-07\n",
      " -4.2886551e-08 -2.4961662e-07]\n",
      "[ 1.78492243e-07  1.78492243e-07 -1.09495495e-05 -1.09495495e-05\n",
      " -4.68357894e-06 -1.24586431e-05 -4.33015930e-06 -2.91328263e-07\n",
      " -4.81089819e-06 -9.49910282e-06]\n",
      "[ 3.1567692e-05  3.1567692e-05 -4.9529003e-04 -4.9529003e-04\n",
      " -4.2209163e-04 -5.6732661e-05 -1.4704607e-05  6.2870022e-06\n",
      " -5.4150063e-04 -2.0980320e-05]\n",
      "[ 0.00189438  0.00189438 -0.00238459 -0.00238459 -0.00656794  0.00523269\n",
      "  0.00404768  0.00014724 -0.00420525  0.00425508]\n",
      "[ 0.0000000e+00  0.0000000e+00 -3.0994020e-13 -1.3781813e-12\n",
      " -1.8186584e-12 -6.1988039e-13 -2.7279875e-12 -1.3694278e-12]\n",
      "[ 1.02028635e-13  1.02028635e-13 -1.19635573e-12 -6.84366788e-13\n",
      " -3.44482065e-13 -1.81037390e-12 -2.99633126e-12 -2.99633126e-12\n",
      " -2.10792633e-13 -1.21380594e-13]\n",
      "[ 2.48893636e-12  2.48893636e-12 -1.12469235e-11 -1.12469235e-11\n",
      " -2.17697084e-12 -3.12597366e-12 -1.36666633e-11 -2.94087740e-11\n",
      " -3.26143604e-12 -4.77487754e-12]\n",
      "[ 1.2363060e-11  1.2363060e-11 -2.2449376e-10 -2.2449376e-10\n",
      " -5.4057425e-11 -4.6458691e-11 -5.5154072e-11 -1.2624658e-10\n",
      " -1.9103838e-10 -5.4482219e-10]\n",
      "[ 3.25185073e-10  3.25185073e-10 -8.46715764e-09 -8.46715764e-09\n",
      " -1.29251454e-09 -2.88893420e-09 -9.67742331e-09 -1.37240335e-08\n",
      " -2.82353607e-09 -1.06709468e-08]\n",
      "[ 6.0983674e-10  6.0983674e-10 -1.4720715e-07 -1.4720715e-07\n",
      " -2.3524493e-08 -9.8750867e-08 -3.4259281e-07 -1.4374601e-07\n",
      " -4.2886551e-08 -2.4961662e-07]\n",
      "[ 1.78492243e-07  1.78492243e-07 -1.09495495e-05 -1.09495495e-05\n",
      " -4.68357894e-06 -1.24586431e-05 -4.33015930e-06 -2.91328263e-07\n",
      " -4.81089819e-06 -9.49910282e-06]\n",
      "[ 3.1567692e-05  3.1567692e-05 -4.9529003e-04 -4.9529003e-04\n",
      " -4.2209163e-04 -5.6732661e-05 -1.4704607e-05  6.2870022e-06\n",
      " -5.4150063e-04 -2.0980320e-05]\n",
      "[ 0.00189438  0.00189438 -0.00238459 -0.00238459 -0.00656794  0.00523269\n",
      "  0.00404768  0.00014724 -0.00420525  0.00425508]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[numpy.ndarray,\n",
       " numpy.ndarray,\n",
       " numpy.ndarray,\n",
       " numpy.ndarray,\n",
       " numpy.ndarray,\n",
       " numpy.ndarray,\n",
       " numpy.ndarray,\n",
       " numpy.ndarray,\n",
       " numpy.ndarray]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this class is essentially the same as nnet above, except that I implemented it in Theano for speed. All of the derivatives are \n",
    "#explicitly calculated, as I wasn't able to get theano to differentiate it. A lot of the set up is actually accomplished by the \n",
    "#previous class that used numpy.\n",
    "    \n",
    "from random import shuffle\n",
    "import theano\n",
    "theano.config.floatX = 'float32'\n",
    "\n",
    "class tnnet:\n",
    "    def __init__(self, resolution, functions, inputdimension, traindatainps, traindataoutps, testdatainps, testdataoutps, synapseThreshold, net = None):\n",
    "        \n",
    "        mynet = None\n",
    "        if net == None:\n",
    "            mynet = nnet(resolution, functions, inputdimension, traindatainps, traindataoutps, synapseThreshold)\n",
    "            mynet.genConsolidate()\n",
    "            mynet.genWeights()\n",
    "        else:\n",
    "            mynet = net\n",
    "        self.nnet = mynet\n",
    "        \n",
    "\n",
    "        self.sharedTrainingInps = shared(np.array(traindatainps).astype(theano.config.floatX))\n",
    "        self.sharedTrainingOutps = shared(np.array(traindataoutps).astype(theano.config.floatX))\n",
    "        self.sharedTestingInps = shared(np.array(testdatainps).astype(theano.config.floatX))\n",
    "        self.sharedTestingOutps = shared(np.array(testdataoutps).astype(theano.config.floatX))\n",
    "\n",
    "\n",
    "#         print \"weights: \" + str(mynet.weights)\n",
    "#         print \"biases: \" + str(mynet.biases)\n",
    "#         print mynet.feedforward(np.array([0,1,2,3]).astype(theano.config.floatX))\n",
    "#         inp_lengths = [len(consol) for consol in mynet.consolidations]\n",
    "#         inp_lengths = [datainps[0].size] + inp_lengths\n",
    "#         self.inp_lengths = np.array(inp_lengths).astype('int32')\n",
    "#         print \"inp_lengths: \" + str(inp_lengths)\n",
    "#         print \"dinp length: \" + str(datainps[0].size)\n",
    "#         print \"consolidations: \" + str(mynet.consolidations)\n",
    "        \n",
    "#         self.maxInp = np.amax(inp_lengths)\n",
    "#         self.maxPad = shared(np.array([0] * (np.amax(inp_lengths) - min(inp_lengths))).astype(theano.config.floatX))\n",
    "#         self.maxZeroes = shared(np.array([0.0] * self.maxInp).astype(theano.config.floatX))\n",
    "        \n",
    "#         initialPaddingLength = np.amax(inp_lengths) - datainps[0].size\n",
    "#         self.initialPadding = shared(np.array([0.0] * initialPaddingLength).astype(theano.config.floatX))\n",
    "#         self.inp_lengths = shared(self.inp_lengths)\n",
    "        \n",
    "        tweights = V2IndexedShared(theano.config.floatX)\n",
    "        tweights.fromList(mynet.weights)\n",
    "        self.weights = map(lambda x: shared(np.array(x).astype(theano.config.floatX)), mynet.weights)\n",
    "        \n",
    "        tbiases = V2IndexedShared(theano.config.floatX)\n",
    "        tbiases.fromList(mynet.biases)\n",
    "#         print tbiases.complete.get_value()\n",
    "        self.biases = map(lambda x: shared(np.array(x).astype(theano.config.floatX)), mynet.biases)\n",
    "    \n",
    "        tcons = V3IndexedShared(mynet.consolidations, 'int32')\n",
    "#         print \"final weights: \" + str(mynet.finalweights)\n",
    "        tfws = shared((mynet.finalweights).astype(theano.config.floatX))\n",
    "        tfbs = shared((mynet.finalbiases).astype(theano.config.floatX))\n",
    "        self.weightnum = mynet.weightnum\n",
    "        self.hiddenlayers = mynet.hiddenlayers\n",
    "        \n",
    "        self.consolMasks = []\n",
    "        self.dEdWsinverseConsols = []\n",
    "        self.oneMultipliers = []\n",
    "        \n",
    "        #this loop fulfills two important functions. First, it makes consolmasks from consolidation lists\n",
    "        #Second, it creates inverse consolidation lists, going from the next layer back to the original layer,\n",
    "        #which is crucial for backpropagation.\n",
    "        for layerConsols in mynet.consolidations:\n",
    "#             print \"initial \" + str(layerConsols)\n",
    "            maxInLength = max(map(len, layerConsols))\n",
    "            inLength = len(flatten(layerConsols))\n",
    "            extended = map(lambda l: l + [inLength] * (maxInLength - len(l)), layerConsols)\n",
    "#             print \"extended: \" + str(extended)\n",
    "            self.consolMasks.append(shared(np.array(extended).astype('int32')))\n",
    "            self.oneMultipliers.append(shared(np.array([1.0] * maxInLength).astype(theano.config.floatX)))\n",
    "            \n",
    "            flattened = flatten(layerConsols)\n",
    "            frame = [0] * len(flattened)\n",
    "            for i in range(len(layerConsols)):\n",
    "                for sub in layerConsols[i]:\n",
    "                    frame[sub] = i\n",
    "            \n",
    "            self.dEdWsinverseConsols.append(shared(np.array(frame).astype('int32')))\n",
    "        \n",
    "#         print self.nnet.consolidations[0]\n",
    "#         print self.dEdWsinverseConsols[0].get_value()\n",
    "            \n",
    "        \n",
    "        \n",
    "        inp = T.fvector('inp')\n",
    "#         paddedInp = T.concatenate([inp, self.initialPadding])\n",
    "        actualOutp = T.fvector('actualOutp')\n",
    "        alpha = T.fscalar('alpha')\n",
    "        \n",
    "        self.consolidations = map(lambda x: V2IndexedShared('int32').fromList(x), self.nnet.consolidations)\n",
    "        \n",
    "        self.winds = tweights.inds\n",
    "        self.ws = tweights.complete\n",
    "        self.binds = tbiases.inds\n",
    "        self.bs = tbiases.complete\n",
    "        self.consindinds = tcons.D3Inds\n",
    "        self.consinds = tcons.D2Inds\n",
    "        self.cons = tcons.complete\n",
    "        self.bMult = shared(np.asscalar(np.array([mynet.branchMultiplier]).astype('int32')))\n",
    "        self.fws = tfws\n",
    "        self.fbs = tfbs\n",
    "#         print \"weights: \" + '\\n'.join(map(str, self.nnet.weights))\n",
    "# #         print self.nnet.biases\n",
    "#         print \"inverse Consols: \" + '\\n'.join(map(lambda x: str(x.get_value().tolist()), self.dEdWsinverseConsols))\n",
    "#         print \"consols: \" + '\\n'.join(map(str, self.nnet.consolidations))\n",
    "        self.zeropad = shared(np.array([0.0]).astype(theano.config.floatX))\n",
    "        \n",
    "        self.bMultOnes = shared(np.array([1.0] * self.nnet.branchMultiplier).astype(theano.config.floatX))\n",
    "        \n",
    "        self.params = self.weights + self.biases + [self.fws, self.fbs]\n",
    "#         self.constparams = [self.consindinds, self.consinds, self.cons, self.winds, self.binds, self.bMult]\n",
    "        \n",
    "#         def singleCons(consInds, tens):\n",
    "#             asum, _ = theano.scan(fn = lambda i, tensor: tensor[i],\n",
    "#                                  sequences = consInds,\n",
    "#                                  non_sequences = tens)\n",
    "#             return asum.sum()\n",
    "        \n",
    "        \n",
    "#         def layer(ind, inpLength, inp):\n",
    "#             weights = getSubV2(ind, self.winds, self.ws)\n",
    "#             biases = getSubV2(ind, self.binds, self.bs)\n",
    "#             consolinds, consols = getSubV3(ind, self.consindinds, self.consinds, self.cons)\n",
    "#             inp = T.repeat(inp[0:inpLength], self.bMult)\n",
    "#             inp = weights * inp\n",
    "            \n",
    "#             #consolidation code\n",
    "#             numConsolidatedRange = T.arange(consolinds.size - 1)\n",
    "#             inp, _ = theano.scan(fn = lambda ind, x, coninds, concomp: singleCons(getSubV2(ind, coninds, concomp), x),\n",
    "#                                                 sequences = numConsolidatedRange,\n",
    "#                                                 non_sequences=[inp, consolinds, consols])\n",
    "#             inp = inp + biases\n",
    "#             inp = relu(inp)\n",
    "#             padding = self.maxPad[0 : self.maxInp - inp.size]\n",
    "#             inp = T.concatenate([inp, padding])\n",
    "#             return inp\n",
    "       \n",
    "        def layer(ind, x):\n",
    "            #get output of layer ind with input x\n",
    "            \n",
    "#             print \"in layer\"\n",
    "#             consolinds = self.consolidations[ind].inds\n",
    "#             consols = self.consolidations[ind].complete\n",
    "            \n",
    "            x = T.repeat(x, self.bMult) * self.weights[ind]\n",
    "            x = T.concatenate([x, T.zeros((5,),dtype=theano.config.floatX)])\n",
    "            x = (x.take(self.consolMasks[ind]).astype(theano.config.floatX)) #.sum(axis = 1)\n",
    "            x = T.dot(x, self.oneMultipliers[ind])\n",
    "# #             inp, _ = theano.map(fn = lambda i: inp[i],\n",
    "# #                                sequences = consols)\n",
    "# #             #consolidation code\n",
    "#             r = T.arange(consolinds.size - 1).astype(theano.config.floatX)\n",
    "#             for i in xrange(len(self.nnet.consolidations[ind])):\n",
    "#                 r = T.set_subtensor(r[i], x[consolinds[i]:consolinds[i + 1]].sum())\n",
    "#             numConsolidatedRange = T.arange(consolinds.size - 1).astype('int32')\n",
    "# #             inp2, _ = theano.map(fn = lambda i: inp1[consolinds[i]: consolinds[i + 1]].sum(),\n",
    "# #                                                 sequences = numConsolidatedRange)\n",
    "#             r, _ = theano.map(fn = lambda i, x: x[consolinds[i]: consolinds[i+1]].sum(),\n",
    "#                                                 sequences = numConsolidatedRange,\n",
    "#                                                 non_sequences=[x])\n",
    "            return theano.tensor.nnet.relu(x + self.biases[ind])\n",
    "#             return r\n",
    "\n",
    "        def gradLayer(ind, nextdEdInputs, layerOutput): #returns (dEdWs, dEdBs, newdEdInputs)\n",
    "            expandedLayerOutput = T.repeat(layerOutput, self.bMult)\n",
    "            inverse = self.dEdWsinverseConsols[ind]\n",
    "            inverseddEdInputs = nextdEdInputs.take(inverse)\n",
    "            dEdWs = expandedLayerOutput * inverseddEdInputs\n",
    "            dEdBs = nextdEdInputs\n",
    "            #upt to here correct\n",
    "            \n",
    "            dOutsdIns = T.gt(layerOutput, T.zeros_like(layerOutput))\n",
    "            dOutsdIns = T.cast(dOutsdIns, 'float32')\n",
    "            \n",
    "            dEdConnections = self.weights[ind] * inverseddEdInputs\n",
    "            dEdConnectionGroups = dEdConnections.reshape((dEdConnections.size // self.bMult, self.bMult))\n",
    "            dEdOuts = T.dot(dEdConnectionGroups, self.bMultOnes) #could need to be axis 1\n",
    "            \n",
    "            newdEdInputs = dEdOuts * dOutsdIns\n",
    "            \n",
    "            return (dEdWs, dEdBs, newdEdInputs)\n",
    "        \n",
    "        def intermediateLoop(z):\n",
    "            ret = []\n",
    "            for i in range(self.hiddenlayers):\n",
    "                z = layer(i, z)\n",
    "                ret.append(z.copy())\n",
    "            \n",
    "            return ret\n",
    "        \n",
    "        def gradLoop(dEdIn, layerOutputs):\n",
    "            dEdWs = []\n",
    "            dEdBs = []\n",
    "            for k in reversed(range(self.hiddenlayers)):\n",
    "                newdEdWs, newdEdBs, dEdIn = gradLayer(k, dEdIn, layerOutputs[k])\n",
    "                dEdWs.append(newdEdWs)\n",
    "                dEdBs.append(newdEdBs)\n",
    "            \n",
    "            return dEdWs, dEdBs\n",
    "        \n",
    "        def myGrad(theta, actualOutp):\n",
    "            #get gradient given input (theta) and the target output (actualOutp)\n",
    "            \n",
    "            #get all layer outputs\n",
    "            outputs = intermediateLoop(theta)\n",
    "            \n",
    "            #list of all outputs, including input layer \"outputs\"\n",
    "            outputs = [theta] + outputs\n",
    "            \n",
    "            #calculate final output\n",
    "            last = T.dot(outputs[-1], self.fws)\n",
    "            last = last + self.fbs\n",
    "            last = theano.tensor.nnet.relu(last)\n",
    "            \n",
    "            #get error\n",
    "            difference = last - actualOutp\n",
    "            err = T.dot(difference, difference)\n",
    "            \n",
    "            #get final layer derivative\n",
    "            finaldOutdIn = T.gt(last, T.zeros_like(last))\n",
    "            finaldOutdIn = T.cast(finaldOutdIn, 'float32')\n",
    "            \n",
    "            #get derivative of error with respect to last layer inputs\n",
    "            initdEdIn = finaldOutdIn * (last - actualOutp)\n",
    "            dEdFbs = initdEdIn   \n",
    "            \n",
    "            \n",
    "            initdEdInshuffled = initdEdIn.dimshuffle(('x',0))\n",
    "            finalStructuredLayerOut = outputs[-1]\n",
    "            finalStructuredLayerOutShuffled = finalStructuredLayerOut.dimshuffle((0,'x'))\n",
    "            \n",
    "            dEdFws = finalStructuredLayerOutShuffled * initdEdInshuffled\n",
    "            \n",
    "            \n",
    "            finalStructuredLayerdOutdIn = T.gt(finalStructuredLayerOut, T.zeros_like(finalStructuredLayerOut))\n",
    "            finalStructuredLayerdOutdIn = T.cast(finalStructuredLayerdOutdIn, 'float32')\n",
    "            \n",
    "            finalStructuredLayerdEdOut = T.dot(initdEdIn, self.fws.T)\n",
    "            \n",
    "            finalStructuredLayerdEdIn = finalStructuredLayerdOutdIn * finalStructuredLayerdEdOut\n",
    "            #up to here is correct\n",
    "\n",
    "            dEdWs, dEdBs = gradLoop(finalStructuredLayerdEdIn, outputs)\n",
    "            \n",
    "            return err, list(reversed(dEdWs)), list(reversed(dEdBs)), dEdFws, dEdFbs #, list(reversed(dEdIns)),\n",
    "            \n",
    "            \n",
    "        final = T.fvector()\n",
    "        def loop(z):\n",
    "            ret = T.fvector()\n",
    "            for i in range(self.hiddenlayers):\n",
    "                z = layer(i, z)\n",
    "                ret = z\n",
    "            return ret\n",
    "        finalHiddenOutput = loop(inp)\n",
    "        final = T.dot(finalHiddenOutput, self.fws)\n",
    "        final = final + self.fbs\n",
    "        final = theano.tensor.nnet.relu(final)\n",
    "        \n",
    "        #Declare theano functions for full classifaction (including end relu linerar classifier)\n",
    "        self.classify = theano.function([inp], final)\n",
    "        self.partialClassify = theano.function([inp], finalHiddenOutput)\n",
    "        \n",
    "        index = T.iscalar()\n",
    "        \n",
    "        self.partialClassifyTraining = theano.function(inputs= [index], outputs = finalHiddenOutput,\n",
    "                                                       givens = {\n",
    "                                                                        inp : self.sharedTrainingInps[index],\n",
    "                                                                    } )\n",
    "        self.partialClassifyTesting = theano.function(inputs=[index], outputs = finalHiddenOutput,\n",
    "                                                     givens = {\n",
    "                                                         inp : self.sharedTestingInps[index]\n",
    "                                                     })\n",
    "        \n",
    "        diff = final - actualOutp\n",
    "        squared = 0.5 * T.dot(diff, diff)\n",
    "\n",
    "#         print self.classify(np.array([0,1,2,3]).astype(theano.config.floatX))\n",
    "\n",
    "        index = T.iscalar()\n",
    "\n",
    "        squaredError, wgrads, bgrads, fwsgrads, fbsgrads = myGrad(inp, actualOutp)\n",
    "#         mygradients = myGrad(inp, actualOutp)\n",
    "        self.realGrad = theano.function(inputs = [inp, actualOutp], outputs = T.grad(squared, self.weights))\n",
    "        self.mygrads = theano.function(inputs = [inp, actualOutp], outputs = wgrads)\n",
    "        \n",
    "        #concatenate lists of the gradients so as to iteratively modify them -- don't worry, I'm not just adding them together\n",
    "        gradients = wgrads + bgrads + [fwsgrads, fbsgrads]\n",
    "        \n",
    "#         realgrads = T.grad(squared, self.params)\n",
    "#         realUpdates = OrderedDict((p, p - alpha * g) for p, g in zip(self.params, realgrads))\n",
    "        param_Updates = OrderedDict((p, p - alpha * g) for p, g in zip(self.params, gradients))\n",
    "        \n",
    "        self.intermediates = theano.function([inp], intermediateLoop(inp))\n",
    "        \n",
    "        self.train = theano.function(inputs = [index, alpha],\n",
    "                                                                    outputs = squaredError,\n",
    "                                                                    updates = param_Updates,\n",
    "                                                                    givens = {\n",
    "                                                                        inp : self.sharedTrainingInps[index],\n",
    "                                                                        actualOutp: self.sharedTrainingOutps[index]\n",
    "                                                                    })\n",
    "#         self.realtrain = theano.function(inputs = [index, alpha],\n",
    "#                                                                     outputs = squared,\n",
    "#                                                                     updates = realUpdates,\n",
    "#                                                                     givens = {\n",
    "#                                                                         inp : self.sharedTrainingInps[index],\n",
    "#                                                                         actualOutp: self.sharedTrainingOutps[index]\n",
    "#                                                                     })\n",
    "        self.test = theano.function(inputs = [index],\n",
    "            outputs = final,\n",
    "            givens = {\n",
    "                inp : self.sharedTestingInps[index]\n",
    "            })\n",
    "    \n",
    "    def descend(self, alpha, epochs, trainingInps, trainingOutps, testingInps, testingOutps, verbose):\n",
    "        training = zip(trainingInps, trainingOutps)\n",
    "        testing = zip(testingInps, testingOutps)\n",
    "        testLen = len(testing)\n",
    "        trainLen = len(trainingInps)\n",
    "        indorder = range(trainLen)\n",
    "        testingAccuracies = []\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            print \"starting epoch...\"\n",
    "            start = time.time()\n",
    "            shuffle(indorder)\n",
    "            for j in indorder:\n",
    "                self.train(j, alpha)\n",
    "            \n",
    "            testingAccuracy = 0.0\n",
    "            for j in range(len(testingOutps)):\n",
    "                if np.argmax(self.test(j)) == np.argmax(testingOutps[j]):\n",
    "                    testingAccuracy += 1.0\n",
    "            # for (testInp, testOutp) in testing:\n",
    "            #     if np.argmax(self.classify(testInp)) == np.argmax(testOutp):\n",
    "            #         testingAccuracy += 1.0\n",
    "                    \n",
    "            percentTestingAccuracy = testingAccuracy / testLen * 100.0\n",
    "            testingAccuracies.append(percentTestingAccuracy)\n",
    "            end = time.time()\n",
    "            if verbose:\n",
    "                print \"epoch \" + str(i + 1) + \" -- testing accuracy : \" + str(percentTestingAccuracy) + \" duration: \" + str(end - start) + \"s\"\n",
    "        \n",
    "        return max(testingAccuracies), testingAccuracies\n",
    "            \n",
    "        \n",
    "tn = tnnet(10, [[lambda x: x + 1], [lambda x: x * 2]], 1, [np.array([0,1,2,3])], [np.array([1,2,3,4])],  [np.array([1,2,3,4])],  [np.array([1,2,3,4])], 100)\n",
    "print tn.nnet.feedforward(np.array([0,1,2,3]))\n",
    "print tn.intermediates(np.array([0,1,2,3]).astype(theano.config.floatX))\n",
    "# print tn.nnet.weights\n",
    "# print tn.nnet.biases\n",
    "x = np.array([0,1,2,3]).astype(theano.config.floatX)\n",
    "classed = tn.classify(np.array([0,1,2,3]).astype(theano.config.floatX))\n",
    "# print '\\n'.join(map(str,classed))\n",
    "# diff = x * 0.5 - classed\n",
    "# print np.dot(diff, diff)\n",
    "# print tn.classify(np.array([0,1,2,3]).astype(theano.config.floatX))\n",
    "print '\\n'.join(map(str, tn.realGrad(x, x * 0.33)))\n",
    "print '\\n'.join(map(str, tn.mygrads(x, x*0.33)))\n",
    "map(type, tn.mygrads(x, x * 0.33))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "nj8CfYB8o8gQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theano.config.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "lDEgKax3o8gb",
    "outputId": "1c206e12-9712-4c4d-ab70-1687de132e4e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating\n",
      "running initial dictSingleGenConsolidate\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "starting to loop\n",
      "branchmultiplier: 23\n",
      "weights length: 18032\n",
      "final layer output length: 4656\n",
      "average number of connections per neuron by layer: [3.872852233676976]\n",
      "spacial dimension: 4\n",
      "branching by dimension: [4, 7, 7, 5]\n",
      "cartesian dimensions: []\n",
      "beginning partial classification\n",
      "partial classification took:  32.9613749981\n",
      "starting to build keras linear classifier\n",
      "10000/10000 [==============================] - 0s 28us/step\n",
      "keras building and training took: 51.6655740738\n",
      "linear model training accuracy,testing accuracy: 0.8840166666666667  ,  0.8929\n",
      "evaluating\n",
      "running initial dictSingleGenConsolidate\n",
      "starting a dictSingleGenConsolidate\n",
      "finished a dictSingleGenConsolidate\n",
      "starting to loop\n",
      "branchmultiplier: 14\n",
      "weights length: 10976\n",
      "final layer output length: 1728\n",
      "average number of connections per neuron by layer: [6.351851851851852]\n",
      "spacial dimension: 2\n",
      "branching by dimension: [8, 6]\n",
      "cartesian dimensions: []\n",
      "beginning partial classification\n",
      "partial classification took:  23.9237821102\n",
      "starting to build keras linear classifier\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-0ea93e761ed5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m \u001b[0mevolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnistEvaluateRandomWeights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-cfcc078affa1>\u001b[0m in \u001b[0;36mevolve\u001b[0;34m(evaluator)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mfinalPop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogbook\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meaMuPlusLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLAMBDA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCXPB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMUTPB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGENERATIONS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmyStats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhalloffame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhallOFame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/theano_p27/lib/python2.7/site-packages/deap/algorithms.pyc\u001b[0m in \u001b[0;36meaMuPlusLambda\u001b[0;34m(population, toolbox, mu, lambda_, cxpb, mutpb, ngen, stats, halloffame, verbose)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;31m# Evaluate the individuals with an invalid fitness\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0minvalid_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpopulation\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m     \u001b[0mfitnesses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvalid_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitnesses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0mind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-0ea93e761ed5>\u001b[0m in \u001b[0;36mmnistEvaluateRandomWeights\u001b[0;34m(individual)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0mlinearClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sgd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical_accuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m     \u001b[0mtrainingHistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinearClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandomWeightsTrainingOutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraininglabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinearClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandomWeightsTestingOutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestinglabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/theano_p27/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/theano_p27/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/theano_p27/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/theano_p27/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1225\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1227\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/theano_p27/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import deap.gp as gp\n",
    "import time\n",
    "import sys\n",
    "import sklearn.svm as svm\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras import metrics\n",
    "K.set_floatx(\"float32\")\n",
    "import copy\n",
    "import dill\n",
    "import pickle\n",
    "import gc\n",
    "sys.setrecursionlimit(1500)\n",
    "\n",
    "def mnistevaluate(individual):\n",
    "    weights = []\n",
    "    biases = []\n",
    "    branching = 0\n",
    "    consolidations = []\n",
    "    fws = []\n",
    "    fbs = []\n",
    "    hiddenlayers = 0\n",
    "    weightnum = 0\n",
    "    branching = 0\n",
    "    \n",
    "    print \"evaluating\"\n",
    "    funcs = []\n",
    "    for dimlist in individual:\n",
    "        newDimlist = []\n",
    "        for tree in dimlist:\n",
    "#             print gp.stringify(tree)\n",
    "            f = gp.compile(tree, pset)\n",
    "            newDimlist.append(f)\n",
    "        funcs.append(newDimlist)\n",
    "    \n",
    "    res = 20\n",
    "    tnet = tnnet(res, funcs, 2, trainingimgs, traininglabels, testingimgs, testinglabels, 200000)\n",
    "    mynet = tnet.nnet\n",
    "    weights = mynet.weights\n",
    "    biases = mynet.biases\n",
    "    branching = mynet.branchMultiplier\n",
    "    consolidations = mynet.consolidations\n",
    "    fws = mynet.finalweights\n",
    "    fbs = mynet.finalbiases\n",
    "    hiddenlayers = mynet.hiddenlayers\n",
    "    weightnum = mynet.weightnum\n",
    "    print \"branchmultiplier: \" + str(mynet.branchMultiplier)\n",
    "    print \"weights length: \" + str(len(flatten(mynet.weights)))\n",
    "#     print \"consolidations lengths\" + str(map(len, mynet.consolidations))\n",
    "    layerDensities = []\n",
    "    prevlayerLength = trainingimgs[0].size\n",
    "    for layer in mynet.weights:\n",
    "        layerLength = len(layer)\n",
    "        branched = prevlayerLength * mynet.branchMultiplier\n",
    "        layerDensities.append((1.0 * branched) / layerLength)\n",
    "        prevlayerLength = layerLength\n",
    "    print \"average number of connections per neuron by layer: \" + str(layerDensities)\n",
    "    print \"spacial dimension: \" + str(len(funcs))\n",
    "    print \"branching by layer: \" + str(map(len, funcs))\n",
    "    print \"beginning training\"\n",
    "    testStart = time.time()\n",
    "    x = tnet.train(0, 0.05)\n",
    "    print \"trained in: \" + str(time.time() - testStart)\n",
    "    print x\n",
    "    print tnet.classify(trainingimgs[0])\n",
    "#     testStart = time.time()\n",
    "#     x = tnet.realtrain(0, 0.05)\n",
    "    print \"autograd trained in: \" + str(time.time() - testStart)\n",
    "    \n",
    "    avgpercenttestAccuracy, avgpercenttestAccuracylist = tnet.descend(0.02, 5, trainingimgs,traininglabels, testingimgs, testinglabels, True)\n",
    "    return avgpercenttestAccuracy\n",
    "\n",
    "\n",
    "sampleHistoryObject = None\n",
    "saveCount = 0\n",
    "iteration = \"cartesian2\"\n",
    "def mnistEvaluateRandomWeights(individual):\n",
    "    weights = []\n",
    "    biases = []\n",
    "    branching = 0\n",
    "    consolidations = []\n",
    "    fws = []\n",
    "    fbs = []\n",
    "    hiddenlayers = 0\n",
    "    weightnum = 0\n",
    "    branching = 0\n",
    "    \n",
    "    print \"evaluating\"\n",
    "    \n",
    "    #don't have to worry about too many cartesian flags since I implemented custom crossover, mutation, and \n",
    "    #creation functions. Those are the only three procedures that could create too many flags.\n",
    "    funcs = []\n",
    "    for dimlist in individual:\n",
    "        newDimlist = []\n",
    "        for tree in dimlist:\n",
    "            if tree == \"cartesian\":\n",
    "                newDimList.append(tree)\n",
    "            else:\n",
    "                f = gp.compile(tree, pset)\n",
    "                newDimlist.append(f)\n",
    "        funcs.append(newDimlist)\n",
    "    \n",
    "    res = 20\n",
    "    tnet = tnnet(res, funcs, 2, trainingimgs, traininglabels, testingimgs, testinglabels, 50000)\n",
    "    mynet = tnet.nnet\n",
    "    weights = mynet.weights\n",
    "    biases = mynet.biases\n",
    "    branching = mynet.branchMultiplier\n",
    "    consolidations = mynet.consolidations\n",
    "    fws = mynet.finalweights\n",
    "    fbs = mynet.finalbiases\n",
    "    hiddenlayers = mynet.hiddenlayers\n",
    "    weightnum = mynet.weightnum\n",
    "    print \"branchmultiplier: \" + str(mynet.branchMultiplier)\n",
    "    print \"weights length: \" + str(len(flatten(mynet.weights)))\n",
    "#     print \"consolidations lengths\" + str(map(len, mynet.consolidations))\n",
    "    layerDensities = []\n",
    "    prevlayerLength = trainingimgs[0].size\n",
    "    for i in range(len(consolidations)):\n",
    "        layerDensities.append(np.mean(map(lambda l: len(l), consolidations[i])))\n",
    "    print \"final layer output length: \" + str(len(consolidations[-1]))\n",
    "    print \"average number of connections per neuron by layer: \" + str(layerDensities)\n",
    "    print \"spacial dimension: \" + str(len(funcs))\n",
    "    print \"branching by dimension: \" + str(map(len, funcs))\n",
    "    print \"cartesian dimensions: \" + str(mynet.cartesianDims)\n",
    "    print \"beginning partial classification\"\n",
    "    testStart = time.time()\n",
    "    \n",
    "    #generate dataset with random weights\n",
    "    randomWeightsTrainingOutputs = []\n",
    "    for i in range(len(trainingimgs)):\n",
    "        randomWeightsTrainingOutputs.append(tnet.partialClassifyTraining(i))\n",
    "        \n",
    "    randomWeightsTestingOutputs = []\n",
    "    for i in range(len(testingimgs)):\n",
    "        randomWeightsTestingOutputs.append(tnet.partialClassifyTesting(i))\n",
    "    \n",
    "    outputSize = randomWeightsTrainingOutputs[0].size\n",
    "        \n",
    "    print \"partial classification took:  \" + str(time.time() - testStart)\n",
    "    testStart = time.time()\n",
    "    print \"starting to build keras linear classifier\"\n",
    "    \n",
    "    linearClassifier = Sequential()\n",
    "    linearClassifier.add(Dense(input_dim=outputSize, units=10, activation=\"softmax\", kernel_initializer=\"normal\"))\n",
    "    linearClassifier.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=[metrics.categorical_accuracy])\n",
    "    \n",
    "    trainingHistory = linearClassifier.fit(np.array(randomWeightsTrainingOutputs,dtype='float32'),np.array(traininglabels,dtype='float32'),epochs=20,verbose=0)\n",
    "    loss, accuracy = linearClassifier.evaluate(np.array(randomWeightsTestingOutputs,dtype='float32'),np.array(testinglabels,dtype='float32'))\n",
    "    \n",
    "    sampleHistoryObject = trainingHistory\n",
    "    \n",
    "    print \"keras building and training took: \" + str(time.time() - testStart)\n",
    "    print \"linear model training accuracy,testing accuracy: \" + str(trainingHistory.history['categorical_accuracy'][-1]) + \"  ,  \" + str(accuracy)\n",
    "    \n",
    "    netHistoryIndividual = {\"net\": copy.deepcopy(mynet), \"kerasHistoryDict\":trainingHistory.history, \"densities\":layerDensities,\n",
    "                           \"funcs\":funcs[:], \"kerasTestAccuracy\":accuracy}\n",
    "    \n",
    "    with open(\"netHistoryIndividual\" + str(iteration) + \"-\" + str(time.time())[:10], \"w+\") as f:\n",
    "        pickle.dump(netHistoryIndividual, f)\n",
    "        \n",
    "    #Garbage collect everything to avoid memory overflows/crashing\n",
    "    \n",
    "    #can't do keras clear session because not using tensorflow\n",
    "#     kerasClearSession()\n",
    "\n",
    "    tnet.sharedTrainingInps.set_value([[]])\n",
    "    tnet.sharedTrainingOutps.set_value([[]])\n",
    "    tnet.sharedTestingInps.set_value([[]])\n",
    "    tnet.sharedTestingOutps.set_value([[]])\n",
    "    \n",
    "    #python garbage collector is pretty lazy. It needs a lot of motivation.\n",
    "    for i in range(10):\n",
    "        gc.collect()\n",
    "        \n",
    "#     mySVMclassifier = svm.LinearSVC()\n",
    "    \n",
    "#     #svm doesn't want vectors as the class, just scalars\n",
    "#     mySVMclassifier.fit(randomWeightsTrainingOutputs, train_labels)\n",
    "    \n",
    "#     accuracy = mySVMclassifier.score(randomWeightsTestingOutputs, test_labels)\n",
    "#     print \"SVM Accuracy \" + str(accuracy)\n",
    "    \n",
    "    #comma is because deap expects a tuple for some reason, this isn't a bug\n",
    "    return accuracy,\n",
    "    \n",
    "\n",
    "evolve(mnistEvaluateRandomWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import dill\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(map(lambda d: d[\"kerasTestAccuracy\"], netHistoryList[87:]))\n",
    "plt.show()\n",
    "print(len(netHistoryList))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "514576"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sys import getsizeof\n",
    "getsizeof(trainingimgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "import pickle\n",
    "iteration = 2\n",
    "for i in range(int(math.ceil(len(netHistoryList)/15.0))):\n",
    "    with open(\"netHistoryList\" + str(iteration) + \"-\" + str(i), \"w+\") as f:\n",
    "        pickle.dump(netHistoryList[i*15:(i+1)*15],f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "sVPrn32Io8go",
    "outputId": "78405ad5-4013-41d4-8530-4fe2b807e272"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4)\n",
      "(100,)\n",
      "[1 1 0 0 0 0 0 1 0 1 0 1 1 1 1 0 0 0 1 1 1 0 0 1 0 1 1 1 0 1 1 1 0 1 1 1 0\n",
      " 1 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 1 0 0 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0\n",
      " 1 0 1 0 0 1 1 0 1 1 0 1 1 0 1 0 0 1 1 0 1 1 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_features=4, random_state=0)\n",
    "print str(X.shape)\n",
    "print str(y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "NeYABakdo8g8",
    "outputId": "6ee523b4-f91c-499c-80c0-ef7a74d67c9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting theano net instance...\n"
     ]
    },
    {
     "ename": "UnusedInputError",
     "evalue": "theano.function was asked to create a function computing outputs given certain inputs, but the provided input variable at index 0 is not part of the computational graph needed to compute the outputs: inp.\nTo make this error into a warning, you can pass the parameter on_unused_input='warn' to theano.function. To disable it completely, use on_unused_input='ignore'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnusedInputError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-868a88d1e99c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m\"numpy classified in \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtestStart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mtnetFromParams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbiases\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfws\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfbs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsolidations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhiddenlayers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweightnum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbranching\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-868a88d1e99c>\u001b[0m in \u001b[0;36mtnetFromParams\u001b[1;34m(weights, biases, fws, fbs, consolidations, hiddenlayers, weightnum, branching)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbranchingmultiplier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbranching\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m\"starting theano net instance...\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mmytnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtnnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainingimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraininglabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestingimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestinglabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mtestStart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmytnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainingimgs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-a7fa26851401>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, resolution, functions, inputdimension, traindatainps, traindataoutps, testdatainps, testdataoutps, synapseThreshold, net)\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[0mfinal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassify\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m \u001b[1;31m#         print self.classify(np.array([0,1,2,3]).astype(theano.config.floatX))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/theano/compile/function.pyc\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[0;32m    318\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m                    output_keys=output_keys)\n\u001b[0m\u001b[0;32m    321\u001b[0m     \u001b[1;31m# We need to add the flag check_aliased inputs if we have any mutable or\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[1;31m# borrowed used defined inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/theano/compile/pfunc.pyc\u001b[0m in \u001b[0;36mpfunc\u001b[1;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[0;32m    477\u001b[0m                          \u001b[0maccept_inplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_inplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    478\u001b[0m                          \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 479\u001b[1;33m                          output_keys=output_keys)\n\u001b[0m\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36morig_function\u001b[1;34m(inputs, outputs, mode, accept_inplace, name, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[0;32m   1774\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1775\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1776\u001b[1;33m                    \u001b[0moutput_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1777\u001b[0m             defaults)\n\u001b[0;32m   1778\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, mode, accept_inplace, function_builder, profile, on_unused_input, fgraph, output_keys)\u001b[0m\n\u001b[0;32m   1413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1414\u001b[0m         \u001b[1;31m# Check if some input variables are unused\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1415\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_unused_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon_unused_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m         \u001b[1;31m# Make a list of (SymbolicInput|SymblicInputKits, indices,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m_check_unused_inputs\u001b[1;34m(self, inputs, outputs, on_unused_input)\u001b[0m\n\u001b[0;32m   1551\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mon_unused_input\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'raise'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1552\u001b[0m                     raise UnusedInputError(msg % (inputs.index(i),\n\u001b[1;32m-> 1553\u001b[1;33m                                                   i.variable, err_msg))\n\u001b[0m\u001b[0;32m   1554\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1555\u001b[0m                     raise ValueError(\"Invalid value for keyword \"\n",
      "\u001b[1;31mUnusedInputError\u001b[0m: theano.function was asked to create a function computing outputs given certain inputs, but the provided input variable at index 0 is not part of the computational graph needed to compute the outputs: inp.\nTo make this error into a warning, you can pass the parameter on_unused_input='warn' to theano.function. To disable it completely, use on_unused_input='ignore'."
     ]
    }
   ],
   "source": [
    "def tnetFromParams(weights, biases, fws, fbs, consolidations, hiddenlayers, weightnum, branching):\n",
    "    frame = nnet(10, [[lambda x: x + 1], [lambda x: x * 2]], 1, [np.array([0,1,2,3])], [np.array([1])], 100)\n",
    "    frame.weights = weights\n",
    "    frame.biases = biases\n",
    "    frame.finalweights = np.array(fws).astype(theano.config.floatX)\n",
    "    frame.finalbiases = np.array(fbs).astype(theano.config.floatX)\n",
    "    frame.consolidations = consolidations\n",
    "    frame.hiddenlayers = hiddenlayers\n",
    "    frame.weightnum = weightnum\n",
    "    frame.branchingmultiplier = branching\n",
    "    print \"starting theano net instance...\"\n",
    "    mytnet = tnnet(10, [[lambda x: x + 1], [lambda x: x * 2]], 1, trainingimgs, traininglabels, testingimgs, testinglabels, 5000, net = frame)\n",
    "    testStart = time.time()\n",
    "    x = mytnet.classify(trainingimgs[0])\n",
    "    print \"classified in \" + str(time.time() - testStart)\n",
    "    testStart = time.time()\n",
    "    x = frame.feedforward(trainingimgs[0])\n",
    "    print \"numpy classified in \" + str(time.time() - testStart)\n",
    "\n",
    "tnetFromParams(weights, biases, fws, fbs, consolidations, hiddenlayers, weightnum, branching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "yEp_G79Jo8hM",
    "outputId": "c5d71b76-ff5e-435a-c958-ef090f8006f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 0.752302922028\n",
      "Cost: 0.234828531853\n",
      "Cost: 0.217997165391\n",
      "Cost: 0.176582778796\n",
      "Cost: 0.0941889559431\n",
      "Cost: 0.0547008715418\n",
      "Cost: 0.0227962112237\n",
      "Cost: 0.0103721161976\n",
      "Cost: 0.00631427914256\n",
      "Cost: 0.00444667437915\n",
      "Cost: 0.00339910571615\n",
      "Cost: 0.00273639533448\n",
      "Cost: 0.00228238999109\n",
      "Cost: 0.00195317405859\n",
      "Cost: 0.00170428799655\n",
      "Cost: 0.00150985199376\n",
      "Cost: 0.00135402741352\n",
      "Cost: 0.00122653983734\n",
      "Cost: 0.00112027524709\n",
      "Cost: 0.00103046853549\n",
      "0.971243725343\n",
      "0.0324757818475\n",
      "0.97118115104\n",
      "0.0308740290756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 970 (CNMeM is disabled, cuDNN not available)\n"
     ]
    }
   ],
   "source": [
    "import theano.tensor.nnet as nnet\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "import numpy as np\n",
    "x = T.dvector()\n",
    "y = T.dscalar()\n",
    "def layer(x, w):\n",
    "    b = np.array([1], dtype=theano.config.floatX)\n",
    "    new_x = T.concatenate([x, b])\n",
    "    m = T.dot(w.T, new_x) #theta1: 3x3 * x: 3x1 = 3x1 ;;; theta2: 1x4 * 4x1\n",
    "    h = nnet.sigmoid(m)\n",
    "    return h\n",
    "def grad_desc(cost, theta):\n",
    "    alpha = 0.1 #learning rate\n",
    "    return theta - (alpha * T.grad(cost, wrt=theta))\n",
    "theta1 = theano.shared(np.array(np.random.rand(3,3), dtype=theano.config.floatX)) # randomly initialize\n",
    "theta2 = theano.shared(np.array(np.random.rand(4,1), dtype=theano.config.floatX))\n",
    "hid1 = layer(x, theta1) #hidden layer\n",
    "out1 = T.sum(layer(hid1, theta2)) #output layer\n",
    "fc = (out1 - y)**2 #cost expression\n",
    "\n",
    "\n",
    "cost = theano.function(inputs=[x, y], outputs=fc, updates=[\n",
    "        (theta1, grad_desc(fc, theta1)),\n",
    "        (theta2, grad_desc(fc, theta2))])\n",
    "run_forward = theano.function(inputs=[x], outputs=out1)\n",
    "inputs = np.array([[0,1],[1,0],[1,1],[0,0]]).reshape(4,2) #training data X\n",
    "exp_y = np.array([1, 1, 0, 0]) #training data Y\n",
    "cur_cost = 0\n",
    "for i in range(10000):\n",
    "    for k in range(len(inputs)):\n",
    "        cur_cost = cost(inputs[k], exp_y[k]) #call our Theano-compiled cost function, it will auto update weights\n",
    "    if i % 500 == 0: #only print the cost every 500 epochs/iterations (to save space)\n",
    "        print('Cost: %s' % (cur_cost,))\n",
    "        \n",
    "\n",
    "\n",
    "#Training done! Let's test it out\n",
    "print(run_forward([0,1]))\n",
    "print(run_forward([1,1]))\n",
    "print(run_forward([1,0]))\n",
    "print(run_forward([0,0]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3b6BDwT7o8hg",
    "outputId": "76a1e4e7-f4cf-411b-e5f3-1882464400a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GpuElemwise{exp,no_inplace}(<CudaNdarrayType(float32, vector)>), HostFromGpu(GpuElemwise{exp,no_inplace}.0)]\n",
      "Looping 1000 times took 0.332850 seconds\n",
      "Result is [ 1.23178029  1.61879349  1.52278066 ...,  2.20771813  2.29967761\n",
      "  1.62323296]\n",
      "Used the gpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 970 (CNMeM is disabled, cuDNN not available)\n"
     ]
    }
   ],
   "source": [
    "from theano import function, config, shared, sandbox\n",
    "import theano.tensor as T\n",
    "import numpy\n",
    "import time\n",
    "\n",
    "vlen = 10 * 30 * 768  # 10 x #cores x # threads per core\n",
    "iters = 1000\n",
    "\n",
    "rng = numpy.random.RandomState(22)\n",
    "x = shared(numpy.asarray(rng.rand(vlen), config.floatX))\n",
    "f = function([], T.exp(x))\n",
    "print(f.maker.fgraph.toposort())\n",
    "t0 = time.time()\n",
    "for i in range(iters):\n",
    "    r = f()\n",
    "t1 = time.time()\n",
    "print(\"Looping %d times took %f seconds\" % (iters, t1 - t0))\n",
    "print(\"Result is %s\" % (r,))\n",
    "if numpy.any([isinstance(x.op, T.Elemwise) for x in f.maker.fgraph.toposort()]):\n",
    "    print('Used the cpu')\n",
    "else:\n",
    "    print('Used the gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "ekPuNdbUo8h7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3G-IDP2bo8iK",
    "outputId": "e1f99a3d-02a6-4232-8845-70c8c603618c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  2.,  1.,  4.], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = T.fvector()\n",
    "y = x\n",
    "y = T.set_subtensor(y[3], 1)\n",
    "out = y\n",
    "f = theano.function([x], out)\n",
    "f(np.array(range(5)).astype(theano.config.floatX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "a1MNNkCvo8iW",
    "outputId": "86b58a00-20e5-49b1-a6dc-545994854e51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2,  4,  4,  6,  6, 10, 10,  8,  8, 12]),\n",
       " array([1, 2, 3, 4, 5, 6]),\n",
       " array([  3.,   5.,   8.,   9.,  10.]))"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = np.array([0.0,0.0,0.0])\n",
    "ws = np.array([1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\n",
    "dEdIns = np.array([1,2,3,4,5,6])\n",
    "prevOut = np.array([2,2,2,2,2])\n",
    "bMult = 2\n",
    "bMultOnes = np.array([1.0,1.0])\n",
    "\n",
    "layerConsols = [[0], [1,2], [3,4], [7,8], [5,6], [9]]\n",
    "flattened = flatten(layerConsols)\n",
    "inverseConsols = [0] * len(flattened)\n",
    "for i in range(len(layerConsols)):\n",
    "    for sub in layerConsols[i]:\n",
    "        inverseConsols[sub] = i\n",
    "\n",
    "inverseConsols = np.array([0,1,1,2,2,4,4,3,3,5])\n",
    "\n",
    "    \n",
    "def gradLayer(nextdEdInputs, layerOutput): #returns (dEdWs, dEdBs, newdEdInputs)\n",
    "        expandedLayerOutput = np.repeat(layerOutput, bMult)\n",
    "        inverseddEdInputs = nextdEdInputs.take(inverseConsols)\n",
    "        dEdWs = expandedLayerOutput * inverseddEdInputs\n",
    "        dEdBs = nextdEdInputs\n",
    "        #upt to here correct\n",
    "        def foo(x):\n",
    "            if x >0.0:\n",
    "                return 1.0\n",
    "            else:\n",
    "                return 0.0\n",
    "        gtCast = np.vectorize(foo)\n",
    "#         dOutsdIns = np.gt(layerOutput, np.zeros_like(layerOutput))\n",
    "#         dOutsdIns = np.cast(dOutsdIns, 'float32')\n",
    "\n",
    "        dOutsdIns = gtCast(layerOutput)\n",
    "        dEdConnections = ws * inverseddEdInputs\n",
    "        dEdConnectionGroups = dEdConnections.reshape((dEdConnections.size // bMult, bMult))\n",
    "        dEdOuts = np.dot(dEdConnectionGroups, bMultOnes) #could need to be axis 1\n",
    "\n",
    "        newdEdInputs = dEdOuts * dOutsdIns\n",
    "\n",
    "        return (dEdWs, dEdBs, newdEdInputs)\n",
    "gradLayer(dEdIns, prevOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "M-PVWbN1o8ir"
   },
   "outputs": [],
   "source": [
    "x = np.array(range(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hcPuP7cAo8iz",
    "outputId": "f6336096-b5f9-4c2d-e44d-e662951cee47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [3, 4, 5]])"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape((2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Fr91u3DHo8i_"
   },
   "outputs": [],
   "source": [
    "import numerai\n",
    "trainingfeats, traininglabels, testingfeats, testinglabels = numerai.readTraining()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "5pIuvsvao8jE",
    "outputId": "334b69d7-dfb4-4693-a26d-2bc06017f70d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testingfeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "zSHm_uoUo8jP",
    "outputId": "23988138-fe8b-4a6c-e3b8-e7b4d0f19050"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "tXkvywWyo8jZ"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm evolve.pyc\n",
    "rm fulcrum.pyc\n",
    "rm fractalNetwork2.pyc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ImKcWwlHo8jn",
    "outputId": "d34e1c0b-9a3c-4f1a-87c9-d1761ad389af"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'run'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-a940d54d3ba1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfulcrum\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfulcrum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'module' object has no attribute 'run'"
     ]
    }
   ],
   "source": [
    "import fulcrum\n",
    "fulcrum.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Uzw4trTho8j0",
    "outputId": "bdd00cdb-ec65-4beb-fadf-484cecc5dc8c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 == 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "e5asE65Xo8kA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "Neuro120fractal.ipynb",
   "provenance": [
    {
     "file_id": "0B-aDu7AYJQFwS0Y4WFdUNGtmRlk",
     "timestamp": 1523566751533
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python [conda env:theano_p27]",
   "language": "python",
   "name": "conda-env-theano_p27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
